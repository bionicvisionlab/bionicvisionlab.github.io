<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Bionic Vision Lab</title>
    <link>https://bionicvisionlab.org/</link>
    <description>Recent content on Bionic Vision Lab</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator>
    <language>en-us</language>
    <copyright>&amp;copy; {year}</copyright>
    <lastBuildDate>Wed, 01 Mar 2023 00:00:00 +0000</lastBuildDate>
    
	    <atom:link href="https://bionicvisionlab.org/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Teaching</title>
      <link>https://bionicvisionlab.org/teaching/</link>
      <pubDate>Wed, 01 Mar 2023 00:00:00 +0000</pubDate>
      
      <guid>https://bionicvisionlab.org/teaching/</guid>
      <description></description>
    </item>
    
    <item>
      <title>In the News</title>
      <link>https://bionicvisionlab.org/news/</link>
      <pubDate>Tue, 04 Oct 2022 09:59:00 -0700</pubDate>
      
      <guid>https://bionicvisionlab.org/news/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Research</title>
      <link>https://bionicvisionlab.org/research/</link>
      <pubDate>Sun, 12 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://bionicvisionlab.org/research/</guid>
      <description>&lt;p&gt;How can we return a functional form of sight to people who are living with incurable blindness?&lt;/p&gt;
&lt;div class=&#34;d-none d-sm-block float-right col-5 m-0 ml-2&#34;&gt;
    &lt;img class=&#34;m-0 mb-2 subtle-black-shadow&#34; src=&#34;https://bionicvisionlab.org/img/visual-prostheses.jpg&#34;/&gt;
    &lt;p class=&#34;mb-1&#34; style=&#34;line-height: 100%&#34;&gt;&lt;small&gt;Main approaches for the design of a visual prosthesis &lt;a href=&#34;https://doi.org/10.1186/s42234-018-0013-8&#34; target=&#34;_blank&#34;&gt;(Fernandez, 2018)&lt;/a&gt; include retinal (A), optic nerve (B), lateral geniculate nucleus (LGN, C), and cortical approaches (D).&lt;/small&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Few disabilities affect human life more than the loss of the ability to see. Although some affected individuals can be treated with surgery or medication, there are no effective treatments for many people blinded by severe degeneration or damage to the retina, the optic nerve, or cortex. In such cases, a visual prosthesis (&amp;ldquo;bionic eye&amp;rdquo;) may be the only option.&lt;/p&gt;
&lt;p&gt;However, the quality of current prosthetic vision is still rudimentary and does not differ much across different device technologies &lt;a href=&#34;https://doi.org/10.1088/1741-2552/aa795e&#34; target=&#34;_blank&#34;&gt;(Beyeler et al., 2017)&lt;/a&gt;.
A major outstanding challenge is translating electrode stimulation into a code that the brain can understand.&lt;/p&gt;
&lt;p&gt;The goal of our research is thus to address fundamental questions at the intersection of neuroscience, computer science, and human-computer interaction that will enable the development of a bionic eye capable of restoring high-quality vision to people who are blind.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Publications</title>
      <link>https://bionicvisionlab.org/publications/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>https://bionicvisionlab.org/publications/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Alumni</title>
      <link>https://bionicvisionlab.org/alumni/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bionicvisionlab.org/alumni/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Collaborators</title>
      <link>https://bionicvisionlab.org/collaborators/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bionicvisionlab.org/collaborators/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Contact Us</title>
      <link>https://bionicvisionlab.org/contact/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bionicvisionlab.org/contact/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Grants</title>
      <link>https://bionicvisionlab.org/grants/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bionicvisionlab.org/grants/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Join Us</title>
      <link>https://bionicvisionlab.org/join/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bionicvisionlab.org/join/</guid>
      <description>&lt;p&gt;In general, we are looking for enthusiastic, computationally minded individuals with a shared passion for bionic vision.
If you are interested in joining us, make sure we have open positions (see below) and check out our &lt;a href=&#34;https://docs.google.com/document/d/1Y1wzFVdp-FCoGM47okaW5eYdOOfpgXD5nM9Q7DpwAMo/edit?usp=sharing&#34;&gt;Lab Manual&lt;/a&gt; to familiarize yourself with our lab culture, policies, and expectations.&lt;/p&gt;
&lt;p&gt;&lt;small&gt;&lt;i class=&#34;fas fa-info-circle&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;
Please note that we get a lot of emails from prospective PhD students, so Michael will not be able to respond to messages that aren&amp;rsquo;t clearly tailored to the lab&amp;rsquo;s vision.
You can make your application stand out by demonstrating that you have spent some time on our website, seen this message, and thought hard about why our lab is a good fit for your skills and interest.&lt;/small&gt;&lt;/p&gt;
&lt;h3 class=&#34;fill-with&#34;&gt;Undergraduate Research Positions for Winter 2023&lt;/h3&gt;
We have a limited number of RA positions available for Winter 2023 (e.g., via PSY-199 or CS-196):
&lt;ul&gt;
&lt;li&gt;Visual psychophysics: Assist in running behavioral studies with blind participants and sighted controls.&lt;/li&gt;
&lt;li&gt;Software engineering: Develop code/applications for &lt;a href=&#34;https://github.com/pulse2percept/pulse2percept&#34;&gt;pulse2percept&lt;/a&gt; (Python)&lt;/li&gt;
&lt;li&gt;Web development: Maintain and extend &lt;a href=&#34;https://www.bionic-vision.org&#34;&gt;bionic-vision.org&lt;/a&gt; (React, HTML, CSS, MongoDB)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In general, students stay for several quarters (one quarter is not enough to get up to speed) and work for academic credit.
Students should have a GPA of â‰¥ 3.0 (University requirement).
If you are interested, please &lt;a href=&#34;../people/beyeler_michael&#34;&gt;contact Michael&lt;/a&gt; with your prior experience and your transcript (unofficial is fine) and we can arrange a meeting.&lt;/p&gt;
&lt;h3 class=&#34;fill-width&#34;&gt;All Other Positions&lt;/h3&gt;
&lt;p&gt;We are completely full at the moment.&lt;/p&gt;
&lt;p&gt;We currently do not have any capacity to accommodate postdocs, exchange students, or interns&amp;mdash;be it over the summer or remote, at the graduate, undergraduate, or high school level.
Your email may therefore go unanswered.&lt;/p&gt;
&lt;p&gt;UCSB students interested in joining us in the future may want to keep an eye on the CS &lt;a href=&#34;https://cs.ucsb.edu/education/undergraduate/special-programs&#34; target=&#34;_blank&#34;&gt;DIMAP&lt;/a&gt; and &lt;a href=&#34;https://ersp.cs.ucsb.edu/&#34; target=&#34;_blank&#34;&gt;ERSP&lt;/a&gt; programs, PBS &lt;a href=&#34;https://psych.ucsb.edu/undergraduate/honors-program&#34; target=&#34;_blank&#34;&gt;Honors Program&lt;/a&gt;, or CoE &lt;a href=&#34;https://engineering.ucsb.edu/undergraduate/college-engineering-honors-program&#34; target=&#34;_blank&#34;&gt;Honors Program&lt;/a&gt;.&lt;/p&gt;
&lt;!--
&lt;h3 class=&#34;fill-width&#34;&gt;PhD Positions for Fall 2023&lt;/h3&gt;
We have a limited number of opportunities to join us as a PhD student in Fall 2023. The deadline is December 2022.
We are especially looking for:
1. &lt;a href=&#34;https://psych.ucsb.edu&#34; target=&#34;_blank&#34;&gt;PBS&lt;/a&gt;: Vision science students interested in working with real &lt;a href=&#34;https://bionicvisionlab.org/research/information-needs-blind-low-vision/&#34;&gt;low vision&lt;/a&gt; and &lt;a href=&#34;https://bionicvisionlab.org/research/predicting-visual-outcomes-visual-prostheses/&#34;&gt;bionic eye patients&lt;/a&gt;. You may run behavioral studies and/or develop computational models to further our understanding of the neural code of vision in health and disease. You don&#39;t need a CS background for this, but should have some experience with vision/cognition, psychophysics, and/or clinical populations.
2. &lt;a href=&#34;https://cs.ucsb.edu&#34; target=&#34;_blank&#34;&gt;CS&lt;/a&gt;/&lt;a href=&#34;https://ece.ucsb.edu&#34; target=&#34;_blank&#34;&gt;ECE&lt;/a&gt;: Computer vision (CV) / human-computer interaction (HCI) students interested in &lt;a href=&#34;https://bionicvisionlab.org/research/immersive-virtual-reality-simulations/&#34;&gt;VR/AR/XR&lt;/a&gt;, &lt;a href=&#34;https://bionicvisionlab.org/research/information-needs-blind-low-vision/&#34;&gt;assistive technologies&lt;/a&gt;, and/or &lt;a href=&#34;https://bionicvisionlab.org/research/event-based-vision/&#34;&gt;Edge AI&lt;/a&gt;. You may develop novel scene understanding algorithms, event-based CV systems, and/or prototypes of near-future accessibility aids. Your goal will be to publish at top-tier venues such as CVPR, CHI, ASSETS, or IEEE VR.
3. &lt;a href=&#34;https://dyns.ucsb.edu&#34; target=&#34;_blank&#34;&gt;DYNS&lt;/a&gt;/&lt;a href=&#34;https://ece.ucsb.edu&#34; target=&#34;_blank&#34;&gt;ECE&lt;/a&gt;/&lt;a href=&#34;https://bioengineering.ucsb.edu/academics/graduate&#34; target=&#34;_blank&#34;&gt;BIOE&lt;/a&gt;: Computational neuroscience students interested in &lt;a href=&#34;https://bionicvisionlab.org/research/event-based-vision/&#34;&gt;event-based vision&lt;/a&gt; and &lt;a href=&#34;https://bionicvisionlab.org/research/computational-models-visual-system/&#34;&gt;computational modeling&lt;/a&gt;. You may develop deep/spiking neural networks of visual cortex and/or work with neuromorphic platforms.
Please apply through the &lt;a href=&#34;https://www.graddiv.ucsb.edu/how-apply/application-and-admission-checklist&#34; target=&#34;_blank&#34;&gt;Grad Admissions Portal&lt;/a&gt;.
You will then be able to indicate your wish to work with us in the &#34;Major and Degree Objective&#34; tab under &#34;Faculty Interests&#34;. 
US citizens and permanent residents may apply for a &lt;a href=&#34;https://www.graddiv.ucsb.edu/how-apply/faqs-applicants#Graduate-Fee&#34;&gt;fee waiver&lt;/a&gt;.
&lt;h2&gt;Postdocs&lt;/h2&gt;
Please &lt;a href=&#34;../people/beyeler_michael&#34;&gt;contact Michael&lt;/a&gt; with your CV and a brief statement
of research accomplishments, interests, and career plans.
Although all applicants are welcome, we are especially looking for expertise at the intersection of computational neuroscience and data science. 
To be considered, you will need at least one publication 
in a high-quality international conference (computer science) 
or journal (neuroscience) 
and you need to have a reasonable chance of getting a fellowship
to support your stay at UCSB.
&lt;h3 class=&#34;fill-width&#34;&gt;PhD Students&lt;/h3&gt;
&lt;i class=&#34;fas fa-brain&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt; We are looking to fill an NIH-funded PhD position in computational neuroscience. The project involves developing computational and data-driven models of the mouse visual cortex in collaboration with Spencer Smith (UCSB), Michael Goard (UCSB), and Cris Niell (U Oregon). Best to apply through DYNS. &lt;a href=&#34;../people/beyeler_michael&#34;&gt;Contact Michael&lt;/a&gt; for more info.
For all other positions, please first apply to one of the following Graduate programs:
- &lt;a href=&#34;https://cs.ucsb.edu/education/grad/admissions&#34;&gt;Department of Computer Science (CS)&lt;/a&gt;:
  Best for people interested in obtaining a formal background in 
  human-computer interaction, computer vision, and/or machine learning.
- &lt;a href=&#34;https://psych.ucsb.edu/prospective-students-0&#34;&gt;Department of Psychological &amp; Brain Sciences (PBS)&lt;/a&gt;:
  best for vision science, psychology, cognition &amp; perception
- &lt;a href=&#34;https://ece.ucsb.edu&#34;&gt;Department of Electrical &amp; Computer Engineering (ECE)&lt;/a&gt;: best for brain-inspired computing and neuromorphic engineering
- &lt;a href=&#34;https://bioengineering.ucsb.edu/academics/graduate&#34;&gt;Graduate Program in Biological Engineering (BioE)&lt;/a&gt;: best for neural engineering and computational biology
- &lt;a href=&#34;https://www.dyns.ucsb.edu/graduate/admissions&#34;&gt;Graduate Program in Dynamical Neuroscience (DYNS)&lt;/a&gt;:
  best for computational neuroscience, computational vision, and brain-computer interfaces
You will then be able to indicate your wish to work with Michael in the &#34;Major and Degree Objective&#34; tab under 
&#34;Faculty Interests&#34;.
&lt;h3 class=&#34;fill-width&#34;&gt;CS/ECE Master&#39;s Students&lt;/h3&gt;
We have several MS positions available for Fall 2021:
We are looking for students interested in applying their methodological skills to research problems in bionic vision. 
- Human-computer interaction: Build VR/AR/XR applications applied to low vision and bionic vision (Unity, compute shaders, image processing, bionic vision simulations, eye tracking)
- Biomedical image analysis: Build predictive models applied to biomedical image datasets (registration, segmentation, self-supervised learning)- 
 - Computer vision: Build predictive models applied to biomedical image datasets (registration, segmentation,
  retinal fundus imaging, optical coherence tomography). 
 - Machine learning/data science: Build predictive models applied to real-world datasets collected on retinal prosthesis
  patients (classification, regression, time-series analysis, interpretable models, heterogeneous data). 
- Neuromorphic engineering: Build brain-inspired event-based vision systems applied to scene understanding (silicon retina, spiking neural networks)
 - Software engineering/parallel programming: Develop parallelization back ends for
  &lt;a href=&#34;https://githb.com/pulse2percept/pulse2percept&#34;&gt;pulse2percept&lt;/a&gt;, our open-source Python-based simulation 
  framework (Python, Cython, SciPy, OpenMP, GPGPU, JAX).
Please &lt;a href=&#34;../people/beyeler_michael&#34;&gt;contact Michael&lt;/a&gt; to set up a time to meet.
We are completely full. Please check back in December for Winter Quarter positions.
Typical responsibilities include one or more of the following:
- Assist in running behavioral studies (typically PSY-99 / 199)
- Develop applications for &lt;a href=&#34;https://githb.com/pulse2percept/pulse2percept&#34;&gt;pulse2percept&lt;/a&gt; (typically CS-196)
- Get hands-on research experience by shadowing a PhD student
- Process and analyze scientific data
- Perform literature reviews
- Attend weekly lab meetings and present once a quarter
&lt;h3 class=&#34;fill-width&#34;&gt;Undergraduate Students&lt;/h3&gt;
We currently do not have any capacity to accommodate postdocs, exchange students, or interns - be it over the summer or remote, at the graduate, undergraduate, or high school level.
--&gt;
&lt;p&gt;


&lt;div class=&#34;gallery2 caption-position-none caption-effect-slide hover-effect-zoom hover-transition&#34; itemscope itemtype=&#34;http://schema.org/ImageGallery&#34;&gt;
				&lt;div class=&#34;box&#34;&gt;
				  &lt;figure itemprop=&#34;associatedMedia&#34; itemscope itemtype=&#34;http://schema.org/ImageObject&#34;&gt;
				    &lt;div class=&#34;img&#34; style=&#34;background-image: url(&#39;https://bionicvisionlab.org/img/gallery//001-ersp.jpg&#39;);&#34; &gt;
				      &lt;img itemprop=&#34;thumbnail&#34; src=&#34;https://bionicvisionlab.org/img/gallery//001-ersp.jpg&#34; alt=&#34;001 ersp&#34; /&gt;
				    &lt;/div&gt;
			      &lt;figcaption&gt;
		          &lt;p&gt;001 ersp&lt;/p&gt;
			      &lt;/figcaption&gt;
				    &lt;a href=&#34;https://bionicvisionlab.org/img/gallery//001-ersp.jpg&#34; itemprop=&#34;contentUrl&#34;&gt;&lt;/a&gt;
				  &lt;/figure&gt;
				&lt;/div&gt;
				&lt;div class=&#34;box&#34;&gt;
				  &lt;figure itemprop=&#34;associatedMedia&#34; itemscope itemtype=&#34;http://schema.org/ImageObject&#34;&gt;
				    &lt;div class=&#34;img&#34; style=&#34;background-image: url(&#39;https://bionicvisionlab.org/img/gallery//002-cvs.jpg&#39;);&#34; &gt;
				      &lt;img itemprop=&#34;thumbnail&#34; src=&#34;https://bionicvisionlab.org/img/gallery//002-cvs.jpg&#34; alt=&#34;002 cvs&#34; /&gt;
				    &lt;/div&gt;
			      &lt;figcaption&gt;
		          &lt;p&gt;002 cvs&lt;/p&gt;
			      &lt;/figcaption&gt;
				    &lt;a href=&#34;https://bionicvisionlab.org/img/gallery//002-cvs.jpg&#34; itemprop=&#34;contentUrl&#34;&gt;&lt;/a&gt;
				  &lt;/figure&gt;
				&lt;/div&gt;
				&lt;div class=&#34;box&#34;&gt;
				  &lt;figure itemprop=&#34;associatedMedia&#34; itemscope itemtype=&#34;http://schema.org/ImageObject&#34;&gt;
				    &lt;div class=&#34;img&#34; style=&#34;background-image: url(&#39;https://bionicvisionlab.org/img/gallery//003-argus.jpg&#39;);&#34; &gt;
				      &lt;img itemprop=&#34;thumbnail&#34; src=&#34;https://bionicvisionlab.org/img/gallery//003-argus.jpg&#34; alt=&#34;003 argus&#34; /&gt;
				    &lt;/div&gt;
			      &lt;figcaption&gt;
		          &lt;p&gt;003 argus&lt;/p&gt;
			      &lt;/figcaption&gt;
				    &lt;a href=&#34;https://bionicvisionlab.org/img/gallery//003-argus.jpg&#34; itemprop=&#34;contentUrl&#34;&gt;&lt;/a&gt;
				  &lt;/figure&gt;
				&lt;/div&gt;
				&lt;div class=&#34;box&#34;&gt;
				  &lt;figure itemprop=&#34;associatedMedia&#34; itemscope itemtype=&#34;http://schema.org/ImageObject&#34;&gt;
				    &lt;div class=&#34;img&#34; style=&#34;background-image: url(&#39;https://bionicvisionlab.org/img/gallery//004-jacob.jpg&#39;);&#34; &gt;
				      &lt;img itemprop=&#34;thumbnail&#34; src=&#34;https://bionicvisionlab.org/img/gallery//004-jacob.jpg&#34; alt=&#34;004 jacob&#34; /&gt;
				    &lt;/div&gt;
			      &lt;figcaption&gt;
		          &lt;p&gt;004 jacob&lt;/p&gt;
			      &lt;/figcaption&gt;
				    &lt;a href=&#34;https://bionicvisionlab.org/img/gallery//004-jacob.jpg&#34; itemprop=&#34;contentUrl&#34;&gt;&lt;/a&gt;
				  &lt;/figure&gt;
				&lt;/div&gt;
				&lt;div class=&#34;box&#34;&gt;
				  &lt;figure itemprop=&#34;associatedMedia&#34; itemscope itemtype=&#34;http://schema.org/ImageObject&#34;&gt;
				    &lt;div class=&#34;img&#34; style=&#34;background-image: url(&#39;https://bionicvisionlab.org/img/gallery//005-michael.jpg&#39;);&#34; &gt;
				      &lt;img itemprop=&#34;thumbnail&#34; src=&#34;https://bionicvisionlab.org/img/gallery//005-michael.jpg&#34; alt=&#34;005 michael&#34; /&gt;
				    &lt;/div&gt;
			      &lt;figcaption&gt;
		          &lt;p&gt;005 michael&lt;/p&gt;
			      &lt;/figcaption&gt;
				    &lt;a href=&#34;https://bionicvisionlab.org/img/gallery//005-michael.jpg&#34; itemprop=&#34;contentUrl&#34;&gt;&lt;/a&gt;
				  &lt;/figure&gt;
				&lt;/div&gt;
				&lt;div class=&#34;box&#34;&gt;
				  &lt;figure itemprop=&#34;associatedMedia&#34; itemscope itemtype=&#34;http://schema.org/ImageObject&#34;&gt;
				    &lt;div class=&#34;img&#34; style=&#34;background-image: url(&#39;https://bionicvisionlab.org/img/gallery//006-vrst.jpg&#39;);&#34; &gt;
				      &lt;img itemprop=&#34;thumbnail&#34; src=&#34;https://bionicvisionlab.org/img/gallery//006-vrst.jpg&#34; alt=&#34;006 vrst&#34; /&gt;
				    &lt;/div&gt;
			      &lt;figcaption&gt;
		          &lt;p&gt;006 vrst&lt;/p&gt;
			      &lt;/figcaption&gt;
				    &lt;a href=&#34;https://bionicvisionlab.org/img/gallery//006-vrst.jpg&#34; itemprop=&#34;contentUrl&#34;&gt;&lt;/a&gt;
				  &lt;/figure&gt;
				&lt;/div&gt;
				&lt;div class=&#34;box&#34;&gt;
				  &lt;figure itemprop=&#34;associatedMedia&#34; itemscope itemtype=&#34;http://schema.org/ImageObject&#34;&gt;
				    &lt;div class=&#34;img&#34; style=&#34;background-image: url(&#39;https://bionicvisionlab.org/img/gallery//007-jason.jpg&#39;);&#34; &gt;
				      &lt;img itemprop=&#34;thumbnail&#34; src=&#34;https://bionicvisionlab.org/img/gallery//007-jason.jpg&#34; alt=&#34;007 jason&#34; /&gt;
				    &lt;/div&gt;
			      &lt;figcaption&gt;
		          &lt;p&gt;007 jason&lt;/p&gt;
			      &lt;/figcaption&gt;
				    &lt;a href=&#34;https://bionicvisionlab.org/img/gallery//007-jason.jpg&#34; itemprop=&#34;contentUrl&#34;&gt;&lt;/a&gt;
				  &lt;/figure&gt;
				&lt;/div&gt;
				&lt;div class=&#34;box&#34;&gt;
				  &lt;figure itemprop=&#34;associatedMedia&#34; itemscope itemtype=&#34;http://schema.org/ImageObject&#34;&gt;
				    &lt;div class=&#34;img&#34; style=&#34;background-image: url(&#39;https://bionicvisionlab.org/img/gallery//008-blind-pizza.png&#39;);&#34; &gt;
				      &lt;img itemprop=&#34;thumbnail&#34; src=&#34;https://bionicvisionlab.org/img/gallery//008-blind-pizza.png&#34; alt=&#34;008 blind pizza&#34; /&gt;
				    &lt;/div&gt;
			      &lt;figcaption&gt;
		          &lt;p&gt;008 blind pizza&lt;/p&gt;
			      &lt;/figcaption&gt;
				    &lt;a href=&#34;https://bionicvisionlab.org/img/gallery//008-blind-pizza.png&#34; itemprop=&#34;contentUrl&#34;&gt;&lt;/a&gt;
				  &lt;/figure&gt;
				&lt;/div&gt;
				&lt;div class=&#34;box&#34;&gt;
				  &lt;figure itemprop=&#34;associatedMedia&#34; itemscope itemtype=&#34;http://schema.org/ImageObject&#34;&gt;
				    &lt;div class=&#34;img&#34; style=&#34;background-image: url(&#39;https://bionicvisionlab.org/img/gallery//008-party.jpeg&#39;);&#34; &gt;
				      &lt;img itemprop=&#34;thumbnail&#34; src=&#34;https://bionicvisionlab.org/img/gallery//008-party.jpeg&#34; alt=&#34;008 party&#34; /&gt;
				    &lt;/div&gt;
			      &lt;figcaption&gt;
		          &lt;p&gt;008 party&lt;/p&gt;
			      &lt;/figcaption&gt;
				    &lt;a href=&#34;https://bionicvisionlab.org/img/gallery//008-party.jpeg&#34; itemprop=&#34;contentUrl&#34;&gt;&lt;/a&gt;
				  &lt;/figure&gt;
				&lt;/div&gt;
				&lt;div class=&#34;box&#34;&gt;
				  &lt;figure itemprop=&#34;associatedMedia&#34; itemscope itemtype=&#34;http://schema.org/ImageObject&#34;&gt;
				    &lt;div class=&#34;img&#34; style=&#34;background-image: url(&#39;https://bionicvisionlab.org/img/gallery//010-hike.jpg&#39;);&#34; &gt;
				      &lt;img itemprop=&#34;thumbnail&#34; src=&#34;https://bionicvisionlab.org/img/gallery//010-hike.jpg&#34; alt=&#34;010 hike&#34; /&gt;
				    &lt;/div&gt;
			      &lt;figcaption&gt;
		          &lt;p&gt;010 hike&lt;/p&gt;
			      &lt;/figcaption&gt;
				    &lt;a href=&#34;https://bionicvisionlab.org/img/gallery//010-hike.jpg&#34; itemprop=&#34;contentUrl&#34;&gt;&lt;/a&gt;
				  &lt;/figure&gt;
				&lt;/div&gt;
&lt;/div&gt;
 



  





&lt;link rel=&#34;stylesheet&#34; href=&#34;https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.1/photoswipe.min.css&#34; integrity=&#34;sha256-sCl5PUOGMLfFYctzDW3MtRib0ctyUvI9Qsmq2wXOeBY=&#34; crossorigin=&#34;anonymous&#34; /&gt;
&lt;link rel=&#34;stylesheet&#34; href=&#34;https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.1/default-skin/default-skin.min.css&#34; integrity=&#34;sha256-BFeI1V+Vh1Rk37wswuOYn5lsTcaU96hGaI7OUVCLjPc=&#34; crossorigin=&#34;anonymous&#34; /&gt;



&lt;div class=&#34;pswp&#34; tabindex=&#34;-1&#34; role=&#34;dialog&#34; aria-hidden=&#34;true&#34;&gt;

&lt;div class=&#34;pswp__bg&#34;&gt;&lt;/div&gt;

&lt;div class=&#34;pswp__scroll-wrap&#34;&gt;
    
    &lt;div class=&#34;pswp__container&#34;&gt;
      &lt;div class=&#34;pswp__item&#34;&gt;&lt;/div&gt;
      &lt;div class=&#34;pswp__item&#34;&gt;&lt;/div&gt;
      &lt;div class=&#34;pswp__item&#34;&gt;&lt;/div&gt;
    &lt;/div&gt;
    
    &lt;div class=&#34;pswp__ui pswp__ui--hidden&#34;&gt;
    &lt;div class=&#34;pswp__top-bar&#34;&gt;
      
      &lt;div class=&#34;pswp__counter&#34;&gt;&lt;/div&gt;
      &lt;button class=&#34;pswp__button pswp__button--close&#34; title=&#34;Close (Esc)&#34;&gt;&lt;/button&gt;
      &lt;button class=&#34;pswp__button pswp__button--share&#34; title=&#34;Share&#34;&gt;&lt;/button&gt;
      &lt;button class=&#34;pswp__button pswp__button--fs&#34; title=&#34;Toggle fullscreen&#34;&gt;&lt;/button&gt;
      &lt;button class=&#34;pswp__button pswp__button--zoom&#34; title=&#34;Zoom in/out&#34;&gt;&lt;/button&gt;
      
      
      &lt;div class=&#34;pswp__preloader&#34;&gt;
        &lt;div class=&#34;pswp__preloader__icn&#34;&gt;
          &lt;div class=&#34;pswp__preloader__cut&#34;&gt;
            &lt;div class=&#34;pswp__preloader__donut&#34;&gt;&lt;/div&gt;
          &lt;/div&gt;
        &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;div class=&#34;pswp__share-modal pswp__share-modal--hidden pswp__single-tap&#34;&gt;
      &lt;div class=&#34;pswp__share-tooltip&#34;&gt;&lt;/div&gt;
    &lt;/div&gt;
    &lt;button class=&#34;pswp__button pswp__button--arrow--left&#34; title=&#34;Previous (arrow left)&#34;&gt;
    &lt;/button&gt;
    &lt;button class=&#34;pswp__button pswp__button--arrow--right&#34; title=&#34;Next (arrow right)&#34;&gt;
    &lt;/button&gt;
    &lt;div class=&#34;pswp__caption&#34;&gt;
      &lt;div class=&#34;pswp__caption__center&#34;&gt;&lt;/div&gt;
    &lt;/div&gt;
    &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>People</title>
      <link>https://bionicvisionlab.org/people/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bionicvisionlab.org/people/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Recent &amp; Upcoming Talks</title>
      <link>https://bionicvisionlab.org/talk/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bionicvisionlab.org/talk/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
