[{"categories":null,"content":"Anvitha Akkaraju is an undergraduate student in the Department of Psychological and Brain Sciences at the University of California, Santa Barbara.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"c5af182f990d49f86f3deb07078e8356","people":["akkaraju_anvitha"],"permalink":"https://bionicvisionlab.org/people/akkaraju_anvitha/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/akkaraju_anvitha/","section":"people","summary":"Anvitha Akkaraju is an undergraduate student in the Department of Psychological and Brain Sciences at the University of California, Santa Barbara.","title":"Anvitha Akkaraju","type":"people"},{"categories":null,"content":"Sriya Aluru is currently a third-year undergraduate student pursuing a Computer Science degree at UC Santa Barbara, and a scholar in the Early Research Scholars Program (ERSP). She is interested in Deep Learning and Computational Neuroscience.\nShe loves hanging out at the beach, trying new places to eat, and playing tennis.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"75ca39b6f5d02c0a47dc6ae65f00afce","people":["aluru_sriya"],"permalink":"https://bionicvisionlab.org/people/aluru_sriya/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/aluru_sriya/","section":"people","summary":"Sriya Aluru is currently a third-year undergraduate student pursuing a Computer Science degree at UC Santa Barbara, and a scholar in the Early Research Scholars Program (ERSP). She is interested in Deep Learning and Computational Neuroscience.\nShe loves hanging out at the beach, trying new places to eat, and playing tennis.","title":"Sriya Aluru","type":"people"},{"categories":null,"content":"Nick Arenberg is currently a fourth-year undergraduate student pursuing a Computer Science degree at UC Santa Barbara. He is working on improving pulse2percept with new features an optimizations and is interested in scientific computing and software engineering.\nWhen he is not coding, he enjoys playing ice hockey on the UCSB club team, going to concerts, and cooking.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"d616a087baa15a70203ad0a08838ad76","people":["arenberg_nick"],"permalink":"https://bionicvisionlab.org/people/arenberg_nick/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/arenberg_nick/","section":"people","summary":"Nick Arenberg is currently a fourth-year undergraduate student pursuing a Computer Science degree at UC Santa Barbara. He is working on improving pulse2percept with new features an optimizations and is interested in scientific computing and software engineering.\nWhen he is not coding, he enjoys playing ice hockey on the UCSB club team, going to concerts, and cooking.","title":"Nick Arenberg","type":"people"},{"categories":null,"content":"Michael Beyeler directs the Bionic Vision Lab at UC Santa Barbara.\nHe received a PhD in Computer Science from UC Irvine as well as a BS in Electrical Engineering and a MS in Biomedical Engineering from ETH Zurich, Switzerland. Prior to joining UCSB in 2019, he completed a postdoctoral fellowship in the labs of Ione Fine (Psychology, Institute for Neuroengineering) and Ariel Rokem (eScience Institute) at the University of Washington, where he developed computational models of bionic vision.\nHe is Associate Director of the UCSB Center for Virtual Environments and Behavior (ReCVEB) and recipient of the National Institutes of Health (NIH) K99/R00 Pathway to Independence Award.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"9b65f6e0cdcdd6af799cdb43ac4127dc","people":["beyeler_michael"],"permalink":"https://bionicvisionlab.org/people/beyeler_michael/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/beyeler_michael/","section":"people","summary":"Michael Beyeler directs the Bionic Vision Lab at UC Santa Barbara.\nHe received a PhD in Computer Science from UC Irvine as well as a BS in Electrical Engineering and a MS in Biomedical Engineering from ETH Zurich, Switzerland. Prior to joining UCSB in 2019, he completed a postdoctoral fellowship in the labs of Ione Fine (Psychology, Institute for Neuroengineering) and Ariel Rokem (eScience Institute) at the University of Washington, where he developed computational models of bionic vision.","title":"Michael Beyeler","type":"people"},{"categories":null,"content":"Tanya Bhatia is an undergraduate research assistant pursuing a degree in biopsychology. She is interested in better understanding and improving the perceptual experience of sight recovery patients and the clinical applications of computational neuroscience.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"e491fe74ed0afc731854c9e3938782af","people":["bhatia_tanya"],"permalink":"https://bionicvisionlab.org/people/bhatia_tanya/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/bhatia_tanya/","section":"people","summary":"Tanya Bhatia is an undergraduate research assistant pursuing a degree in biopsychology. She is interested in better understanding and improving the perceptual experience of sight recovery patients and the clinical applications of computational neuroscience.","title":"Tanya Bhatia","type":"people"},{"categories":null,"content":"Alec Bodolay is currently a fourth-year undergraduate student pursuing a Biopsychology degree at UC Santa Barbara.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"837fee71f92061b7b1b273e744bab34b","people":["bodolay_alec"],"permalink":"https://bionicvisionlab.org/people/bodolay_alec/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/bodolay_alec/","section":"people","summary":"Alec Bodolay is currently a fourth-year undergraduate student pursuing a Biopsychology degree at UC Santa Barbara.","title":"Alec Bodolay","type":"people"},{"categories":null,"content":"Ashley is currently a Master\u0026rsquo;s Student in the Computer Science Department at UC Santa Barbara. She graduated with her Bachelor\u0026rsquo;s in Biology at Cal Poly San Luis Obispo in 2019 and her Associate\u0026rsquo;s in Computer Science at Cuesta College in 2020.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"ed0dcb12899df28a672a05c404e320e5","people":["bruce_ashley"],"permalink":"https://bionicvisionlab.org/people/bruce_ashley/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/bruce_ashley/","section":"people","summary":"Ashley is currently a Master\u0026rsquo;s Student in the Computer Science Department at UC Santa Barbara. She graduated with her Bachelor\u0026rsquo;s in Biology at Cal Poly San Luis Obispo in 2019 and her Associate\u0026rsquo;s in Computer Science at Cuesta College in 2020.","title":"Ashley Bruce","type":"people"},{"categories":null,"content":"Alexander Chau is currently a first-year undergraduate student pursuing a Computer Science degree at UC Santa Barbara.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"4fe46f4f4748ba0aa777bed26fa7ec73","people":["chau_alexander"],"permalink":"https://bionicvisionlab.org/people/chau_alexander/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/chau_alexander/","section":"people","summary":"Alexander Chau is currently a first-year undergraduate student pursuing a Computer Science degree at UC Santa Barbara.","title":"Alexander Chau","type":"people"},{"categories":null,"content":"Lauren Eckhardt is currently a third-year undergraduate student pursuing a Biopsychology degree at UC Santa Barbara. She is interested in neuroprosthetics and computational neuroscience. In her free time, she enjoys hiking, camping and reading.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"021192d2b27d8ad6ab49ed5efe365814","people":["eckhardt_lauren"],"permalink":"https://bionicvisionlab.org/people/eckhardt_lauren/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/eckhardt_lauren/","section":"people","summary":"Lauren Eckhardt is currently a third-year undergraduate student pursuing a Biopsychology degree at UC Santa Barbara. She is interested in neuroprosthetics and computational neuroscience. In her free time, she enjoys hiking, camping and reading.","title":"Lauren Eckhardt","type":"people"},{"categories":null,"content":"Harshita Gangaswamy is currently a second-year undergraduate student pursuing a Computer Engineering degree at UC Santa Barbara, and a scholar in the Early Research Scholars Program (ERSP). She is interested in deep learning and computational neuroscience.\nWhen she is not studying and doing research, she enjoys reading novels and watching TV shows with her roommates and friends. She has also been volunteering to teach kids through the Society of Women Engineers.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"81655537f54e185163d76eaa9966c64b","people":["gangaswamy_harshita"],"permalink":"https://bionicvisionlab.org/people/gangaswamy_harshita/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/gangaswamy_harshita/","section":"people","summary":"Harshita Gangaswamy is currently a second-year undergraduate student pursuing a Computer Engineering degree at UC Santa Barbara, and a scholar in the Early Research Scholars Program (ERSP). She is interested in deep learning and computational neuroscience.\nWhen she is not studying and doing research, she enjoys reading novels and watching TV shows with her roommates and friends. She has also been volunteering to teach kids through the Society of Women Engineers.","title":"Harshita Gangaswamy","type":"people"},{"categories":null,"content":"Robert Gee is currently a third-year undergraduate student pursuing a Computer Science degree at UC Santa Barbara.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"10a9844ffc0e0f520fe6d86a331a8dcb","people":["gee_robert"],"permalink":"https://bionicvisionlab.org/people/gee_robert/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/gee_robert/","section":"people","summary":"Robert Gee is currently a third-year undergraduate student pursuing a Computer Science degree at UC Santa Barbara.","title":"Robert Gee","type":"people"},{"categories":null,"content":"Anand Giduthuri is currently a second-year undergraduate student pursuing a Computer Science degree at UC Santa Barbara. His interests include computer vision and deep learning.\nIn his free time, he likes to spend time at the beach and play badminton.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"7aa3af6bf78e84b324fcf54bb809ffc9","people":["giduthuri_anand"],"permalink":"https://bionicvisionlab.org/people/giduthuri_anand/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/giduthuri_anand/","section":"people","summary":"Anand Giduthuri is currently a second-year undergraduate student pursuing a Computer Science degree at UC Santa Barbara. His interests include computer vision and deep learning.\nIn his free time, he likes to spend time at the beach and play badminton.","title":"Anand Giduthuri","type":"people"},{"categories":null,"content":"Jacob Granley is a PhD student in the Department of Computer Science.\nPrior to joining UCSB, he received his Masters and Bachelors in Computer Science from Colorado School of Mines. He is pursuing his PhD under Dr. Beyeler as part of the Bionic Vision lab, where he hopes to use Computer Science and Machine Learning methods to help improve artificial vision technologies with the ultimate goal of restoring sight to the blind.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2b70b8d79cd7bf947cd51020510152a3","people":["granley_jacob"],"permalink":"https://bionicvisionlab.org/people/granley_jacob/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/granley_jacob/","section":"people","summary":"Jacob Granley is a PhD student in the Department of Computer Science.\nPrior to joining UCSB, he received his Masters and Bachelors in Computer Science from Colorado School of Mines. He is pursuing his PhD under Dr. Beyeler as part of the Bionic Vision lab, where he hopes to use Computer Science and Machine Learning methods to help improve artificial vision technologies with the ultimate goal of restoring sight to the blind.","title":"Jacob Granley","type":"people"},{"categories":null,"content":"Elaine Ho is currently a first-year undergraduate student pursuing a Computer Science degree at UC Santa Barbara.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"fd26ca538c8b2a588ceb0ed0194d7d71","people":["ho_elaine"],"permalink":"https://bionicvisionlab.org/people/ho_elaine/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/ho_elaine/","section":"people","summary":"Elaine Ho is currently a first-year undergraduate student pursuing a Computer Science degree at UC Santa Barbara.","title":"Elaine Ho","type":"people"},{"categories":null,"content":"Yuchen Hou is a project scientist in the Bionic Vision Lab with a BS in Psychological \u0026amp; Brain Scieces from UCSB.\nIn Fall 2022, she will continue in the Bionic Vision Lab as a PhD student in Computer Science.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"e3745716f7ad68c766108f2e2cbeefef","people":["hou_yuchen"],"permalink":"https://bionicvisionlab.org/people/hou_yuchen/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/hou_yuchen/","section":"people","summary":"Yuchen Hou is a project scientist in the Bionic Vision Lab with a BS in Psychological \u0026amp; Brain Scieces from UCSB.\nIn Fall 2022, she will continue in the Bionic Vision Lab as a PhD student in Computer Science.","title":"Yuchen Hou","type":"people"},{"categories":null,"content":"Rutvik Jha is currently a third-year undergraduate student pursuing a Computer Engineering degree at UC Santa Barbara. He is working on event-based deep learning models and is interested in deploying cutting-edge deep learning techniques.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"ec846e9abe7f970e345ae3ba38d1424b","people":["jha_rutvik"],"permalink":"https://bionicvisionlab.org/people/jha_rutvik/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/jha_rutvik/","section":"people","summary":"Rutvik Jha is currently a third-year undergraduate student pursuing a Computer Engineering degree at UC Santa Barbara. He is working on event-based deep learning models and is interested in deploying cutting-edge deep learning techniques.","title":"Rutvik Jha","type":"people"},{"categories":null,"content":"Byron is a PhD student in the Department of Psychological \u0026amp; Brain Sciences. He was born and raised in St. Louis, Missouri. He moved to New York City to study psychology, where he received a BA in Psychology from St. John’s University (2015) and then a MA in Behavioral Neuroscience from Queens College (2017). Byron worked as a Research Operations Manager at a start-up company that develops assistive products for blind and low vision individuals (2017 - 2020).\nByron\u0026rsquo;s main research interest is studying how image processing and psychophysics can be used to understand how low vision conditions affect visual tasks. Specifically, how combining computational models with simulated low vision impairment conditions can help inform and enhance individualized vision capabilities.\nByron is supervised by Dr. Michael Beyeler in the Bionic Vision Lab and Dr. Miguel Eckstein in the Vision and Image Understanding Lab.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"226dccd548b210ce20689586bc7b8aba","people":["johnson_byron"],"permalink":"https://bionicvisionlab.org/people/johnson_byron/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/johnson_byron/","section":"people","summary":"Byron is a PhD student in the Department of Psychological \u0026amp; Brain Sciences. He was born and raised in St. Louis, Missouri. He moved to New York City to study psychology, where he received a BA in Psychology from St. John’s University (2015) and then a MA in Behavioral Neuroscience from Queens College (2017). Byron worked as a Research Operations Manager at a start-up company that develops assistive products for blind and low vision individuals (2017 - 2020).","title":"Byron A. Johnson","type":"people"},{"categories":null,"content":"Wayne Johnson is currently a third-year undergraduate student pursuing a Psychological \u0026amp; Brain Sciences degree at UC Santa Barbara. He is working on how people\u0026rsquo;s perceptions change when encountered with first or second hand information from society and is interested in going to graduate school for psychology.\nWhen he is not doing major university stuff, he enjoys having fun making music, reading, sports and his favorite food is Italian. He has also been volunteering with the democratic grassroots foundation canvassing / phone banking and making donations to his old community college.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"4c6ea83f5017ca02fc7a76079b1c87d0","people":["johnson_wayne"],"permalink":"https://bionicvisionlab.org/people/johnson_wayne/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/johnson_wayne/","section":"people","summary":"Wayne Johnson is currently a third-year undergraduate student pursuing a Psychological \u0026amp; Brain Sciences degree at UC Santa Barbara. He is working on how people\u0026rsquo;s perceptions change when encountered with first or second hand information from society and is interested in going to graduate school for psychology.\nWhen he is not doing major university stuff, he enjoys having fun making music, reading, sports and his favorite food is Italian. He has also been volunteering with the democratic grassroots foundation canvassing / phone banking and making donations to his old community college.","title":"Wayne D. Johnson","type":"people"},{"categories":null,"content":"Justin Kasowksi transferred to UC Santa Barbara in 2016 after receiving associates degrees in Biological Sciences and Chemistry from Santa Barbara City College. In 2018, he graduated UCSB with a degree in Molecular, Cellular, and Developmental Biology.\nHe is pursuing his PhD under Dr. Michael Beyeler in the Bionic Vision Lab, where he utilizes virtual reality and computer vision to model the perceptual experience of retinal prosthesis patients.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"25e494b70e3d83523af0ee2774cf00aa","people":["kasowski_justin"],"permalink":"https://bionicvisionlab.org/people/kasowski_justin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/kasowski_justin/","section":"people","summary":"Justin Kasowksi transferred to UC Santa Barbara in 2016 after receiving associates degrees in Biological Sciences and Chemistry from Santa Barbara City College. In 2018, he graduated UCSB with a degree in Molecular, Cellular, and Developmental Biology.\nHe is pursuing his PhD under Dr. Michael Beyeler in the Bionic Vision Lab, where he utilizes virtual reality and computer vision to model the perceptual experience of retinal prosthesis patients.","title":"Justin Kasowski","type":"people"},{"categories":null,"content":"Anderson Liu is currently a first-year undergraduate student pursuing a Computer Science degree at UC Santa Barbara. He is interested in applications of game development for the benefit of society.\nIn his free time, he enjoys playing badminton.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"627783e0c057cdab431b1e19162502e4","people":["liu_anderson"],"permalink":"https://bionicvisionlab.org/people/liu_anderson/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/liu_anderson/","section":"people","summary":"Anderson Liu is currently a first-year undergraduate student pursuing a Computer Science degree at UC Santa Barbara. He is interested in applications of game development for the benefit of society.\nIn his free time, he enjoys playing badminton.","title":"Anderson Liu","type":"people"},{"categories":null,"content":"Ananth Mahes is an undergraduate student pursuing a degree in Biopsychology at the University of California, Santa Barbara.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"c5bbeb3a42a7419d3b0df805a71922b2","people":["mahes_ananth"],"permalink":"https://bionicvisionlab.org/people/mahes_ananth/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/mahes_ananth/","section":"people","summary":"Ananth Mahes is an undergraduate student pursuing a degree in Biopsychology at the University of California, Santa Barbara.","title":"Ananth Mahes","type":"people"},{"categories":null,"content":"Sahil Naik is currently a third-year undergraduate student pursuing a Computer Engineering degree at UC Santa Barbara. He is currently interested in Computational Neuroscience and Artificial Intelligence but hopes to delve more into deep learning in the future. He also really loves the beach and beach games like die and spikeball.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"557653db966b2d3531471d2469543fa0","people":["naik_sahil"],"permalink":"https://bionicvisionlab.org/people/naik_sahil/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/naik_sahil/","section":"people","summary":"Sahil Naik is currently a third-year undergraduate student pursuing a Computer Engineering degree at UC Santa Barbara. He is currently interested in Computational Neuroscience and Artificial Intelligence but hopes to delve more into deep learning in the future. He also really loves the beach and beach games like die and spikeball.","title":"Sahil Naik","type":"people"},{"categories":null,"content":"Ryan Neydavood is a staff scientist, research coordinator, and lab manager of the Bionic Vision Lab.\nHe graduated from UC Santa Barbara in 2021 with a degree in Psychology \u0026amp; Brain Sciences. He was born and raised in Los Angeles, California where he developed a commitment to healthcare. Ryan is interested in Virtual Reality, neurophysiology, and advancing the field of bionic vision to help cure blindness.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"07bcf61e83804b1777afd8d80daa4116","people":["neydavood_ryan"],"permalink":"https://bionicvisionlab.org/people/neydavood_ryan/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/neydavood_ryan/","section":"people","summary":"Ryan Neydavood is a staff scientist, research coordinator, and lab manager of the Bionic Vision Lab.\nHe graduated from UC Santa Barbara in 2021 with a degree in Psychology \u0026amp; Brain Sciences. He was born and raised in Los Angeles, California where he developed a commitment to healthcare. Ryan is interested in Virtual Reality, neurophysiology, and advancing the field of bionic vision to help cure blindness.","title":"Ryan Neydavood","type":"people"},{"categories":null,"content":"Bill Nguyen is an undergraduate student in the Departments of Psychological \u0026amp; Brain Sciences (PBS) and Mathematics at UC Santa Barbara. He is interested in the exciting potential of neural prostheses, both on a technological and clinical level.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"88921ab62b48dba707e97e967eaf728b","people":["nguyen_bill"],"permalink":"https://bionicvisionlab.org/people/nguyen_bill/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/nguyen_bill/","section":"people","summary":"Bill Nguyen is an undergraduate student in the Departments of Psychological \u0026amp; Brain Sciences (PBS) and Mathematics at UC Santa Barbara. He is interested in the exciting potential of neural prostheses, both on a technological and clinical level.","title":"Bill Nguyen","type":"people"},{"categories":null,"content":"Alex Rasla is currently a first-year graduate student in the B.S/M.S. program pursuing a Computer Science degree at UC Santa Barbara. He is interested in Machine Learning, Computer Vision, AR/VR, and autonomous systems.\nIn his free time, Alex enjoys playing the piano or guitar, and producing music. Some of his other hobbies include hanging out at the beach, reading books, and playing sports. Once he graduates, Alex wants to work for a company that makes the world a better place.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"6070452bd4da4b5fcb8adc841079aee1","people":["rasla_alex"],"permalink":"https://bionicvisionlab.org/people/rasla_alex/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/rasla_alex/","section":"people","summary":"Alex Rasla is currently a first-year graduate student in the B.S/M.S. program pursuing a Computer Science degree at UC Santa Barbara. He is interested in Machine Learning, Computer Vision, AR/VR, and autonomous systems.\nIn his free time, Alex enjoys playing the piano or guitar, and producing music. Some of his other hobbies include hanging out at the beach, reading books, and playing sports. Once he graduates, Alex wants to work for a company that makes the world a better place.","title":"Alex Rasla","type":"people"},{"categories":null,"content":"Lucas Relic is currently a Master\u0026rsquo;s Student in the Computer Science Department at UC Santa Barbara.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"bfc44800677d9bfa49cce9601ec58c3c","people":["relic_lucas"],"permalink":"https://bionicvisionlab.org/people/relic_lucas/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/relic_lucas/","section":"people","summary":"Lucas Relic is currently a Master\u0026rsquo;s Student in the Computer Science Department at UC Santa Barbara.","title":"Lucas Relic","type":"people"},{"categories":null,"content":"Vanessa Salgado is currently a fourth-year undergraduate student pursuing a Computer Science degree at UC Santa Barbara. She is interested Data Science, Deep Learning, and Neural Networks.\nIn her free time, she loves rock climbing and spending time outdoors with her friends. Her hobbies include reading memoirs, trying new restaurants, and discovering new music. After graduation, Vanessa would like to use technology for social good.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"59bb1b4c87c6d4d9361e037402a8e891","people":["salgado_vanessa"],"permalink":"https://bionicvisionlab.org/people/salgado_zavaleta_vanessa/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/salgado_zavaleta_vanessa/","section":"people","summary":"Vanessa Salgado is currently a fourth-year undergraduate student pursuing a Computer Science degree at UC Santa Barbara. She is interested Data Science, Deep Learning, and Neural Networks.\nIn her free time, she loves rock climbing and spending time outdoors with her friends. Her hobbies include reading memoirs, trying new restaurants, and discovering new music. After graduation, Vanessa would like to use technology for social good.","title":"Vanessa Salgado Zavaleta","type":"people"},{"categories":null,"content":"Melani Sanchez Garica is a Postdoctoral Researcher in the Department of Computer Science at UCSB.\nPrior to joining UCSB, she received a PhD in Computer Science and Systems Engineering from Universidad de Zaragoza, Spain, as well as a BS in Chemical Engineering and a MS in Chemical Engineering from Universidad de Valencia, Spain.\nMelani\u0026rsquo;s main research interests lie in Computer Vision and Deep Learning. She is particularly excited about conducting research in simulated prosthetic vision (SPV) and building immersive virtual reality (VR) systems of SPV that combine computational modeling of the brain with different computer vision algorithms.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"637086ab4079efde6e99acb8b3f374e2","people":["sanchez_garcia_melani"],"permalink":"https://bionicvisionlab.org/people/sanchez_garcia_melani/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/sanchez_garcia_melani/","section":"people","summary":"Melani Sanchez Garica is a Postdoctoral Researcher in the Department of Computer Science at UCSB.\nPrior to joining UCSB, she received a PhD in Computer Science and Systems Engineering from Universidad de Zaragoza, Spain, as well as a BS in Chemical Engineering and a MS in Chemical Engineering from Universidad de Valencia, Spain.\nMelani\u0026rsquo;s main research interests lie in Computer Vision and Deep Learning. She is particularly excited about conducting research in simulated prosthetic vision (SPV) and building immersive virtual reality (VR) systems of SPV that combine computational modeling of the brain with different computer vision algorithms.","title":"Melani Sanchez Garcia","type":"people"},{"categories":null,"content":"Shivani Sista is currently a second-year undergraduate student pursuing a Computer Science degree at UC Santa Barbara, and a scholar in the Early Research Scholars Program (ERSP). She is interested in deep learning, computer vision, and computational neuroscience. In her free time, she enjoys playing the violin, drawing, and watching TV.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"81521c50bd2e2b502a681b810531ee5a","people":["sista_shivani"],"permalink":"https://bionicvisionlab.org/people/sista_shivani/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/sista_shivani/","section":"people","summary":"Shivani Sista is currently a second-year undergraduate student pursuing a Computer Science degree at UC Santa Barbara, and a scholar in the Early Research Scholars Program (ERSP). She is interested in deep learning, computer vision, and computational neuroscience. In her free time, she enjoys playing the violin, drawing, and watching TV.","title":"Shivani Sista","type":"people"},{"categories":null,"content":"Madori Spiker is a MS student in Computer Science at UC Santa Barbara.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"16a892356347222eb5ddec17b1eca141","people":["spiker_madori"],"permalink":"https://bionicvisionlab.org/people/spiker_madori/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/spiker_madori/","section":"people","summary":"Madori Spiker is a MS student in Computer Science at UC Santa Barbara.","title":"Madori Spiker","type":"people"},{"categories":null,"content":"Gita Supramaniam is currently a second-year undergraduate student pursuing a Computer Science degree at UC Santa Barbara.\nIn her free time, she enjoys reading and going on walks.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"06ff86945e97b58a6925161ae5f82ff8","people":["supramaniam_gita"],"permalink":"https://bionicvisionlab.org/people/supramaniam_gita/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/supramaniam_gita/","section":"people","summary":"Gita Supramaniam is currently a second-year undergraduate student pursuing a Computer Science degree at UC Santa Barbara.\nIn her free time, she enjoys reading and going on walks.","title":"Gita Supramaniam","type":"people"},{"categories":null,"content":"Eyob Teshome is currently a first-year undergraduate student pursuing a Computer Science degree at UC Santa Barbara. He is a Black Researchers Advancing Intelligence in Neurocomputation (BRAIN) Scholar, and is interested in Artificial Intelligence, Virtual Reality, and Computer Vision.\nWhen he is not studying in the library, he enjoys working out, playing soccer, and watching movies with his friends.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"c0df3d356bd8facfcee0b6383efe5e95","people":["teshome_eyob"],"permalink":"https://bionicvisionlab.org/people/teshome_eyob/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/teshome_eyob/","section":"people","summary":"Eyob Teshome is currently a first-year undergraduate student pursuing a Computer Science degree at UC Santa Barbara. He is a Black Researchers Advancing Intelligence in Neurocomputation (BRAIN) Scholar, and is interested in Artificial Intelligence, Virtual Reality, and Computer Vision.\nWhen he is not studying in the library, he enjoys working out, playing soccer, and watching movies with his friends.","title":"Eyob Teshome","type":"people"},{"categories":null,"content":"Lexie Van Os is currently a third-year undergraduate student pursuing Psychological \u0026amp; Brain Sciences and Communication degrees at UC Santa Barbara. She is interested cognitive neuroscience.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"f61141d4798607fc199ee7654bee7e2c","people":["vanos_lexie"],"permalink":"https://bionicvisionlab.org/people/vanos_lexie/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/vanos_lexie/","section":"people","summary":"Lexie Van Os is currently a third-year undergraduate student pursuing Psychological \u0026amp; Brain Sciences and Communication degrees at UC Santa Barbara. She is interested cognitive neuroscience.","title":"Lexie Van Os","type":"people"},{"categories":null,"content":"Apurv Varshney is currently a first-year graduate student pursuing a Master\u0026rsquo;s in Computer Science degree at UC Santa Barbara. He is interested in improving Bionic Vision using Computer vision and human computer interaction (HCI) techniques. In his free time he enjoys hiking and playing Tennis.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"283fe3910514662d9abab07376970c6f","people":["varshney_apurv"],"permalink":"https://bionicvisionlab.org/people/varshney_apurv/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/varshney_apurv/","section":"people","summary":"Apurv Varshney is currently a first-year graduate student pursuing a Master\u0026rsquo;s in Computer Science degree at UC Santa Barbara. He is interested in improving Bionic Vision using Computer vision and human computer interaction (HCI) techniques. In his free time he enjoys hiking and playing Tennis.","title":"Apurv Varshney","type":"people"},{"categories":null,"content":"Francie Wei is currently a fourth-year undergraduate student pursuing a Computer Science degree at UC Santa Barbara. She is interested in machine learning behind artificial vision.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"58bc915d1d9d4f5a8a3a730dbb259dc1","people":["wei_francie"],"permalink":"https://bionicvisionlab.org/people/wei_francie/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/wei_francie/","section":"people","summary":"Francie Wei is currently a fourth-year undergraduate student pursuing a Computer Science degree at UC Santa Barbara. She is interested in machine learning behind artificial vision.","title":"Francie Wei","type":"people"},{"categories":null,"content":"Aiwen Xu is a PhD student in Computer Science. Prior to UC Santa Barbara, she received a BS in Computer Science and a BS in Mathematics from New York University Shanghai. She hopes to utilize mathematical modeling and machine learning techniques to improve bionic vision.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"8f8cb324f0e2fc7e16448789c3667a8d","people":["xu_aiwen"],"permalink":"https://bionicvisionlab.org/people/xu_aiwen/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/xu_aiwen/","section":"people","summary":"Aiwen Xu is a PhD student in Computer Science. Prior to UC Santa Barbara, she received a BS in Computer Science and a BS in Mathematics from New York University Shanghai. She hopes to utilize mathematical modeling and machine learning techniques to improve bionic vision.","title":"Aiwen Xu","type":"people"},{"categories":null,"content":"More info coming soon.\n","date":1672531200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672531200,"objectID":"a3783704b1256bf2f3b35b18c927cff4","people":null,"permalink":"https://bionicvisionlab.org/teaching/2023-winter-cs281b/","publishdate":"2023-01-01T00:00:00Z","relpermalink":"/teaching/2023-winter-cs281b/","section":"teaching","summary":"Overview of computer vision problems and techniques for analyzing the content of images and video. Topics include image formation, edge detection, image segmentation, pattern recognition, texture analysis, optical flow, stereo vision, shape representation and recovery techniques, issues in object recognition, and case studies of practical vision systems.","title":"CS/ECE-281B: Advanced Topics in Computer Vision","type":"teaching"},{"categories":null,"content":"Same course as ECE 181. Not open for credit to students who have completed ECE/CMPSC 181B with a grade of C or better. ECE/CMPSC 181 is a legal repeat of ECE/CMPSC 181B.\nPrerequisites: Upper-division standing in Electrical Engineering, Computer Engineering, Computer Science, Chemical Engineering or Mechanical Engineering.\n","date":1661990400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1661990400,"objectID":"7981ea9f46ce9dd391990a2500d6bc97","people":null,"permalink":"https://bionicvisionlab.org/teaching/2022-fall-cs181/","publishdate":"2022-09-01T00:00:00Z","relpermalink":"/teaching/2022-fall-cs181/","section":"teaching","summary":"Overview of computer vision problems and techniques for analyzing the content of images and video. Topics include image formation, edge detection, image segmentation, pattern recognition, texture analysis, optical flow, stereo vision, shape representation and recovery techniques, issues in object recognition, and case studies of practical vision systems.","title":"CS/ECE-181: Introduction to Computer Vision","type":"teaching"},{"categories":null,"content":"","date":1646611200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1646611200,"objectID":"de0a79fb350159a76ada48eff10bef7b","people":["Lucas Relic","Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2022-deep-stimulus-encoder/","publishdate":"2022-03-07T00:00:00Z","relpermalink":"/publications/2022-deep-stimulus-encoder/","section":"publications","summary":"We propose a perceptual stimulus encoder based on convolutional neural networks that is trained in an end-to-end fashion to predict the electrode activation patterns required to produce a desired visual percept. ","title":"Deep learning-based perceptual stimulus encoder for bionic vision","type":"publications"},{"categories":null,"content":"","date":1646611200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1646611200,"objectID":"47847d38f499b8a03dca80ce46258239","people":["Justin Kasowski","Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2022-immersive-vr/","publishdate":"2022-03-07T00:00:00Z","relpermalink":"/publications/2022-immersive-vr/","section":"publications","summary":"We present VR-SPV, an open-source virtual reality toolbox for simulated prosthetic vision that uses a psychophysically validated computational model to allow sighted participants to 'see through the eyes' of a bionic eye user.","title":"Immersive virtual reality simulations of bionic vision","type":"publications"},{"categories":null,"content":"PSY-221F is the new course number for PSY-265 formerly taught by Greg Ashby\nCourse Description This is a lecture course that surveys computational neuroscience, which is a branch of neuroscience that employs mathematical models, theoretical analysis, and abstractions of the brain to understand the principles that govern development, structure, physiology, and cognitive abilities of the nervous system. We will cover both classical (e.g., GLM, LIF, Hodgkin-Huxley model) and state-of-the-art methods (i.e., deep learning).\nBy the end of this course, you should be able to:\n describe how the brain \u0026ldquo;computes\u0026rdquo;, describe different methods that computational neuroscientists use to model neural coding, computationally model the biophysics of single neurons and the dynamics of neural networks, fit a computational model to experimental data.  You will gain experience both conceptually and practically, by homework assignments that involve solving problems and implementing computational models. However, this is not primarily a programming course - that is, the main goal is to learn the concepts, not to learn a programming language or particular programming techniques. However, coding examples of the concepts is the best way to demonstrate (and facilitate) your knowledge of them. Lab sections will feature Python \u0026amp; math tutorials, hands-on examples, and guided programming sessions.\nPrerequisites The formal prerequisite is PSY-221B, but the only part of that course that is necessary is the introduction to matrix algebra.\nThe actual necessary background includes:\n calculus, some prior exposure to matrix algebra, some prior exposure to Python.  Desirable, but not strictly necessary:\n prior exposure to differential equations, basic knowledge of neuroscience.  Content Textbook: Dayan \u0026amp; Abbott (2001)\nTopics to be covered:\n Intro to CompNeuro: concepts, properties of neurons, cell types Neural encoding: spike trains and firing rates, early visual system Neuroelectronics: Electrical properties of neurons, Nernst equation Point neuron models: LIF, Izhikevich neurons, Hodgkin-Huxley neurons Morphological neuron models: synaptic conducances, cable equation, multi-compartment models Network models: firing rate models, feedforward/recurrent models, stochastic networks Plasticity \u0026amp; learning: short \u0026amp; long-term plasticity, reinforcement learning Machine and deep learning: model fitting, GLM, CNN, RNN Applications: sensory systems, language, decision-making, \u0026hellip;  Your grade will be determined by biweekly quizzes, homework assignments (drop the lowest) and a take-home final exam.\nMore information at: https://gauchospace.ucsb.edu/courses/course/view.php?id=10610.\n","date":1646092800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1646092800,"objectID":"690d235d8e7f4e8a8e3ea4e2083a195b","people":null,"permalink":"https://bionicvisionlab.org/teaching/2022-spring-psy221f/","publishdate":"2022-03-01T00:00:00Z","relpermalink":"/teaching/2022-spring-psy221f/","section":"teaching","summary":"A lecture course that surveys computational neuroscience, which is a branch of neuroscience that employs mathematical models, theoretical analysis, and abstractions of the brain to understand the principles that govern development, structure, physiology, and cognitive abilities of the nervous system. We will cover both classical (e.g., GLM, LIF, Hodgkin-Huxley model) and state-of-the-art methods (i.e., deep learning).","title":"PSY-221F: Computational Neuroscience","type":"teaching"},{"categories":null,"content":"","date":1640131200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640131200,"objectID":"10e800338dcbf02f3fd25a256ed0cc7d","people":["Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2021-learning-to-see-again/","publishdate":"2021-12-22T00:00:00Z","relpermalink":"/publications/2021-learning-to-see-again/","section":"publications","summary":"We show that sighted individuals can learn to adapt to the unnatural on- and off-cell population responses produced by electronic and optogenetic sight recovery technologies.","title":"Learning to see again: Perceptual learning of simulated abnormal on- off-cell population responses in sighted individuals","type":"publications"},{"categories":null,"content":"Rather than aiming to one day restore natural vision (which may remain elusive until we fully understand the neural code of vision), we might be better off thinking about how to create practical and useful artificial vision now. Specifically, a visual prosthesis has the potential to provide visual augmentations through the means of artificial intelligence (AI) based scene understanding (e.g., by highlighting important objects), tailored to specific real-world tasks that are known to affect the quality of life of people who are blind (e.g., face recognition, outdoor navigation, self-care).\nIn the future, these visual augmentations could be combined with GPS to give directions, warn users of impending dangers in their immediate surroundings, or even extend the range of visible light with the use of an infrared sensor (think bionic night-time vision). Once the quality of the generated artificial vision reaches a certain threshold, there are a lot of exciting avenues to pursue.\n","date":1639267200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1639267200,"objectID":"483f7439d7ffd8ed32df84fef3409470","people":null,"permalink":"https://bionicvisionlab.org/research/smart-bionic-eye/","publishdate":"2021-12-12T00:00:00Z","relpermalink":"/research/smart-bionic-eye/","section":"research","summary":"Rather than aiming to one day restore *natural* vision, we might be better off thinking about how to create practical and useful *artificial* vision now.","title":"Towards a Smart Bionic Eye","type":"research"},{"categories":null,"content":"The goal of this project is to obtain a nuanced understanding of the strategies that people who are blind or visually impaired (BVI) employ to perform different instrumental activities of daily living (iADLs).\nIdentifying useful and relevant visual cues that could support these iADLs, especially when the task involves some level of scene understanding, orientation, and mobility, will be essential to the success of near-future visual accessibility aids.\n","date":1638316800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1638316800,"objectID":"0436c06999d02c1a39549c55f7aa4543","people":null,"permalink":"https://bionicvisionlab.org/research/information-needs-blind-low-vision/","publishdate":"2021-12-01T00:00:00Z","relpermalink":"/research/information-needs-blind-low-vision/","section":"research","summary":"A nuanced understanding of the strategies that people who are blind or visually impaired employ to perform different instrumental activities of daily living (iADLs) is essential to the success of future visual accessibility aids.","title":"Understanding the Information Needs of People Who Are Blind or Visually Impaired","type":"research"},{"categories":null,"content":"","date":1635724800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1635724800,"objectID":"9a060bf8d239d3032bdf3b9c520fe632","people":["Jacob Granley","Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2021-biphasic-axon-map/","publishdate":"2021-11-01T00:00:00Z","relpermalink":"/publications/2021-biphasic-axon-map/","section":"publications","summary":"We present a phenomenological model that predicts phosphene appearance as a function of stimulus amplitude, frequency, and pulse duration.","title":"A computational model of phosphene appearance for epiretinal prostheses","type":"publications"},{"categories":null,"content":"A major outstanding challenge is predicting what people \u0026ldquo;see\u0026rdquo; when they use their devices.\nInstead of seeing focal spots of light, current visual implant users perceive highly distorted percepts, which vary in shape not just across subjects but also across electrodes and often fail to assemble into more complex percepts. Furthermore, phosphenes appear fundamentally different depending on whether they are generated with retinal or cortical implants.\nThe goal of this project is thus to combine psychophysical and neuroanatomical data that can inform phosphene models capable of linking electrical stimulation directly to perception.\n","date":1633132800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1633132800,"objectID":"b4577bf7255e69c478cf022f745b64e1","people":null,"permalink":"https://bionicvisionlab.org/research/predicting-visual-outcomes-visual-prostheses/","publishdate":"2021-10-02T00:00:00Z","relpermalink":"/research/predicting-visual-outcomes-visual-prostheses/","section":"research","summary":"What do visual prosthesis users see, and why? Clinical studies have shown that the vision provided by current devices differs substantially from normal sight.","title":"Predicting Visual Outcomes for Visual Prostheses","type":"research"},{"categories":null,"content":"Our lack of understanding of multi-electrode interactions severely limits current stimulation protocols. For example, current Argus II protocols simply attempt to minimize electric field interactions by maximizing phase delays across electrodes using ‘time-multiplexing’. The assumption is that single-electrode percepts act as atomic ‘building blocks’ of patterned vision. However, these building blocks often fail to assemble into more complex percepts.\nThe goal of this project is therefore to develop new stimulation strategies that minimize perceptual distortions. One potential avenue is to view this as an end-to-end optimization problem, where a deep neural network (encoder) is trained to predict the electrical stimulus needed to produce a desired percept (target).\nImportantly, this model would have to be trained with the phosphene model in the loop, such that the overall network would minimize a perceptual error between the predicted and target output. This is technically challenging, because a phosphene model must be:\n simple enough to be differentiable such that it can be included in the backward pass of a deep neural network, complex enough to be able to explain the spatiotemporal perceptual distortions observed in real prosthesis patients, and amenable to an efficient implementation such that the training of the network is feasible.  ","date":1633046400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1633046400,"objectID":"2c6fc964c5b613455122b2baa2413267","people":null,"permalink":"https://bionicvisionlab.org/research/end-to-end-optimization/","publishdate":"2021-10-01T00:00:00Z","relpermalink":"/research/end-to-end-optimization/","section":"research","summary":"Rather than predicting perceptual distortions, one needs to solve the inverse problem: What is the best stimulus to generate a desired visual percept?","title":"End-to-End Optimization of Bionic Vision","type":"research"},{"categories":null,"content":"Due to the unique requirements of working with bionic eye recipients (e.g., required assistance, increased setup time, travel cost), experimentation with different encoding methods remains challenging and expensive.\nInstead, embedding simulated prosthetic vision (SPV) models in immersive virtual reality (VR) allows sighted subjects to act as virtual patients by \u0026ldquo;seeing\u0026rdquo; through the eyes of the patient, taking into account their head and eye movements as they explore an immersive virtual environment.\nThis can speed up the development process by allowing us to test theoretical predictions in high-throughput experiments, the best of which can be validated and improved upon in an iterative process with the bionic eye recipient in the loop.\n","date":1633046400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1633046400,"objectID":"562dc6f51b794437707ec763e74b8907","people":null,"permalink":"https://bionicvisionlab.org/research/immersive-virtual-reality-simulations/","publishdate":"2021-10-01T00:00:00Z","relpermalink":"/research/immersive-virtual-reality-simulations/","section":"research","summary":"Embedding simulated prosthetic vision models in immersive virtual reality allows sighted subjects to act as virtual patients by \"seeing\" through the eyes of the patient.","title":"Immersive Virtual Reality Simulations of Bionic Vision","type":"research"},{"categories":null,"content":"","date":1632700800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1632700800,"objectID":"1ea7bfff6a164cada4127025bca057b9","people":["Jacob Granley","Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2021-hba-u-net/","publishdate":"2021-09-27T00:00:00Z","relpermalink":"/publications/2021-hba-u-net/","section":"publications","summary":"We propose HBA-U-Net: a U-Net backbone with hierarchical bottleneck attention to highlight retinal abnormalities that may be important for fovea and optic disc segmentation in the degenerated retina.","title":"U-Net with hierarchical bottleneck attention for landmark detection in fundus images of the degenerated retina","type":"publications"},{"categories":[],"content":"Prof. Beyeler was part of the Giz Asks series, where the focused turned to the prospect of using brain-machine interface technology to directly write in information to the brain.\nRead the full interview here.\n","date":1632155340,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1632155353,"objectID":"97e77cd152658cef8ec13fdd329eb163","people":["Michael Beyeler"],"permalink":"https://bionicvisionlab.org/post/2021-09-giz-asks/","publishdate":"2021-09-20T09:29:00-07:00","relpermalink":"/post/2021-09-giz-asks/","section":"post","summary":"Prof. Beyeler was featured in a Giz Asks article about the prospect of using brain-machine interfaces to directly write in information to the brain.","title":"Will it ever be possible to upload information to my brain?","type":"post"},{"categories":null,"content":"","date":1631232000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1631232000,"objectID":"bd0e96fe8780217f5653eb89d9b142ad","people":["Justin Kasowski","Byron A. Johnson","Ryan Neydavood","Anvitha Akkaraju","Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2021-xr-visual-accessibility/","publishdate":"2021-09-10T00:00:00Z","relpermalink":"/publications/2021-xr-visual-accessibility/","section":"publications","summary":"We present a systematic literature review of 216 publications from 109 different venues assessing the potential of XR technology to serve as not just a visual accessibility aid but also as a tool to study perception and behavior in people with low vision and blind people whose vision was restored with a neuroprosthesis.","title":"Furthering visual accessibility with extended reality (XR): a systematic review","type":"publications"},{"categories":null,"content":"What would the world look like with a bionic eye?\nThis graduate course will introduce students to the multidisciplinary field of bionic vision viewed through the lens of computer science, neuroscience, and human-computer interaction.\nThe course will conclude with a programming project (teams of ≤ 4, any language/environment ok) in lieu of a final exam, giving students an opportunity to gain hands-on experience of working on open research problems using methods and tools best suited to their scientific background.\n         Instructor Michael Beyeler (first initial last name at ucsb dot edu)   Class F21, Tue/Thu 9:00 \u0026ndash; 10:50 am, Phelps 3526   Office Hours Tue 2\u0026ndash;4 pm Zoom (schedule a meeting)    \rChangelog:\r 2021-10-09: Switched order of mid-quarter content 2021-09-27: Updated office hours and assigned reading for Week 1 2021-09-15: Posted initial schedule  \rCourse Objectives The course will give an overview of current bionic eye technology designed to restore vision to people living with incurable blindness. By the end of the course, you should be able to:\n identify various types of bionic eye technologies, their differences and similarities explain how the retina and visual cortex support our sense of seeing apply common computer vision \u0026amp; machine learning techniques for stimulus encoding give a nuanced review of the HCI \u0026amp; ethics issues associated with implantable neurotechnology demonstrate your hands-on experience of working on open problems in the field  The course is targeted to a diverse audience spanning computer science (computer vision, human factors, deep learning) to psychology (vision, psychophysics) and brain sciences (computational neuroscience, neuroengineering).\nPrerequisites  There are no official prerequisites for this course. The instructor will do his best to make the course content self-contained, including a crash course in neuroscience \u0026amp; computational vision. However, homeworks and final projects will require programming. Homeworks will be based around pulse2percept, a Python-based simulation framework for bionic vision. Any suitable programming language/framework is ok for the final project.  FAQ  Will classes be in person? Yes, and you are strongly encouraged to attend. What about office hours? I will offer both in-person and virtual office hours. Do instructors and students need to wear a mask in class? Yes. There will be no exceptions to this policy. Sure, it\u0026rsquo;ll be a little weird at first, but I\u0026rsquo;m sure we\u0026rsquo;ll all adjust pretty quickly. What if I can\u0026rsquo;t make a lecture? Send me a quick email before the lecture. You don\u0026rsquo;t need a reason for your first 3 absences. I will do my best to record the lectures and upload them to GauchoCast for those who cannot make a lecture, but I am unable to make any remote accommodations beyond that. What if I\u0026rsquo;m sick or need to quarantine or isolate? Now more important than ever, do not come in if you feel under the weather. Email me, then follow UCSB testing \u0026amp; quarantine protocol. What if the instructor needs to quarantine? In this case we will temporarily shift to remote instruction. What if my question isn\u0026rsquo;t answered here? I\u0026rsquo;m happy to answer your question via email.  Schedule Note: This schedule is subject to slight change over the course of the quarter.\n\r\rWk\rDate\rReading\rTopics\rAction\rHWout\rHWdue\rQuiz\r\r\r\r\r0\rThu\rSep 23\r\rR1\r\r\r\rL1: Introduction\rL2: Bionic Vision - Then \u0026 Now\r\r\r\r\r\r\r\r\r\r1\rTue\rSep 28\rR2, R3\r\r\rL3: Sight Recovery Technologies\rL4: Foundations of Vision\r \r\rHW1\r\r\r\r\rThu\rSep 30\r\r\r\rL5: Computational Neuroscience\rA1: Introduction to Google Colab \u0026 Python\r\r Quiz 1 (Q1) due by Sun, Oct 3, 11:59 pm.\r\r\r\rA1\r\r\rQ1\r\r\r2\rTue\rOct 5\rR4\r\rGuest lecture by Aiwen Xu\r\rL6: Retina in Health \u0026 Disease\r\r\r\r\r\r\r\r\rThu\rOct 7\rR5\r\r\rL7: Retinal Prostheses\r\r Homework 1 (HW1) due by Sun, Oct 10, 11:59 pm.\r\r\r\r\r\rHW1\r\r\r\r3\rTue\rOct 12\rR6\r\r\rL8: Computational Models of Bionic Vision\r\r\r\r\r\r\r\r\rThu\rOct 14\rR7\r\r\rA2: Introduction to pulse2percept in Python\rA3: Group Project Discussion\r\r Quiz 2 (Q2) due by Sun, Oct 17, 11:59 pm.\r\r\r\rA2, A3\rHW2\r\rQ2\r\r\r4\rTue\rOct 19\rR8\r\r\rL9: The Role of Machine Learning in Bionic Vision\r\r\r\r\r\r\r\r\rThu\rOct 21\rR9\r\r\rL10: Optimizing Electrical Stimulation in an Artificial Retina\r\r Homework 2 (HW2) due by Sun, Oct 24, 11:59 pm.\r\r\r\r\r\rHW2\r\r\r\r5\rTue\rOct 26\rR10, R11\r\r\rL11: The Role of Mixed Reality in Bionic Vision\r\r\rA4\r\r\r\r\r\rThu\rOct 28\r\r\rA4: Project Progress Presentations \rTeam \u0026 project description (TPD) due by Sun, Oct 31, 11:59 pm.\r\r  A5\r\rTPD\r\r\r\r6\rTue\rNov 2\rR12\r\r\rL12: The Role of Image Processing in Bionic Vision\rA5: BionicVisionVR Demo by Justin Kasowski\r\r\r\r\r\r\r\r\rThu\rNov 4\rR13\r\r\rL13: The Role of Computer Vision in Bionic Vision\rA6: Smart Bionic Eye\r\r Quiz 3 (Q3) due by Sun, Nov 7, 11:59 pm.\r\r\r\rA6\r\r\rQ3\r\r\r7\rTue\rNov 9\rR14, R15\r\r\rL14: Cortical Prostheses - Approaches \u0026 Challenges\rL15: Phosphene Models for Cortical Prostheses\r\r\r\r\r\r\r\rThu\rNov 11\r\r\rVeterans' Day\r\r\r\r\r\r\r\r8\rTue\rNov 16\rR16, R17\r\r\rL16: Learning to See Again with a Bionic Eye\r\r\r\r\r\r\r\r\rThu\rNov 18\r\r\rA7: Guest Visit by Jason Esterhuizen, ORION implantee \r Quiz 4 (Q4) due by Sun, Nov 21, 11:59 pm.\r\r\r\r\rA7\r\r\r\r\rQ4\r\r\r9\rTue\rNov 23\r\r\rA8: Project Progress Presentations\r\rA8\r\r\r\r\rThu\rNov 25\r\r\r\rThanksgiving Day\r\r\r\r\r\r\r\r10\rTue\rNov 30\r\r\r\r\rL17: The Future of Bionic Vision\r\r\r\r\r\r\r\r\rThu\rDec 2\r\r\r\r\rA9: Quarter Review\r\r\rProject report (PR) \u0026amp; source code (SC) due Sun, Dec 5, 11:59 pm.\r\r\r\r\rA9\r\r\rPR\u0026amp;SC\r\r\r11\rTue\rDec 7\r\rA10: Final Project Presentations\rA10\r\r\r\r\r\r\rCourse Requirements \u0026amp; Grading Your final grade will be determined as follows:\n 20% Homework assignments:  10% Homework 1 10% Homework 2   30% \u0026ldquo;Check Your Knowledge\u0026rdquo; quizzes  10% per quiz Lowest-scoring quiz will be dropped   50% Final project implementation, documentation, and presentation  5% Project proposal presentation (1 slide) 5% Project progress presentation (2 slides: what have you done, what\u0026rsquo;s left to do) 20% Project final presentation 20% Project final report (+5% extra credit if project shows promise of turning into a publication)    Lateness Policy All assignments are due at 11:59:59 pm on the scheduled due date, typically a Sunday (timestamp of the online submission system).\n Each student will be allowed 3 \u0026ldquo;late days\u0026rdquo; over the course of the quarter for which lateness will not be penalized. Late days cannot be applied to project deadlines. Late days may be applied to the quizzes and homework assignments: Anything turned in between 12:00:00 am and 11:59:59 pm the next day is one day late; every day thereafter that an assignment is late, including weekends and holidays, counts as an additional late day. No late work will be accepted after the deadline if you have used up all your late days. If you\u0026rsquo;re not done on time, you should turn in what you have to receive partial credit. No exceptions will be made for the final project report.  Please make sure you understand this policy.\n\u0026ldquo;Check Your Knowledge\u0026rdquo; Quizzes We will have 4 GauchoSpace quizzes over the quarter that test your theoretical/conceptual knowledge of the course content (this includes lectures and assigned reading materials).\nThe following rules apply:\n Quizzes must be completed by Sunday 11:59 pm of the respective week (lateness policy applies) You have 30 mins per attempt A quiz can be taken twice. If you decide to take the quiz again, only your second attempt will be counted (that is, the score from your first attempt will be dropped, this is called \u0026ldquo;grading method: last attempt\u0026rdquo; on GauchoSpace) At the end of the quarter, the lowest-scoring quiz will be dropped. (Each of the 3 highest-scoring quizzes will thus account for 10% of your grade)  Final Project In lieu of a final exam, students will conduct a programming project (team size ≤ 4). The goal of the project is to gain hands-on experience working on open research questions in bionic vision using tools and methods best suited to their scientific background.\nAll projects must address a research question and have a programming component. Students are free to use any programming language and development environment they choose. Building a project based on pulse2percept is encouraged (especially for students with relatively little programming experience) but is by no means required. Reproducing key research findings in the literature is allowed. No pure literature reviews, please.\nProjects that show promise of turning into a publication will receive extra credit.\nStudents will present their project to the rest of the class during finals week. In addition, students will submit a write-up of their project and hand in their source code (see Milestones).\nThe project will be evaluated based on the:\n originality/novelty of the idea technical strength of the work (emphasis on the research, not the programming expertise) organization, clarity, and style of the project report effort and completeness of the work (normalized by the number of team members)  Project Milestones    Date Time Deliverable due     Thu, Oct 14 9:00 am Students start forming teams and discussing project ideas in class.   Thu, Oct 28 9:00 am Teams present their project ideas in class.   Sun, Oct 31 11:59 pm Teams submit a project title and 2-3 sentence project description.   Tue, Nov 23 9:00 am Teams present their project progress in class.   Sun, Dec 5 11:59 pm Teams hand in their final project report and all source code.   Tue, Dec 7 9:00 am Teams make their final project presentations in class.    Students are encouraged to discuss ideas with the instructors, so that feedback can be incorporated early in the process.\nLate days cannot be used on these project deadlines.\nAcademic Integrity The University of California has formal policies related to academic integrity.\nAny act of academic dishonesty, such as cheating or plagiarism, will result in a University disciplinary action and an \u0026ldquo;F\u0026rdquo; in this course. In addition to academic integrity, I also expect everyone in this class to treat their fellow students and course staff with respect.\nBasic Needs If you are facing any challenges securing food or housing and believe this may affect your performance in the class, you are urged to meet with a Food Security and Calfresh Advocate who is aware of the broad variety of resources that UCSB has to offer (see their drop-in hours at food.ucsb.edu). You are also urged to contact the professor if you are comfortable doing so.\nPlease visit food.ucsb.edu for additional resources including Calfresh, the AS Food Bank, and more.\n","date":1628985600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1628985600,"objectID":"2dad7ab16b905e022d4e43580bb840eb","people":null,"permalink":"https://bionicvisionlab.org/teaching/2021-fall-cs291a/","publishdate":"2021-08-15T00:00:00Z","relpermalink":"/teaching/2021-fall-cs291a/","section":"teaching","summary":"This graduate course will introduce students to the multidisciplinary field of bionic vision viewed through the lens of computer science, neuroscience, and human-computer interaction.","title":"CS-291A: Bionic Vision","type":"teaching"},{"categories":null,"content":"Understanding the early visual system in health and disease is a key issue for neuroscience and neuroengineering applications such as visual prostheses.\nAlthough the processing of visual information in the healthy retina and early visual cortex (EVC) has been studied in detail, no comprehensive computational model exists that captures the many cell-level and network-level biophysical changes common to retinal degenerative diseases and other sources of visual impairment.\nTo address this challenge, we are developing computational models of the retina and EVC to elucidate the neural code of vision.\n","date":1627776000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1627776000,"objectID":"2b86195429a6dd5c19256f15a02306aa","people":null,"permalink":"https://bionicvisionlab.org/research/computational-models-visual-system/","publishdate":"2021-08-01T00:00:00Z","relpermalink":"/research/computational-models-visual-system/","section":"research","summary":"Understanding the visual system in health and disease is a key issue for neuroscience and neuroengineering applications such as visual prostheses.","title":"Computational Models of the Visual System","type":"research"},{"categories":null,"content":"How are visual acuity and daily activities affected by visual impairment?\nPrevious studies with people who have retinal degeneration have shown that vision is altered and impaired in the presence of a scotoma. This is also the case when a sighted person is tested under simulated low vision (SLV) conditions. However, the extent to which patient-specific factors affect vision and quality of life is not well understood.\nTesting sighted participants with SLV allows us to compare performance to real patients, design simulations to be as naturalistic as possible, and assess changes in vision for real life tasks instead of relying on acuity alone.\n","date":1622505600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1622505600,"objectID":"8f35d635d63daf950223aa36a8f607ce","people":null,"permalink":"https://bionicvisionlab.org/research/simulated-visual-impairment/","publishdate":"2021-06-01T00:00:00Z","relpermalink":"/research/simulated-visual-impairment/","section":"research","summary":"How are visual acuity and daily activities affected by visual impairment? Previous studies have shown that vision is altered and impaired in the presence of a scotoma, but the extent to which patient-specific factors affect vision and quality of life is not well understood.","title":"Simulating Visual Impairment","type":"research"},{"categories":null,"content":"","date":1620086400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1620086400,"objectID":"ce7e87355e58295ded0c12942f667a7c","people":["Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2021-explainable-ai/","publishdate":"2021-05-04T00:00:00Z","relpermalink":"/publications/2021-explainable-ai/","section":"publications","summary":"We present an explainable artificiall intelligence (XAI) model fit on a large longitudinal dataset that can predict electrode deactivation in Argus II.","title":"Explainable AI for retinal prostheses: Predicting electrode deactivation from routine clinical measures","type":"publications"},{"categories":null,"content":"pulse2percept is a BSD-licensed, open-source Python package for simulated prosthetic vision (SPV).\nBuilt on the NumPy and SciPy stacks, as well as contributions from the broader Python community, pulse2percept provides an open-source implementation of several phosphene models for a wide range of state-of-the-art retinal prostheses, to provide insight into the visual experience provided by these devices.\nAs pulse2percept continues to be adopted by several research labs around the globe, we continue to improve its functionality and performance as well as add new implants, models, and datasets.\n","date":1619827200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1619827200,"objectID":"e92da78b8295caab451498157b19bc7c","people":null,"permalink":"https://bionicvisionlab.org/research/pulse2percept/","publishdate":"2021-05-01T00:00:00Z","relpermalink":"/research/pulse2percept/","section":"research","summary":"pulse2percept is an open-source Python simulation framework used to predict the perceptual experience of retinal prosthesis patients across a wide range of implant configurations.","title":"pulse2percept: A Python-Based Simulation Framework for Bionic Vision","type":"research"},{"categories":[],"content":"Over the years, cyberpunk tales and sci-fi series have featured characters with cybernetic vision—most recently Star Trek Discovery\u0026rsquo;s Lieutenant Keyla Detmer and her ocular implants. In the real world, restoring “natural” vision is still a complex puzzle, though researchers at UC Santa Barbara are developing a smart prosthesis that provides cues to the visually impaired, much like a computer vision system talks to a self-driving car.\nToday, over 10 million people worldwide are living with profound visual impairment, many due to retinal degeneration diseases. Ahead of this week\u0026rsquo;s Augmented Humans International Conference, we spoke with Dr. Michael Beyeler, Assistant Professor in Computer Science and Psychological \u0026amp; Brain Sciences at UCSB, who is forging ahead with synthetic sight trials at his Bionic Vision Lab and will be presenting a paper at the conference.\nRead the full interview here.\n","date":1614097740,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1614097753,"objectID":"12d36a5e56f13526d99026da0f2d0eb9","people":["Michael Beyeler"],"permalink":"https://bionicvisionlab.org/post/2021-02-pcmag/","publishdate":"2021-02-23T09:29:00-07:00","relpermalink":"/post/2021-02-pcmag/","section":"post","summary":"Instead of focusing on one day restoring ‘natural’ vision, we may be better off thinking about how to create ‘practical’ and ‘useful’ artificial vision now.","title":"PCMag: Building the bionic eye... with car tech?","type":"post"},{"categories":null,"content":"","date":1614038400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1614038400,"objectID":"44c941643b53b9b8fe1d9d80e20ef966","people":["Justin Kasowski","Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2021-towards-immersive-vr/","publishdate":"2021-02-23T00:00:00Z","relpermalink":"/publications/2021-towards-immersive-vr/","section":"publications","summary":"We propose to embed biologically realistic models of simulated prosthetic vision in immersive virtual reality so that sighted subjects can act as 'virtual patients' in real-world tasks.","title":"Towards immersive virtual reality simulations of bionic vision","type":"publications"},{"categories":null,"content":"","date":1613952000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1613952000,"objectID":"f4d31dde088561df71570dfd3af2cf11","people":["Aiwen Xu","Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2021-scene-simplification/","publishdate":"2021-02-01T00:00:00Z","relpermalink":"/publications/2021-scene-simplification/","section":"publications","summary":"We combined deep learning-based scene simplification strategies with a psychophysically validated computational model of the retina to generate realistic predictions of simulated prosthetic vision.","title":"Deep learning-based scene simplification for bionic vision","type":"publications"},{"categories":null,"content":"Same course as ECE 181. Not open for credit to students who have completed ECE/CMPSC 181B with a grade of C or better. ECE/CMPSC 181 is a legal repeat of ECE/CMPSC 181B.\nPrerequisites: Upper-division standing in Electrical Engineering, Computer Engineering, Computer Science, Chemical Engineering or Mechanical Engineering.\n","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"ae5ee224e19cf700fc8876dd2c5037bf","people":null,"permalink":"https://bionicvisionlab.org/teaching/2021-winter-cs181/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/teaching/2021-winter-cs181/","section":"teaching","summary":"Overview of computer vision problems and techniques for analyzing the content of images and video. Topics include image formation, edge detection, image segmentation, pattern recognition, texture analysis, optical flow, stereo vision, shape representation and recovery techniques, issues in object recognition, and case studies of practical vision systems.","title":"CS/ECE-181: Introduction to Computer Vision","type":"teaching"},{"categories":[],"content":"Dr. Beyeler sat down with Luming Cao from SciSection\u0026rsquo;s Human and Science platform to talk about how bionic vision, as sci-fi as it sounds, is already helping to restore vision to the blind.\nThe transcript of this informal interview is now available, and a podcast will follow soon.\nRead the full interview here.\n","date":1601742540,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1601742553,"objectID":"ec3c44a3dfec833dd01f282eefa9461f","people":["Michael Beyeler"],"permalink":"https://bionicvisionlab.org/post/2020-10-scisection/","publishdate":"2020-10-03T09:29:00-07:00","relpermalink":"/post/2020-10-scisection/","section":"post","summary":"Dr. Beyeler talks about how bionic vision, as sci-fi as it sounds, is already helping to restore vision to the blind.","title":"SciSection: Interview with Michael Beyeler","type":"post"},{"categories":null,"content":"PSY 110A is the former number of PSY 130. Students who have completed PSY110A with a C- or below may take PSY 130 as a legal repeat.\nPrerequisites: Open to Psychological \u0026amp; Brain Sciences, Biopsychology, and Interdisciplinary Studies majors only.\nWe take our ability to see for granted. It is for the most part automatic and effortless and thus might seem relatively simple. But behind the scenes our brains dedicate over a 1/4 of their machinery to analyze and interpret the light falling on our eyes. How does the brain do it?\nIn this course we will learn how the brain gives rise to our visual experience from seeing depth, color, and motion, to recognizing faces and objects. Importantly, the course illustrates an approach to study psychology and the brain combining behavioral research, neurophysiology and computational theory.\n","date":1601424000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1601424000,"objectID":"42140d1938d80b337f7aa7055292a764","people":null,"permalink":"https://bionicvisionlab.org/teaching/2020-fall-psych130/","publishdate":"2020-09-30T00:00:00Z","relpermalink":"/teaching/2020-fall-psych130/","section":"teaching","summary":"An overview of theory and research into the human performance and biological processes of visual perception. Typical topics may range from the detection of simple stimuli to the identification of objects and events.","title":"PSY-130: Perception - Vision","type":"teaching"},{"categories":[],"content":"Michael Beyeler and the Bionic Vision Lab are featured heavily in the Spring Edition of UCSB\u0026rsquo;s College of Engineering Convergence Magazine:\n \u0026ldquo;There is research to try to understand the brain—how it works on a mechanistic and algorithmic level—and then there\u0026rsquo;s applying that to an engineered system that can interface with the brain,\u0026rdquo; says Michael Beyeler, an assistant professor in Computer Science and Psychological \u0026amp; Brain Sciences, in providing context for his research, which lies in the emerging interdisciplinary field of neuroengineering.\n  “Brain-computer interfaces can be used both for treating neurological and mental disorders as well as for understanding brain function,” he says. “Eventually, they should also allow us to restore vision to the blind.”\n Read the full article here.\n","date":1588350540,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1588350553,"objectID":"e67f6c32303141447581b0c8bdb0f443","people":["Michael Beyeler"],"permalink":"https://bionicvisionlab.org/post/2020-05-convergence/","publishdate":"2020-05-01T09:29:00-07:00","relpermalink":"/post/2020-05-convergence/","section":"post","summary":"Bionic Vision Lab featured in UCSB College of Engineering's Convergence Magazine.","title":"UCSB Convergence: Reverse engineering the brain","type":"post"},{"categories":null,"content":"How does cortical circuitry perform the visual scene analysis needed to support navigation through the environment?\nMost studies of central visual processing are focused on detection or discrimination of specific features of simple artificial stimuli (e.g., orientation, direction of motion, object identity). However, navigation through the environment involves a very different set of computational goals, such as identifying landmarks and using optic flow to avoid obstacles. Furthermore, these computations occur under a very different stimulus regime, with the animal actively sampling a complex and continually moving sensory scene.\nOur goal is to determine how the brain extracts relevant visual features from the rich, dynamic visual input that typifies active exploration, and develop (deep) predictive models of brain activity based on visual input and several behavioral variables. The data includes one-of-a-kind measures of neural activity in mice navigating through real-world and virtual environments, collected using 2-photon imaging and electrophysiology by our collaborators Spencer Smith, Michael Goard, and Cris Niell.\nThe results of this project will provide knowledge about normal visual function and insights for treating impaired vision via prosthetic or assistive devices.\n","date":1577923200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577923200,"objectID":"e1165442b451c1b4848a6243964ca32d","people":null,"permalink":"https://bionicvisionlab.org/research/mouse-visual-navigation/","publishdate":"2020-01-02T00:00:00Z","relpermalink":"/research/mouse-visual-navigation/","section":"research","summary":"How does the brain extract relevant visual features from the rich, dynamic visual input that typifies active exploration, and how does the neural representation of these features support visual navigation?","title":"Cortical Visual Processing for Navigation","type":"research"},{"categories":null,"content":"What would the world look like with a bionic eye?\nThis graduate course will introduce students to the multidisciplinary field of bionic vision, with an emphasis on both the computer science and neuroscience of the field.\nThe course will conclude with a programming project (teams of ≤ 3, any language/environment ok) in lieu of a final exam, giving students an opportunity to gain hands-on experience of working on open research problems using methods and tools best suited to their scientific background.\n         Instructor Michael Beyeler (first initial last name at ucsb dot edu)   Class WQ 2020, Tue/Thu 9:00 \u0026ndash; 10:50 am, Phelps 3526   Office Hours Tue 4:00 \u0026ndash; 5:00 pm or by appointment, Psych East 3822    This website and the Piazza Forum will be used as centers for communication. Homework submission will occur through GauchoSpace. Make sure you are enrolled! (Come to class to get an add code.)\nTable of Contents\r Course Objectives Prerequisites Schedule Course Requirements \u0026amp; Grading Lateness Policy Final Project  Project Milestones Project Presentation Project Report   Academic Integrity Basic Needs  \rCourse Objectives The course will give an overview of current bionic eye technology designed to restore vision to people living with incurable blindness. By the end of the course, you should be able to:\n Identify various types of bionic eye technologies, their differences and similarities Have a basic understanding of the neuroscience of the human visual system Be familiar with common preprocessing, encoding, and electrical stimulation methods Understand the limitations of current bionic eye technologies Have hands-on experience of working on open problems in the field  The course is targeted to a diverse audience spanning from computer science (human factors, neural networks, computer vision) to psychology (vision, psychophysics) and brain sciences (computational neuroscience, neuroengineering).\nPrerequisites  There are no official prerequisites for this course. The instructor will do his best to make the course content self-contained. However, prior programming experience (e.g., Python, Matlab, C++) will be highly beneficial as Homework 2 (HW2) and the final project require programming. Students will be introduced to pulse2percept, a Python-based simulation framework for bionic vision, which will form the basis for HW2 and (optionally) the final project.  Schedule Import calendar:  Note: This schedule is subject to change over the course of the quarter.\n\r\rWk\rDate\rReading\rTopics\rAction\rHW out\rHW due\r\r\r\r\r1\rTue\rJan 7\r\r\r\rIntroduction: Class requirements, policies\rBionic vision: then \u0026amp; now\r\r\r\r\r\r\r\rThu\rJan 9\r\rR1,\rR2\r\r\r\rBlinding eye diseases\rSight restoration approaches \u0026amp; challenges\r\r\r\r\rHW1\r\r\r\r\r2\rTue\rJan 14\r\rR3\r\r\r\rFundamentals of neuroscience\rThe visual system\r\r\r\r\r\r\r\rThu\rJan 16\r\rR4\r\r\r\rComputational neuroscience\rIntroduction to Python\r\r\rHomework 1 (HW1) due by Sun, Jan 19, 11:59 pm.\r\r\r\r\rA1\t\r\rHW1\r\r\r3\rTue\rJan 21\r\rR5,\rR6\r\r\r\rRetina in health \u0026amp; disease\rRetinal prostheses\r\r\r\r\r\r\r\rThu\rJan 23\r\rR7\r\r\r\rIntroduction to pulse2percept in Python\rProject ideas: Discussion \u0026amp; brainstorming\r\r\r\rA2\r\r\r\r\r\r4\rTue\rJan 28\r\rR8\r\r\r\rVisual psychophysics for retinal prostheses\rPhosphene models: Scoreboard, axon map\r\r\r\r\r\r\r\rThu\rJan 30\r\r\rTeams present their project ideas \rTeam \u0026 project description (TPD) due by Sun, Feb 2, 11:59 pm.\r\r\r\r\r\rTPD\r\r\r5\rTue\rFeb 4\r\rR9\r\r\r\rCortical prostheses: approaches, challenges\rPhosphene models for cortical prostheses\r\r\r\r\rHW2\r\r\r\r\rThu\rFeb 6\r\r\r\rMid-quarter review\r\r\r\rA3\r\r\r\r\r\r6\rTue\rFeb 11\r\rR10,\rR11\r\r\r\rTraining \u0026amp; rehabilitation\rCortical plasticity \u0026amp; perceptual learning\r\r\r\r\r\r\r\rThu\rFeb 13\r\r\rGuest Visit: Jason Esterhuizen, ORION implantee\r \rA4\r\r\r\r\r\r7\rTue\rFeb 18\r\rR12, \rR13\r\r\r\rImproving visual outcomes in bionic eye technologies\rAdvanced stimulation strategies\r\r\r\r\r\r\r\rThu\rFeb 20\r\rR14\r\r\r\rOptimizing electrical stimulation in an artificial retina\r\r\rHomework 2 (HW2) due by Sun, Feb 23, 11:59 pm.\r\r\r\r\r\rHW2\r\r\r8\rTue\rFeb 25\r\rR15, \rR16\r\r\r\rScene representation for future bionic eye technologies\rAdvanced encoding methods\r\r\r\r\r\r\r\rThu\rFeb 27\r\r\rTeams present project progress\r\r\r\r\r\r9\rTue\rMar 3\r\rTeams work on projects -- Instructor out of the country\r\r\r\r\r\rThu\rMar 5\r\rTeams work on projects -- Instructor out of the country\r\r\r\r\r\r\r10\rTue\rMar 10\r\rR17\r\r\rGuest Lecture: Dr. Noelle Stiles, USC/Caltech\r\r\r\r\r\r\rThu\rMar 12\r\rR18\r\r\r\rOutlook: Future of bionic vision\rAlternatives to brain-computer interfaces\r\r\rProject report (PR) \u0026amp; source code (SC) due Sun, Mar 15, 11:59 pm.\r\r\r\r\r\rPR\u0026amp;SC\r\r11\rTue\rMar 17\r\rTeams make their final project presentations\r\r\r\r\r\r\rCourse Requirements \u0026amp; Grading Your final grade will be determined as follows:\n 15% Class participation and attendance:  Students are expected to attend all class sessions and actively participate in class discussions and activities. If a student must miss a session, they should email the instructor beforehand. Each student will be allowed 3 excused absences (no detailed explanation required) before their absence will start to negatively affect their participation grade. However, late arrivals and unexcused absences will most definitely have a negative effect on a student\u0026rsquo;s participation grade.   30% Homework assignments:  10% Homework 1 20% Homework 2   55% Final project implementation, documentation, and presentation  5% Project idea presentation (1 slide) 10% Project progress presentation (2 slides: what have you done, what\u0026rsquo;s left to do) 20% Project final presentation 20% Project final report (+5% extra credit if project shows promise of turning into a publication)    Lateness Policy All assignments are due at 11:59:59 pm on the scheduled due date, typically a Sunday (timestamp of the online submission system).\n Each student will be allowed 3 \u0026ldquo;late days\u0026rdquo; over the course of the quarter for which lateness will not be penalized. Late days cannot be applied to project deadlines. Late days may be applied to one or both homework assignments: Anything turned in between 12:00:00 am and 11:59:59 pm the next day is one day late; every day thereafter that an assignment is late, including weekends and holidays, counts as an additional late day. Absolutely no late work will be accepted after the deadline if you have used up all your late days. If you\u0026rsquo;re not done on time, you must turn in what you have to receive partial credit. There will be no exceptions from this rule. No exceptions will be made for the final project report.  Please make sure you understand this policy.\nFinal Project In lieu of a final exam, students will conduct a programming project (team size ≤ 3). The goal of the project is to gain hands-on experience working on open research questions in bionic vision using tools and methods best suited to their scientific background.\nAll projects must address a research question and have a programming component. Students are free to use any programming language and development environment they choose. Building a project based on pulse2percept is encouraged (especially for students with relatively little programming experience) but is by no means required. Reproducing key research findings in the literature is allowed. No pure literature reviews, please.\nProjects that show promise of turning into a publication will receive extra credit.\nStudents will present their project to the rest of the class during finals week. In addition, students will submit a write-up of their project and hand in their source code (see Milestones).\nThe project will be evaluated based on the:\n originality/novelty of the idea technical strength of the work (emphasis on the research, not the programming expertise) organization, clarity, and style of the project report effort and completeness of the work (normalized by the number of team members)  Project Milestones    Date Time Deliverable due     Thu, Jan 23 9:00 am Students start forming teams and discussing project ideas in class.   Thu, Jan 30 9:00 am Teams present their project ideas in class.   Sun, Feb 2 11:59 pm Teams submit a project title and 2-3 sentence project description.   Thu, Feb 27 9:00 am Teams present their project progress in class.   Sun, Mar 15 11:59 pm Teams hand in their final project report and all source code.   Tue, Mar 17  Teams make their final project presentations in class.    Students are encouraged to discuss ideas with the instructors, so that feedback can be incorporated early in the process.\nLate days cannot be used on these project deadlines.\nProject Presentation Teams will present their project via Zoom on Tue, Mar 17.\nEach team will have 20 mins to present (+5 mins for Questions \u0026amp; Answers). Sign up for a time slot here.\nBefore the meeting, decide who will host the slides/demo. This person will share their screen during the meeting. Other team members can choose to be physically present with the person sharing the screen or simply log in from their own computer.\nThere are at least two strategies to present your work:\n Strategy A: Follow the outline of your report  Introduction, Methods, Results, Discussion   Strategy B: Top-down  Give an overview of the project\u0026rsquo;s end result Follow with a detailed discussion of the various features/techniques    Make sure to address the challenges you faced and how you overcame them! What have you learned?\nEvery student in the team must say something.\nProject Report Each team will also submit a write-up of their project:\n Use the CHI Extended Abstracts template Structure your report like a short research paper (~4 pages):  Abstract: ~150 words Introduction (1-2 paragraphs)  What did you study and why?   Related work (1/2 page)  Brief summary of the relevant literature. Make sure to point out gaps in the literature that your project is trying to address.   Methods (1-2 pages)  First paragraph: Describe the big-picture idea behind your system/model/approach. Subsections: Walk the reader through all the steps/features (with pictures/schematics).   Results (1-2 pages)  Structure based on research question(s) and/or experiments. Have 2-3 figures to support your claims. Explain each figure and summarize the findings.   Discussion (1/2 page)  First sentence: Summarize your findings. Discuss: What does it all mean? What have you learned? Future work?      When you\u0026rsquo;re done, zip up the PDF/DOC together with all your source code and upload the zip file to GauchoSpace.\nDon\u0026rsquo;t forget to submit your source code.\nAcademic Integrity The University of California has formal policies related to academic integrity.\nAny act of academic dishonesty, such as cheating or plagiarism, will result in a University disciplinary action and an \u0026ldquo;F\u0026rdquo; in this course. In addition to academic integrity, I also expect everyone in this class to treat their fellow students and course staff with respect.\nBasic Needs If you are facing any challenges securing food or housing and believe this may affect your performance in the class, you are urged to meet with a Food Security and Calfresh Advocate who is aware of the broad variety of resources that UCSB has to offer (see their drop-in hours at food.ucsb.edu). You are also urged to contact the professor if you are comfortable doing so.\nPlease visit food.ucsb.edu for additional resources including Calfresh, the AS Food Bank, and more.\n","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577836800,"objectID":"e575d5ab26bf85a2b9d88aa8cefe5cd2","people":null,"permalink":"https://bionicvisionlab.org/teaching/2020-winter-cs291i/","publishdate":"2020-01-01T00:00:00Z","relpermalink":"/teaching/2020-winter-cs291i/","section":"teaching","summary":"This graduate course will introduce students to the multidisciplinary field of bionic vision, with an emphasis on both the computer science and neuroscience of the field.","title":"CS-291I: Bionic Vision","type":"teaching"},{"categories":null,"content":"Neuromorphic event‐based vision sensors are poised to dramatically improve the latency, robustness and power in applications ranging from smart sensing to autonomous driving and assistive technologies for people who are blind.\nSoon these sensors may power low vision aids and retinal implants, where the visual scene has to be processed quickly and efficiently before it is displayed. However, novel methods are needed to process the unconventional output of these sensors in order to unlock their potential.\n","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577836800,"objectID":"fd8775517ff4ebf614b1c8406a8ad65c","people":null,"permalink":"https://bionicvisionlab.org/research/event-based-vision/","publishdate":"2020-01-01T00:00:00Z","relpermalink":"/research/event-based-vision/","section":"research","summary":"Neuromorphic event-based vision sensors may soon power low vision aids and retinal implants, where the visual scene has to be processed quickly and efficiently before it is displayed.","title":"Event-Based Vision at the Edge","type":"research"},{"categories":null,"content":"There are known individual differences in both ability to learn the layout of novel environments and flexibility of strategies for navigating known environments. It is unclear, however, how navigational abilities and situational awareness are impacted by high-stress scenarios and whether augmented reality (AR) could be employed to enhance performance and situational awareness.\nThis project will investigate three core questions:\n How does a person\u0026rsquo;s navigational abilities change in extreme situations? How can we best train them for these situations? How can vision augmentation be employed to improve situational awareness?  ","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577836800,"objectID":"6d1aaa1b527886d7de38a9b9acd81f7c","people":null,"permalink":"https://bionicvisionlab.org/research/hight-stress-navigation/","publishdate":"2020-01-01T00:00:00Z","relpermalink":"/research/hight-stress-navigation/","section":"research","summary":"How do people's navigatioal abilities change in stressful conditions? How can we best train them for these situations? And how can vision augmentation be employed to improve situational awareness?","title":"Visual Navigation Under High-Stress Conditions","type":"research"},{"categories":[],"content":"","date":1570742503,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570742503,"objectID":"01d43ae4db26724f7e05489e59bab7d8","people":["Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2019-optimal-surgical-placement/","publishdate":"2019-10-10T14:21:43-07:00","relpermalink":"/publications/2019-optimal-surgical-placement/","section":"publications","summary":"We systematically explored the space of possible implant configurations to make recommendations for optimal intraocular positioning of Argus II.","title":"Model-based recommendations for optimal surgical placement of epiretinal implants","type":"publications"},{"categories":null,"content":"","date":1563321600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1563321600,"objectID":"a3097d298d06cb569e35f87e6e81a170","people":["Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2019-data-driven-models-human-neuroscience-neuroengineering/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publications/2019-data-driven-models-human-neuroscience-neuroengineering/","section":"publications","summary":"In this review, we provide an accessible primer to modern modeling approaches and highlight recent data-driven discoveries in the domains of neuroimaging, single-neuron and neuronal population responses, and device neuroengineering.","title":"Data-driven models in human neuroscience and neuroengineering","type":"publications"},{"categories":[],"content":"A new article appeared in PCMag to celebrate the inauguration of the Bionic Vision Lab at UCSB:\n Bionic vision might sound like science fiction, but Dr. Michael Beyeler is working on just that.\n  Originally from Switzerland, Dr. Beyeler is wrapping up his postdoctoral fellow at the University of Washington before moving to the University of California Santa Barbara this fall to head up the newly formed Bionic Vision Lab in the Departments of Computer Science and Psychological \u0026amp; Brain Sciences.\n  We spoke with him about this \u0026ldquo;deep fascination with the brain\u0026rdquo; and how he hopes his work will eventually be able to restore vision to the blind. Here are edited and condensed excerpts from our conversation.\n Read the full article here.\n","date":1562689740,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562689753,"objectID":"00c60f07f684f1b3efbeb9fa775c1b01","people":["Michael Beyeler"],"permalink":"https://bionicvisionlab.org/post/2019-07-pcmag/","publishdate":"2019-07-09T09:29:00-07:00","relpermalink":"/post/2019-07-pcmag/","section":"post","summary":"Michael Beyeler recently sat down with PCMag to talk about bionic vision and his move to UC Santa Barbara.","title":"PCMag: Restoring vision with bionic eyes - no longer science fiction","type":"post"},{"categories":null,"content":"","date":1561593600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1561593600,"objectID":"386c91297fe76d33fc00b9225d6ec9dd","people":["Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2019-neural-correlates-sparse-coding-dimensionality-reduction/","publishdate":"2019-06-27T00:00:00Z","relpermalink":"/publications/2019-neural-correlates-sparse-coding-dimensionality-reduction/","section":"publications","summary":"Brains face the fundamental challenge of extracting relevant information from high-dimensional external stimuli in order to form the neural basis that can guide an organism's behavior and its interaction with the world. One potential approach to addressing this challenge is to reduce the number of variables required to represent a particular input space (i.e., dimensionality reduction). We review compelling evidence that a range of neuronal responses can be understood as an emergent property of nonnegative sparse coding (NSC)—a form of efficient population coding due to dimensionality reduction and sparsity constraints.","title":"Neural correlates of sparse coding and dimensionality reduction","type":"publications"},{"categories":null,"content":"","date":1561334400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1561334400,"objectID":"9aade570f250a8bdf7d19bf2115101b8","people":["Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2019-axon-map-model/","publishdate":"2019-06-24T00:00:00Z","relpermalink":"/publications/2019-axon-map-model/","section":"publications","summary":"We show that the perceptual experience of retinal implant users can be accurately predicted using a computational model that simulates each individual patient’s retinal ganglion axon pathways.","title":"A model of ganglion axon pathways accounts for percepts elicited by retinal implants","type":"publications"},{"categories":null,"content":"","date":1558310400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1558310400,"objectID":"c444c103408be4d6a1dbd752616ec318","people":["Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2019-biophysical-model-axonal-stimulation/","publishdate":"2019-05-20T00:00:00Z","relpermalink":"/publications/2019-biophysical-model-axonal-stimulation/","section":"publications","summary":"To investigate the effect of axonal stimulation on the retinal response, we developed a computational model of a small population of morphologically and biophysically detailed retinal ganglion cells, and simulated their response to epiretinal electrical stimulation. We found that activation thresholds of ganglion cell somas and axons varied systematically with both stimulus pulse duration and electrode-retina distance. These findings have important implications for the improvement of stimulus encoding methods for epiretinal prostheses.","title":"Biophysical model of axonal stimulation in epiretinal visual prostheses","type":"publications"},{"categories":null,"content":"","date":1557446400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557446400,"objectID":"7364a8adf91ea84cc0fbbd0c04424708","people":["Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2019-retinal-sheet-transplants/","publishdate":"2019-05-10T00:00:00Z","relpermalink":"/publications/2019-retinal-sheet-transplants/","section":"publications","summary":"A Commentary on: Detailed Visual Cortical Responses Generated by Retinal Sheet Transplants in Rats with Severe Retinal Degeneration by Foik, A. T., Lean, G. A., Scholl, L. R., McLelland, B. T., Mathur, A., Aramant, R. B., et al. (2018). J. Neurosci. 38, 10709–10724. doi: 10.1523/JNEUROSCI.1279-18.2018","title":"Commentary: Detailed visual cortical responses generated by retinal sheet transplants in rats with severe retinal degeneration","type":"publications"},{"categories":null,"content":"","date":1531440000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1531440000,"objectID":"096961db4e57e2fb4d3906e8230e49cf","people":["Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2018-carlsim4/","publishdate":"2018-07-13T00:00:00Z","relpermalink":"/publications/2018-carlsim4/","section":"publications","summary":"We have developed CARLsim 4, a user-friendly SNN library written in C++ that can simulate large biologically detailed neural networks. Improving on the efficiency and scalability of earlier releases, the present release allows for the simulation using multiple GPUs and multiple CPU cores concurrently in a heterogeneous computing cluster. Benchmarking results demonstrate simulation of 8.6 million neurons and 0.48 billion synapses using 4 GPUs and up to 60x speedup for multi-GPU implementations over a single-threaded CPU implementation, making CARLsim 4 well-suited for large-scale SNN models in the presence of real-time constraints.","title":"CARLsim 4: An open source library for large scale, biologically detailed spiking neural network simulation using heterogeneous clusters","type":"publications"},{"categories":null,"content":"","date":1503360000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1503360000,"objectID":"b5e80da46501c93df7df8c6fb3c5fc7f","people":["Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2017-learning-to-see-again/","publishdate":"2017-08-22T00:00:00Z","relpermalink":"/publications/2017-learning-to-see-again/","section":"publications","summary":"The goal of this review is to summarize the vast basic science literature on developmental and adult cortical plasticity with an emphasis on how this literature might relate to the field of prosthetic vision.","title":"Learning to see again: Biological constraints on cortical plasticity and the implications for sight restoration technologies","type":"publications"},{"categories":null,"content":"","date":1498867200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1498867200,"objectID":"0f9bbe69fd665667e284936ab7bda6e7","people":["Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2017-pulse2percept/","publishdate":"2017-07-01T00:00:00Z","relpermalink":"/publications/2017-pulse2percept/","section":"publications","summary":"*pulse2percept* is an open-source Python simulation framework used to predict the perceptual experience of retinal prosthesis patients across a wide range of implant configurations.","title":"pulse2percept: A Python-based simulation framework for bionic vision","type":"publications"},{"categories":null,"content":"","date":1470009600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1470009600,"objectID":"6010a0be9a85e86c6ad356a4d230a9e2","people":["Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2016-sparse-decomposition-model/","publishdate":"2016-08-01T00:00:00Z","relpermalink":"/publications/2016-sparse-decomposition-model/","section":"publications","summary":"Using a dimensionality reduction technique known as non-negative matrix factorization, we found that a variety of medial superior temporal (MSTd) neural response properties could be derived from MT-like input features. The responses that emerge from this technique, such as 3D translation and rotation selectivity, spiral tuning, and heading selectivity, can account for a number of empirical results. These findings (1) provide a further step toward a scientific understanding of the often nonintuitive response properties of MSTd neurons; (2) suggest that response properties, such as complex motion tuning and heading selectivity, might simply be a byproduct of MSTd neurons performing dimensionality reduction on their inputs; and (3) imply that motion perception in the cortex is consistent with ideas from the efficient-coding and free-energy principles.","title":"3D visual response properties of MSTd emerge from an efficient, sparse population code","type":"publications"},{"categories":null,"content":"","date":1448928000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1448928000,"objectID":"de49b660f9fc238f3af998f4dfc28f79","people":["Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2015-gpu-visually-guided-robot-navigation/","publishdate":"2015-12-01T00:00:00Z","relpermalink":"/publications/2015-gpu-visually-guided-robot-navigation/","section":"publications","summary":"We present a cortical neural network model for visually guided navigation that has been embodied on a physical robot exploring a real-world environment. The model includes a rate based motion energy model for area V1, and a spiking neural network model for cortical area MT. The model generates a cortical representation of optic flow, determines the position of objects based on motion discontinuities, and combines these signals with the representation of a goal location to produce motor commands that successfully steer the robot around obstacles toward the goal. This study demonstrates how neural signals in a model of cortical area MT might provide sufficient motion information to steer a physical robot on human-like paths around obstacles in a real-world environment.","title":"A GPU-accelerated cortical neural network model for visually guided robot navigation","type":"publications"},{"categories":null,"content":"","date":1436659200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1436659200,"objectID":"4c7bedf1cb0d806fe2aece390417d28c","people":["Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2015-carlsim3/","publishdate":"2015-07-12T00:00:00Z","relpermalink":"/publications/2015-carlsim3/","section":"publications","summary":"We have developed CARLsim 3, a user-friendly, GPU-accelerated SNN library written in C/C++ that is capable of simulating biologically detailed neural models. The present release of CARLsim provides a number of improvements over our prior SNN library to allow the user to easily analyze simulation data, explore synaptic plasticity rules, and automate parameter tuning. In the present paper, we provide examples and performance benchmarks highlighting the library's features.","title":"CARLsim 3: A user-friendly and highly optimized library for the creation of neurobiologically detailed spiking neural networks","type":"publications"},{"categories":null,"content":"","date":1401580800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1401580800,"objectID":"9dfaef9074cb247761c6511079679203","people":["Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2014-vision-road-lane-detection/","publishdate":"2014-06-01T00:00:00Z","relpermalink":"/publications/2014-vision-road-lane-detection/","section":"publications","summary":"This paper presents an integrative approach to ego-lane detection that aims to be as simple as possible to enable real-time computation while being able to adapt to a variety of urban and rural traffic scenarios. The approach at hand combines and extends a road segmentation method in an illumination-invariant color image, lane markings detection using a ridge operator, and road geometry estimation using RANdom SAmple Consensus (RANSAC). The power and robustness of this algorithm has been demonstrated in a car simulation system as well as in the challenging KITTI data base of real-world urban traffic scenarios.","title":"Vision-based robust road lane detection in urban environments","type":"publications"},{"categories":null,"content":"","date":1391558400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1391558400,"objectID":"a53663b6b62012e138a0743d6e6dfef2","people":["Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2014-snn-pattern-motion/","publishdate":"2014-01-20T00:00:00Z","relpermalink":"/publications/2014-snn-pattern-motion/","section":"publications","summary":"We present a two-stage model of visual area MT that we believe to be the first large-scale spiking network to demonstrate pattern direction selectivity. In this model, component-direction-selective (CDS) cells in MT linearly combine inputs from V1 cells that have spatiotemporal receptive fields according to the motion energy model of Simoncelli and Heeger. Pattern-direction-selective (PDS) cells in MT are constructed by pooling over MT CDS cells with a wide range of preferred directions. Responses of our model neurons are comparable to electrophysiological results for grating and plaid stimuli as well as speed tuning.","title":"Efficient spiking neural network model of pattern motion selectivity in visual cortex","type":"publications"},{"categories":null,"content":"","date":1390176000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1390176000,"objectID":"da2f3225cbcc97db91c2933db3c0c0ee","people":["Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2014-gpgpu-accelerated-simulation-parameter-tuning/","publishdate":"2014-01-20T00:00:00Z","relpermalink":"/publications/2014-gpgpu-accelerated-simulation-parameter-tuning/","section":"publications","summary":"We describe a simulation environment that can be used to design, construct, and run spiking neural networks (SNNs) quickly and efficiently using graphics processing units (GPUs). We then explain how the design of the simulation environment utilizes the parallel processing power of GPUs to simulate large-scale SNNs and describe recent modeling experiments performed using the simulator. Finally, we present an automated parameter tuning framework that utilizes the simulation environment and evolutionary algorithms to tune SNNs.","title":"GPGPU accelerated simulation and parameter tuning for neuromorphic applications","type":"publications"},{"categories":null,"content":"","date":1385856000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1385856000,"objectID":"e469311b24ad43d62ae7a26f056d1942","people":["Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2013-categorization-mnist-stdp/","publishdate":"2013-12-01T00:00:00Z","relpermalink":"/publications/2013-categorization-mnist-stdp/","section":"publications","summary":"We present a large-scale model of a hierarchical spiking neural network (SNN) that integrates a low-level memory encoding mechanism with a higher-level decision process to perform a visual classification task in real-time. The model consists of Izhikevich neurons and conductance-based synapses for realistic approximation of neuronal dynamics, a spike-timing-dependent plasticity (STDP) synaptic learning rule with additional synaptic dynamics for memory encoding, and an accumulator model for memory retrieval and categorization. The full network, which comprised 71,026 neurons and approximately 133 million synapses, ran in real-time on a single off-the-shelf graphics processing unit (GPU). The network achieved 92% correct classifications on MNIST in 100 rounds of random sub-sampling, which is comparable to other SNN approaches and provides a conservative and reliable performance metric. Additionally, the model correctly predicted reaction times from psychophysical experiments. Because of the scalability of the approach and its neurobiological fidelity, the current model can be extended to an efficient neuromorphic implementation that supports more generalized object recognition and decision-making architectures found in the brain.","title":"Categorization and decision-making in a neurobiologically plausible spiking network using a STDP-like plasticity rule","type":"publications"},{"categories":null,"content":"","date":1288569600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1288569600,"objectID":"1df3e4d282d890015a5345a70810e5d6","people":["Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2010-exploring-olfactory-networks/","publishdate":"2010-11-01T00:00:00Z","relpermalink":"/publications/2010-exploring-olfactory-networks/","section":"publications","summary":"Olfactory stimuli are represented in a high-dimensional space by neural networks of the olfactory system. While a number of studies have illustrated the importance of inhibitory networks within the olfactory bulb or the antennal lobe for the shaping and processing of olfactory information, it is not clear how exactly these inhibitory networks are organized to provide filtering and contrast enhancement capabilities. In this work the aim is to study the topology of the proposed networks by using software simulations and hardware implementation. While we can study the dependence of the activity on each parameter of the theoretical models with the simulations, it is important to understand whether the models can be used in robotic applications for real-time odor recognition. We present the results of a linear simulation, a spiking simulation with I\u0026F neurons and a real-time hardware emulation using neuromorphic VLSI chips.","title":"Exploring olfactory sensory networks: Simulations and hardware emulation","type":"publications"},{"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"0345abb3184f3021cfe981d9c1b0ead1","people":[],"permalink":"https://bionicvisionlab.org/collaborators/boynton_geoff/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/collaborators/boynton_geoff/","section":"collaborators","summary":"","title":"","type":"collaborators"},{"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"e81cc6a213259bcccd0481e866fc4f73","people":[],"permalink":"https://bionicvisionlab.org/collaborators/brunton_bing/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/collaborators/brunton_bing/","section":"collaborators","summary":"","title":"","type":"collaborators"},{"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"d159791a8442e301af2f6ce0f7b65bb5","people":[],"permalink":"https://bionicvisionlab.org/collaborators/dagnelie_gislin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/collaborators/dagnelie_gislin/","section":"collaborators","summary":"","title":"","type":"collaborators"},{"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"cbd88cd6538699a558bbbcd23229ab06","people":[],"permalink":"https://bionicvisionlab.org/collaborators/eckstein_miguel/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/collaborators/eckstein_miguel/","section":"collaborators","summary":"","title":"","type":"collaborators"},{"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"e0941d3038b77f624edd5c354cfe2612","people":[],"permalink":"https://bionicvisionlab.org/collaborators/fernandez_eduardo/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/collaborators/fernandez_eduardo/","section":"collaborators","summary":"","title":"","type":"collaborators"},{"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"bd76d6c0532e954c7a69a73fc2b83f16","people":[],"permalink":"https://bionicvisionlab.org/collaborators/fine_ione/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/collaborators/fine_ione/","section":"collaborators","summary":"","title":"","type":"collaborators"},{"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"124fe87861e790e184e6a15a299416f0","people":[],"permalink":"https://bionicvisionlab.org/collaborators/giesbrecht_barry/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/collaborators/giesbrecht_barry/","section":"collaborators","summary":"","title":"","type":"collaborators"},{"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"08cb4baf0e819a154a89d51ccf472b0a","people":[],"permalink":"https://bionicvisionlab.org/collaborators/goard_michael/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/collaborators/goard_michael/","section":"collaborators","summary":"","title":"","type":"collaborators"},{"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"5aa56499202dd4f4d2674829cdead929","people":[],"permalink":"https://bionicvisionlab.org/collaborators/grafton_scott/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/collaborators/grafton_scott/","section":"collaborators","summary":"","title":"","type":"collaborators"},{"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"4c0e7e578fe0a2de11ccdf2b92688825","people":[],"permalink":"https://bionicvisionlab.org/collaborators/hegarty_mary/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/collaborators/hegarty_mary/","section":"collaborators","summary":"","title":"","type":"collaborators"},{"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"826508bc3d1b39eb7e478070cf266785","people":[],"permalink":"https://bionicvisionlab.org/collaborators/montezuma_sandra/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/collaborators/montezuma_sandra/","section":"collaborators","summary":"","title":"","type":"collaborators"},{"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"6c8afc0395cca73b0f99c53bfdf0e212","people":[],"permalink":"https://bionicvisionlab.org/collaborators/niell_cris/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/collaborators/niell_cris/","section":"collaborators","summary":"","title":"","type":"collaborators"},{"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"74edf1fcd71e82ad16afe5f271aa8723","people":[],"permalink":"https://bionicvisionlab.org/collaborators/open_ra/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/collaborators/open_ra/","section":"collaborators","summary":"","title":"","type":"collaborators"},{"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"b194678a7a6a010af51b3a392b87fdf4","people":[],"permalink":"https://bionicvisionlab.org/collaborators/open_student/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/collaborators/open_student/","section":"collaborators","summary":"","title":"","type":"collaborators"},{"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"a53ebfbe9e0f7c87114a1f4ff9c06cf1","people":[],"permalink":"https://bionicvisionlab.org/collaborators/rokem_ariel/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/collaborators/rokem_ariel/","section":"collaborators","summary":"","title":"","type":"collaborators"},{"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"0302f9c6a7657d8d70c47c800a1047ae","people":[],"permalink":"https://bionicvisionlab.org/collaborators/second_sight/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/collaborators/second_sight/","section":"collaborators","summary":"","title":"","type":"collaborators"},{"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"6636f6af3ca44951f03a6496c0f51b51","people":[],"permalink":"https://bionicvisionlab.org/collaborators/smith_spencer/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/collaborators/smith_spencer/","section":"collaborators","summary":"","title":"","type":"collaborators"},{"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f19bf5bee0480291e98f9538f6ec0325","people":[],"permalink":"https://bionicvisionlab.org/collaborators/weiland_jim/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/collaborators/weiland_jim/","section":"collaborators","summary":"","title":"","type":"collaborators"},{"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"a1b2db76f8bcd92aee74d434c799bf16","people":[],"permalink":"https://bionicvisionlab.org/grants/2021-r01-mouse/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/grants/2021-r01-mouse/","section":"grants","summary":"","title":"Cortical visual processing for navigation","type":"grants"},{"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"d1700e2bc315bd058766abe8cb79f635","people":[],"permalink":"https://bionicvisionlab.org/grants/2021-ucsb-academic-senate/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/grants/2021-ucsb-academic-senate/","section":"grants","summary":"","title":"Event-based scene understanding for bionic vision","type":"grants"},{"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"449e696159cfd0650277154e94d8219e","people":[],"permalink":"https://bionicvisionlab.org/grants/2020-r00-virtual-prototyping/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/grants/2020-r00-virtual-prototyping/","section":"grants","summary":"","title":"Virtual prototyping for retinal prosthesis patients","type":"grants"},{"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"4e6594480155b2f52ee673351ff91384","people":[],"permalink":"https://bionicvisionlab.org/grants/2021-icb-army/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/grants/2021-icb-army/","section":"grants","summary":"","title":"Visual navigation under high-stress conditions","type":"grants"}]