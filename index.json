[{"categories":null,"content":"Kartik Adimulam is a 3rd-year undergraduate Statistics \u0026amp; Data Science major at UC Santa Barbara. He is fascinated by the use of artificial intelligence and computational neuroscience to solve modern-day health issues.\nWhen he is not learning about data science or pursuing his interests as a researcher, he enjoys watching podcasts and playing basketball with his fraternity. He also enjoys working on supplementary personal data science projects focused on algorithmic trading.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"aa3a035221076ec1176ef33e8345f724","people":["adimulam_kartik"],"permalink":"https://bionicvisionlab.org/people/adimulam_kartik/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/adimulam_kartik/","section":"people","summary":"Kartik Adimulam is a 3rd-year undergraduate Statistics \u0026amp; Data Science major at UC Santa Barbara. He is fascinated by the use of artificial intelligence and computational neuroscience to solve modern-day health issues.\nWhen he is not learning about data science or pursuing his interests as a researcher, he enjoys watching podcasts and playing basketball with his fraternity. He also enjoys working on supplementary personal data science projects focused on algorithmic trading.","title":"Kartik Adimulam","type":"people"},{"categories":null,"content":"Fatima Aguilar is an undergraduate student pursuing English and Sociology degrees at UC Santa Barbara.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"6867db52395ad48cf20de05fbff1f17d","people":["aguilar_fatima"],"permalink":"https://bionicvisionlab.org/people/aguilar_fatima/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/aguilar_fatima/","section":"people","summary":"Fatima Aguilar is an undergraduate student pursuing English and Sociology degrees at UC Santa Barbara.","title":"Fatima Aguilar","type":"people"},{"categories":null,"content":"Michael Beyeler directs the Bionic Vision Lab at UC Santa Barbara.\nHe received a PhD in Computer Science from UC Irvine as well as a BS in Electrical Engineering and a MS in Biomedical Engineering from ETH Zurich, Switzerland. Prior to joining UCSB in 2019, he completed a postdoctoral fellowship in the labs of Ione Fine (Psychology, Institute for Neuroengineering) and Ariel Rokem (eScience Institute) at the University of Washington, where he developed computational models of bionic vision.\nHe is Associate Director of the UCSB Center for Virtual Environments and Behavior (ReCVEB) and recipient of the National Institutes of Health (NIH) K99/R00 Pathway to Independence Award as well as the prestigious DP2 New Innovator Award.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"9b65f6e0cdcdd6af799cdb43ac4127dc","people":["beyeler_michael"],"permalink":"https://bionicvisionlab.org/people/beyeler_michael/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/beyeler_michael/","section":"people","summary":"Michael Beyeler directs the Bionic Vision Lab at UC Santa Barbara.\nHe received a PhD in Computer Science from UC Irvine as well as a BS in Electrical Engineering and a MS in Biomedical Engineering from ETH Zurich, Switzerland. Prior to joining UCSB in 2019, he completed a postdoctoral fellowship in the labs of Ione Fine (Psychology, Institute for Neuroengineering) and Ariel Rokem (eScience Institute) at the University of Washington, where he developed computational models of bionic vision.","title":"Michael Beyeler","type":"people"},{"categories":null,"content":"Anissa Carter is a Promise Scholar and second-year student in the Department of Computer Science. She is interested in applying computer science to the furtherment of the medical field.\nIn her spare time, she loves to swim, bike, and hike.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"4f189bb2ce5ea013e0566250eb940bcd","people":["carter_anissa"],"permalink":"https://bionicvisionlab.org/people/carter_anissa/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/carter_anissa/","section":"people","summary":"Anissa Carter is a Promise Scholar and second-year student in the Department of Computer Science. She is interested in applying computer science to the furtherment of the medical field.\nIn her spare time, she loves to swim, bike, and hike.","title":"Anissa Carter","type":"people"},{"categories":null,"content":"Juliana Chou is currently a fourth-year student pursuing a Biopsychology degree at UC Santa Barbara. She is interested in learning more about neuroprosthetics and deep learning.\nShe also serves as a mentor in UCSB\u0026rsquo;s Undergraduate Mentorship Program and is a research assistant in the Keiflin Lab, investigating neural networks implicated in context-based decision making.\nIn her free time she enjoys trying out new recipes and watching sunsets with friends.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"295592e781a0e054c41bca1d82f0b190","people":["chou_juliana"],"permalink":"https://bionicvisionlab.org/people/chou_juliana/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/chou_juliana/","section":"people","summary":"Juliana Chou is currently a fourth-year student pursuing a Biopsychology degree at UC Santa Barbara. She is interested in learning more about neuroprosthetics and deep learning.\nShe also serves as a mentor in UCSB\u0026rsquo;s Undergraduate Mentorship Program and is a research assistant in the Keiflin Lab, investigating neural networks implicated in context-based decision making.\nIn her free time she enjoys trying out new recipes and watching sunsets with friends.","title":"Juliana Chou","type":"people"},{"categories":null,"content":"Yongtak (Dylan) Chung is an undergraduate student pursuing a degree in Computer Science at UC Santa Barbara.\nHe is interested in the field of natural language processing and is particularly intrigued by the Transformer architecture. In his free time he likes to work on side projects, weight lift, and conduct research on what his favorite TV show is.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"643a8578193d1d9b8af1b9ce3f22a028","people":["chung_yontak"],"permalink":"https://bionicvisionlab.org/people/chung_yongtak/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/chung_yongtak/","section":"people","summary":"Yongtak (Dylan) Chung is an undergraduate student pursuing a degree in Computer Science at UC Santa Barbara.\nHe is interested in the field of natural language processing and is particularly intrigued by the Transformer architecture. In his free time he likes to work on side projects, weight lift, and conduct research on what his favorite TV show is.","title":"Yongtak (Dylan) Chung","type":"people"},{"categories":null,"content":"Edward Ding is currently a second year undergraduate student pursuing a Computer Engineering degree at UC Santa Barbara. He is interested in the world of computer vision, control systems, robotics engineering and machine learning. He is especially intrigued by the relation of those subjects to computer architecture and hardware design.\nEdward also currently serves as an Undergraduate Learning Assistant (ULA) for the Computer Science Department\u0026rsquo;s introductory CMPSC 16 class, tutoring and mentoring first year CS and CE students.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"cd60dfcff7b37ae7747249942edfa46c","people":["ding_edward"],"permalink":"https://bionicvisionlab.org/people/ding_edward/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/ding_edward/","section":"people","summary":"Edward Ding is currently a second year undergraduate student pursuing a Computer Engineering degree at UC Santa Barbara. He is interested in the world of computer vision, control systems, robotics engineering and machine learning. He is especially intrigued by the relation of those subjects to computer architecture and hardware design.\nEdward also currently serves as an Undergraduate Learning Assistant (ULA) for the Computer Science Department\u0026rsquo;s introductory CMPSC 16 class, tutoring and mentoring first year CS and CE students.","title":"Edward Ding","type":"people"},{"categories":null,"content":"Harshita Gangaswamy is currently a third-year undergraduate student pursuing a Computer Engineering degree at UC Santa Barbara. She is interested in deep learning and computational neuroscience.\nWhen she is not studying and doing research, she enjoys reading novels and watching TV shows with her roommates and friends. She has also been volunteering to teach kids through the Society of Women Engineers.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"81655537f54e185163d76eaa9966c64b","people":["gangaswamy_harshita"],"permalink":"https://bionicvisionlab.org/people/gangaswamy_harshita/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/gangaswamy_harshita/","section":"people","summary":"Harshita Gangaswamy is currently a third-year undergraduate student pursuing a Computer Engineering degree at UC Santa Barbara. She is interested in deep learning and computational neuroscience.\nWhen she is not studying and doing research, she enjoys reading novels and watching TV shows with her roommates and friends. She has also been volunteering to teach kids through the Society of Women Engineers.","title":"Harshita Gangaswamy","type":"people"},{"categories":null,"content":"Umang is a graduate student pursuing Integrated MS-PhD program in the ECE Department at UCSB. He is primarily interested in machine learning, vision systems, and computationally efficient brain-inspired algorithms. He is passionate about employing these algorithms to design fast and robust edge-vision systems dedicated to tasks like object recognition and tracking.\nOff work, you can generally find him hiking on weekends.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"604ed37d3cc978d3cd8a23603785471e","people":["garg_umang"],"permalink":"https://bionicvisionlab.org/people/garg_umang/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/garg_umang/","section":"people","summary":"Umang is a graduate student pursuing Integrated MS-PhD program in the ECE Department at UCSB. He is primarily interested in machine learning, vision systems, and computationally efficient brain-inspired algorithms. He is passionate about employing these algorithms to design fast and robust edge-vision systems dedicated to tasks like object recognition and tracking.\nOff work, you can generally find him hiking on weekends.","title":"Umang Garg","type":"people"},{"categories":null,"content":"Olivia Gettner is an undergraduate student pursuing a Biopsychology degree at UC Santa Barbara.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"d1e6c0722f0477c5b8055247d37216a4","people":["gettner_olivia"],"permalink":"https://bionicvisionlab.org/people/gettner_olivia/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/gettner_olivia/","section":"people","summary":"Olivia Gettner is an undergraduate student pursuing a Biopsychology degree at UC Santa Barbara.","title":"Olivia Gettner","type":"people"},{"categories":null,"content":"Lucas Gil Nadolskis is currently a Graduate Student Researcher in the Bionic Vision Lab.\nLucas got his BS in Computer Science with a minor in Neuroscience from the University of Minnesota in 2021, where he performed research related to autonomous navigation, computer vision and brain-computer interfaces. Later, he got his MS in Biomedical Engineering from Carnegie Mellon University, where his primary work focused on analyzing top-down pathways of the visual system and how this could be integrated into cortical implants for the blind. In addition, he worked with the Human-Computer Interaction department on issues related to accessibility in data visualization, an area that he still seeks to explore in the future.\nStarting Fall \u0026lsquo;23, Lucas will be a PhD student in the Interdepartmental Graduate Program in Dynamical Neuroscience (DYNS) at UC Santa Barbara, where he will investigate novel ways to approach cortical implants for the blind. Being blind himself since the age of five, Lucas\u0026rsquo; interests are broad, ranging from neuroscience to accessibility, but can be summarized as efforts to improve the lives of blind people around the world.\nOutside of the lab, most of his free time is occupied by music, traveling and searching for audio-described content.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"20ca85f22e16a1a06fc09c6075f8eb35","people":["gil_nadolskis_lucas"],"permalink":"https://bionicvisionlab.org/people/gil_nadolskis_lucas/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/gil_nadolskis_lucas/","section":"people","summary":"Lucas Gil Nadolskis is currently a Graduate Student Researcher in the Bionic Vision Lab.\nLucas got his BS in Computer Science with a minor in Neuroscience from the University of Minnesota in 2021, where he performed research related to autonomous navigation, computer vision and brain-computer interfaces. Later, he got his MS in Biomedical Engineering from Carnegie Mellon University, where his primary work focused on analyzing top-down pathways of the visual system and how this could be integrated into cortical implants for the blind.","title":"Lucas Gil Nadolskis","type":"people"},{"categories":null,"content":"Isabella Gonzalez is currently a fourth-year undergraduate student pursuing a Biopsychology degree at UC Santa Barbara with a minor in Spanish. She is interested in low vision and neuroprosthetics. Isabella will pursue a career in the medical field and is especially passionate about providing healthcare to underserved populations. She currently is part of a medical brigade club at UCSB and volunteers at the hospital.\nIn her free time, Isabella enjoys yoga, ballet, and pottery.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"42c3358392f569cc675e258f5365b1f3","people":["gonzalez_isabella"],"permalink":"https://bionicvisionlab.org/people/gonzalez_isabella/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/gonzalez_isabella/","section":"people","summary":"Isabella Gonzalez is currently a fourth-year undergraduate student pursuing a Biopsychology degree at UC Santa Barbara with a minor in Spanish. She is interested in low vision and neuroprosthetics. Isabella will pursue a career in the medical field and is especially passionate about providing healthcare to underserved populations. She currently is part of a medical brigade club at UCSB and volunteers at the hospital.\nIn her free time, Isabella enjoys yoga, ballet, and pottery.","title":"Isabella Gonzalez","type":"people"},{"categories":null,"content":"Jacob Granley is a PhD student in the Department of Computer Science.\nPrior to joining UCSB, he received his Masters and Bachelors in Computer Science from Colorado School of Mines. He is pursuing his PhD under Dr. Beyeler as part of the Bionic Vision lab, where he hopes to use Computer Science and Machine Learning methods to help improve artificial vision technologies with the ultimate goal of restoring sight to the blind.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2b70b8d79cd7bf947cd51020510152a3","people":["granley_jacob"],"permalink":"https://bionicvisionlab.org/people/granley_jacob/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/granley_jacob/","section":"people","summary":"Jacob Granley is a PhD student in the Department of Computer Science.\nPrior to joining UCSB, he received his Masters and Bachelors in Computer Science from Colorado School of Mines. He is pursuing his PhD under Dr. Beyeler as part of the Bionic Vision lab, where he hopes to use Computer Science and Machine Learning methods to help improve artificial vision technologies with the ultimate goal of restoring sight to the blind.","title":"Jacob Granley","type":"people"},{"categories":null,"content":"Yolanda He is a second-year student pursuing a BS in Biopsychology at UC Santa Barbara. She is interested in studying psychophysics and low vision.\nIn her free time, she enjoys going to the beach, the gym, and downtown with her friends.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"52d4f2aef1fab9420d7926b4114dca16","people":["he_yolanda"],"permalink":"https://bionicvisionlab.org/people/he_yolanda/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/he_yolanda/","section":"people","summary":"Yolanda He is a second-year student pursuing a BS in Biopsychology at UC Santa Barbara. She is interested in studying psychophysics and low vision.\nIn her free time, she enjoys going to the beach, the gym, and downtown with her friends.","title":"Yolanda He","type":"people"},{"categories":null,"content":"Isaac Hoffman is currently a third-year student pursuing a Computer Science degree at UC Santa Barbara, with a minor in Speech and Language Technologies. He is interested in machine learning and creating systems which can enable the use of large-scale deep learning models in various fields outside of computing.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"60b915f53d0378d20063e9de6b28da6b","people":["hoffman_isaac"],"permalink":"https://bionicvisionlab.org/people/hoffman_isaac/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/hoffman_isaac/","section":"people","summary":"Isaac Hoffman is currently a third-year student pursuing a Computer Science degree at UC Santa Barbara, with a minor in Speech and Language Technologies. He is interested in machine learning and creating systems which can enable the use of large-scale deep learning models in various fields outside of computing.","title":"Isaac Hoffman","type":"people"},{"categories":null,"content":"Yuchen Hou is a PhD student in Computer Science at UC Santa Barbara. She is interested in computational neuroscience and machine learning. Her research goal is to model the dynamics of brain functions by integrating knowledge from computer, cognitive, and neural science.\nPrior to pursuing her PhD studies, she was an undergraduate research assistant in the Bionic Vision Lab with a BS degree in Psychological \u0026amp; Brain Sciences.\nIn her free time, she likes reading fiction books and watching action movies.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"e3745716f7ad68c766108f2e2cbeefef","people":["hou_yuchen"],"permalink":"https://bionicvisionlab.org/people/hou_yuchen/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/hou_yuchen/","section":"people","summary":"Yuchen Hou is a PhD student in Computer Science at UC Santa Barbara. She is interested in computational neuroscience and machine learning. Her research goal is to model the dynamics of brain functions by integrating knowledge from computer, cognitive, and neural science.\nPrior to pursuing her PhD studies, she was an undergraduate research assistant in the Bionic Vision Lab with a BS degree in Psychological \u0026amp; Brain Sciences.\nIn her free time, she likes reading fiction books and watching action movies.","title":"Yuchen Hou","type":"people"},{"categories":null,"content":"Byron is a PhD student in the Department of Psychological \u0026amp; Brain Sciences. He was born and raised in St. Louis, Missouri. He moved to New York City to study psychology, where he received a BA in Psychology from St. John’s University (2015) and then a MA in Behavioral Neuroscience from Queens College (2017). Byron worked as a Research Operations Manager at a start-up company that develops assistive products for blind and low vision individuals (2017 - 2020).\nByron\u0026rsquo;s main research interest is studying how image processing and psychophysics can be used to understand how low vision conditions affect visual tasks. Specifically, how combining computational models with simulated low vision impairment conditions can help inform and enhance individualized vision capabilities.\nByron is supervised by Dr. Michael Beyeler in the Bionic Vision Lab and Dr. Miguel Eckstein in the Vision and Image Understanding Lab.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"226dccd548b210ce20689586bc7b8aba","people":["johnson_byron"],"permalink":"https://bionicvisionlab.org/people/johnson_byron/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/johnson_byron/","section":"people","summary":"Byron is a PhD student in the Department of Psychological \u0026amp; Brain Sciences. He was born and raised in St. Louis, Missouri. He moved to New York City to study psychology, where he received a BA in Psychology from St. John’s University (2015) and then a MA in Behavioral Neuroscience from Queens College (2017). Byron worked as a Research Operations Manager at a start-up company that develops assistive products for blind and low vision individuals (2017 - 2020).","title":"Byron A. Johnson","type":"people"},{"categories":null,"content":"Justin Kasowksi transferred to UC Santa Barbara in 2016 after receiving associates degrees in Biological Sciences and Chemistry from Santa Barbara City College. In 2018, he graduated UCSB with a degree in Molecular, Cellular, and Developmental Biology.\nHe is pursuing his PhD under Dr. Michael Beyeler in the Bionic Vision Lab, where he utilizes virtual reality and computer vision to model the perceptual experience of retinal prosthesis patients.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"25e494b70e3d83523af0ee2774cf00aa","people":["kasowski_justin"],"permalink":"https://bionicvisionlab.org/people/kasowski_justin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/kasowski_justin/","section":"people","summary":"Justin Kasowksi transferred to UC Santa Barbara in 2016 after receiving associates degrees in Biological Sciences and Chemistry from Santa Barbara City College. In 2018, he graduated UCSB with a degree in Molecular, Cellular, and Developmental Biology.\nHe is pursuing his PhD under Dr. Michael Beyeler in the Bionic Vision Lab, where he utilizes virtual reality and computer vision to model the perceptual experience of retinal prosthesis patients.","title":"Justin Kasowski","type":"people"},{"categories":null,"content":"Mari Khachatryan is an undergraduate student pursuing a Biopsychology degree at UC Santa Barbara.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"4d177f7aec2451eb8391b43a0bb60d76","people":["khachatryan_mari"],"permalink":"https://bionicvisionlab.org/people/khachatryan_mari/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/khachatryan_mari/","section":"people","summary":"Mari Khachatryan is an undergraduate student pursuing a Biopsychology degree at UC Santa Barbara.","title":"Mari Khachatryan","type":"people"},{"categories":null,"content":"Sangita Kunapuli is a fourth-year undergraduate student studying Computer Science at UC Santa Barbara. She is passionate about applications of computer vision, deep learning, and using technology for good. Previously, Sangita contributed to the Where’s the Bear project with UCSB RACELab as part of the Early Research Scholars Program.\nIn her free time, Sangita enjoys singing a cappella with her team UCSB Ravaani, going to the gym, and journaling with a cup of tea.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"d62d32d64693279a72ec5a67d56a8a52","people":["kunapuli_sangita"],"permalink":"https://bionicvisionlab.org/people/kunapuli_sangita/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/kunapuli_sangita/","section":"people","summary":"Sangita Kunapuli is a fourth-year undergraduate student studying Computer Science at UC Santa Barbara. She is passionate about applications of computer vision, deep learning, and using technology for good. Previously, Sangita contributed to the Where’s the Bear project with UCSB RACELab as part of the Early Research Scholars Program.\nIn her free time, Sangita enjoys singing a cappella with her team UCSB Ravaani, going to the gym, and journaling with a cup of tea.","title":"Sangita Kunapuli","type":"people"},{"categories":null,"content":"Tori LeVer is a fourth-year undergraduate pursuing a B.S. in Psychological \u0026amp; Brain Sciences at UC Santa Barbara and lab manager in the Bionic Vision Lab.\nTori is interested at the intersection of social cognitive neuroscience, perception, and assistive technology.\nOutside of managing the lab, she is an RA with the LEAP Neuro lab (Lapate), where she is investigating the temporal coding of dynamic emotional experiences using behavioral and electrophysiological methods. She also is conducting her honors thesis with Dr. Hongbo Yu where she is investigating the moral standing of blame at a group level. After graduation, she hopes to pursue a PhD in computational or social cognitive neuroscience.\nIn her free time, Tori enjoys baking and decorating cakes as well as hosting car meets as the president of UCSB’s Gaucho Automotive Society.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"4055b36559805f4073b5aa897873b64e","people":["levier_tori"],"permalink":"https://bionicvisionlab.org/people/levier_tori/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/levier_tori/","section":"people","summary":"Tori LeVer is a fourth-year undergraduate pursuing a B.S. in Psychological \u0026amp; Brain Sciences at UC Santa Barbara and lab manager in the Bionic Vision Lab.\nTori is interested at the intersection of social cognitive neuroscience, perception, and assistive technology.\nOutside of managing the lab, she is an RA with the LEAP Neuro lab (Lapate), where she is investigating the temporal coding of dynamic emotional experiences using behavioral and electrophysiological methods.","title":"Tori LeVier","type":"people"},{"categories":null,"content":"Dariya (Dasha) Lobko is working towards a Biopsychology B.S. at UC Santa Barbara, graduating in 2024. Apart from her work in the Bionic Vision Lab, she also enjoys working as a research assistant in Dr. Miguel Eckstein\u0026rsquo;s Vision and Image Understanding (VIU) lab, where she assists graduate students in conducting psychophysical experiments. Dasha was extensively involved in investigating how imaging modulations can aid radiologists in diagnosing medical conditions (such as breast cancer) in visual search tasks, as part of Devi Klein\u0026rsquo;s project (PhD candidate).\nDasha was born and raised in Donetsk, Ukraine prior to moving to Santa Barbara in 2015. She works as a part time medical assistant in a neurology and neurosurgery clinic and has a special interest in patients experiencing neurovisual deficits. In her free time, Dasha enjoys staying active, volunteering at the hospital and helping humanitarian efforts in Ukraine through a local nonprofit.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"8003608e9a2282ebf240adcad8db497f","people":["lobko_dariya"],"permalink":"https://bionicvisionlab.org/people/lobko_dariya/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/lobko_dariya/","section":"people","summary":"Dariya (Dasha) Lobko is working towards a Biopsychology B.S. at UC Santa Barbara, graduating in 2024. Apart from her work in the Bionic Vision Lab, she also enjoys working as a research assistant in Dr. Miguel Eckstein\u0026rsquo;s Vision and Image Understanding (VIU) lab, where she assists graduate students in conducting psychophysical experiments. Dasha was extensively involved in investigating how imaging modulations can aid radiologists in diagnosing medical conditions (such as breast cancer) in visual search tasks, as part of Devi Klein\u0026rsquo;s project (PhD candidate).","title":"Dariya (Dasha) Lobko","type":"people"},{"categories":null,"content":"Xiankun Lu is currently a third-year undergraduate student pursuing a Physics degree at UC Santa Barbara. Before joining the lab, he worked as a Data Scientist in the High-Energy Physics research lab.\nOutside of lab, he enjoys philosophy, piloting, and symphonies. He has also been volunteering with the Physics Circus.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"09df714829d3f1df8c007b8adc349ea6","people":["lu_xiankun"],"permalink":"https://bionicvisionlab.org/people/lu_xiankun/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/lu_xiankun/","section":"people","summary":"Xiankun Lu is currently a third-year undergraduate student pursuing a Physics degree at UC Santa Barbara. Before joining the lab, he worked as a Data Scientist in the High-Energy Physics research lab.\nOutside of lab, he enjoys philosophy, piloting, and symphonies. He has also been volunteering with the Physics Circus.","title":"Xiankun Lu","type":"people"},{"categories":null,"content":"Nancy Mahmoud is an undergraduate student pursuing a Biopsychology degree at UC Santa Barbara.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"cc46e9d04b472d76234df10e2d5f7c60","people":["mahmoud_nancy"],"permalink":"https://bionicvisionlab.org/people/mahmoud_nancy/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/mahmoud_nancy/","section":"people","summary":"Nancy Mahmoud is an undergraduate student pursuing a Biopsychology degree at UC Santa Barbara.","title":"Nancy Mahmoud","type":"people"},{"categories":null,"content":"Megumi Ondo is an undergraduate student pursuing a Computer Science degree at UC Santa Barbara.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"8358514c18afa54abb731b4019cb684f","people":["ondo_megumi"],"permalink":"https://bionicvisionlab.org/people/ondo_megumi/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/ondo_megumi/","section":"people","summary":"Megumi Ondo is an undergraduate student pursuing a Computer Science degree at UC Santa Barbara.","title":"Megumi Ondo","type":"people"},{"categories":null,"content":"Jennifer is an undergraduate student working towards a BS in Biopsychology, with a minor in Applied Psychology. She is interested in cognitive neuroscience, social and development psychology, with plans of attending graduate school for therapy or social work.\nShe also enjoys trying new restaurants around Santa Barbara and being in nature with friends.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"8a9ae9275e74d40353a25b7464bbd8c4","people":["phung_jennifer"],"permalink":"https://bionicvisionlab.org/people/phung_jennifer/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/phung_jennifer/","section":"people","summary":"Jennifer is an undergraduate student working towards a BS in Biopsychology, with a minor in Applied Psychology. She is interested in cognitive neuroscience, social and development psychology, with plans of attending graduate school for therapy or social work.\nShe also enjoys trying new restaurants around Santa Barbara and being in nature with friends.","title":"Jennifer Phung","type":"people"},{"categories":null,"content":"Galen Pogoncheff joined the Bionic Vision Lab in 2022 as a PhD student in the Computer Science department. Driven to improve the processing of visual stimuli for bionic vision devices, he aims to advance techniques in computer vision using mechanisms inspired by neural processing.\nPrior to joining the lab, Galen obtained his B.S. and M.S. in Computer Science from the University of Colorado and subsequently led the research and development of machine learning models for wearable electrophysiology devices at a local startup.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"4438a2bc07066689cc572fd851af41ff","people":["pogoncheff_galen"],"permalink":"https://bionicvisionlab.org/people/pogoncheff_galen/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/pogoncheff_galen/","section":"people","summary":"Galen Pogoncheff joined the Bionic Vision Lab in 2022 as a PhD student in the Computer Science department. Driven to improve the processing of visual stimuli for bionic vision devices, he aims to advance techniques in computer vision using mechanisms inspired by neural processing.\nPrior to joining the lab, Galen obtained his B.S. and M.S. in Computer Science from the University of Colorado and subsequently led the research and development of machine learning models for wearable electrophysiology devices at a local startup.","title":"Galen Pogoncheff","type":"people"},{"categories":null,"content":"Laya Pullela is a BS Student in the College of Creative Studies and a member of the Bionic Vision Lab at UC Santa Barbara. She is interested in applying machine learning and computational biology to medical applications.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"f675e7132e9275e87bc12f0df2acf858","people":["pullela_laya"],"permalink":"https://bionicvisionlab.org/people/pullela_laya/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/pullela_laya/","section":"people","summary":"Laya Pullela is a BS Student in the College of Creative Studies and a member of the Bionic Vision Lab at UC Santa Barbara. She is interested in applying machine learning and computational biology to medical applications.","title":"Laya Pullela","type":"people"},{"categories":null,"content":"Ethan Roma is currently a fourth-year undergraduate student pursuing a Biopsychology degree in the College of Letters and Science at UC Santa Barbara. He wants to learn more about the behavioral and physiological causes of losses in sensation such as sight, and how technical prosthetics might be enabled/designed to address said losses.\nIn his free time, he enjoys making music, skateboarding, and late night drive-thrus with his friends.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"9188420eb57f9c4d5eaeb4041f21cb90","people":["roma_ethan"],"permalink":"https://bionicvisionlab.org/people/roma_ethan/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/roma_ethan/","section":"people","summary":"Ethan Roma is currently a fourth-year undergraduate student pursuing a Biopsychology degree in the College of Letters and Science at UC Santa Barbara. He wants to learn more about the behavioral and physiological causes of losses in sensation such as sight, and how technical prosthetics might be enabled/designed to address said losses.\nIn his free time, he enjoys making music, skateboarding, and late night drive-thrus with his friends.","title":"Ethan Roma","type":"people"},{"categories":null,"content":"Callie Sardina is a first year student pursuing a MS in Computer Science at UCSB. She is interested in machine learning, deep learning, computational vision, and theoretical computer science. She is passionate about employing computer science within the realm of medical sciences to help make a positive impact on people\u0026rsquo;s well-being.\nIn her free time, you\u0026rsquo;ll find Callie painting, watching sunsets, and doing gymnastics.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"9e447bfec019140e16831484d15d68f1","people":["sardina_callie"],"permalink":"https://bionicvisionlab.org/people/sardina_callie/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/sardina_callie/","section":"people","summary":"Callie Sardina is a first year student pursuing a MS in Computer Science at UCSB. She is interested in machine learning, deep learning, computational vision, and theoretical computer science. She is passionate about employing computer science within the realm of medical sciences to help make a positive impact on people\u0026rsquo;s well-being.\nIn her free time, you\u0026rsquo;ll find Callie painting, watching sunsets, and doing gymnastics.","title":"Callie Sardina","type":"people"},{"categories":null,"content":"Eirini Schoinas is currently a first-year undergraduate student pursuing a Computing degree in the College of Creative Studies at UC Santa Barbara. She is interested in human-computer interaction and new ways for computers to interface with the brain.\nIn her free time, she enjoys reading science fiction and fantasy novels and making art.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"fabfd5792b657e19c558420ac2ff4ce5","people":["schoinas_eirini"],"permalink":"https://bionicvisionlab.org/people/schoinas_eirini/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/schoinas_eirini/","section":"people","summary":"Eirini Schoinas is currently a first-year undergraduate student pursuing a Computing degree in the College of Creative Studies at UC Santa Barbara. She is interested in human-computer interaction and new ways for computers to interface with the brain.\nIn her free time, she enjoys reading science fiction and fantasy novels and making art.","title":"Eirini Schoinas","type":"people"},{"categories":null,"content":"Shivani Sista is currently a second-year undergraduate student pursuing a Computer Science degree at UC Santa Barbara, and a scholar in the Early Research Scholars Program (ERSP). She is interested in deep learning, computer vision, and computational neuroscience. In her free time, she enjoys playing the violin, drawing, and watching TV.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"81521c50bd2e2b502a681b810531ee5a","people":["sista_shivani"],"permalink":"https://bionicvisionlab.org/people/sista_shivani/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/sista_shivani/","section":"people","summary":"Shivani Sista is currently a second-year undergraduate student pursuing a Computer Science degree at UC Santa Barbara, and a scholar in the Early Research Scholars Program (ERSP). She is interested in deep learning, computer vision, and computational neuroscience. In her free time, she enjoys playing the violin, drawing, and watching TV.","title":"Shivani Sista","type":"people"},{"categories":null,"content":"Madori Spiker is a MS student in Computer Science at UC Santa Barbara.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"16a892356347222eb5ddec17b1eca141","people":["spiker_madori"],"permalink":"https://bionicvisionlab.org/people/spiker_madori/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/spiker_madori/","section":"people","summary":"Madori Spiker is a MS student in Computer Science at UC Santa Barbara.","title":"Madori Spiker","type":"people"},{"categories":null,"content":"Jiaxin Su is an undergraduate student pursuing degrees in Data Science and Statistics as well as in Mathematics at UC Santa Barbara.\nShe is interested in working at the intersection of biostatistics and psychology. In her free time, she enjoys running and playing frisbee.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2104459f97364834d46b2358ae484380","people":["su_jiaxin"],"permalink":"https://bionicvisionlab.org/people/su_jiaxin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/su_jiaxin/","section":"people","summary":"Jiaxin Su is an undergraduate student pursuing degrees in Data Science and Statistics as well as in Mathematics at UC Santa Barbara.\nShe is interested in working at the intersection of biostatistics and psychology. In her free time, she enjoys running and playing frisbee.","title":"Jiaxin Su","type":"people"},{"categories":null,"content":"Eyob is currently a third-year undergraduate student pursuing a Computer Science degree at UC Santa Barbara. He is a Student Engagement and Enrichment in Data Science (SEEDS) Undergraduate Research Fellow, and is interested in Artificial Intelligence, Virtual Reality, and Computer Vision.\nWhen he is not in class or studying in the library, he enjoys working out, hanging out with friends, and playing soccer.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"c0df3d356bd8facfcee0b6383efe5e95","people":["teshome_eyob"],"permalink":"https://bionicvisionlab.org/people/teshome_eyob/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/teshome_eyob/","section":"people","summary":"Eyob is currently a third-year undergraduate student pursuing a Computer Science degree at UC Santa Barbara. He is a Student Engagement and Enrichment in Data Science (SEEDS) Undergraduate Research Fellow, and is interested in Artificial Intelligence, Virtual Reality, and Computer Vision.\nWhen he is not in class or studying in the library, he enjoys working out, hanging out with friends, and playing soccer.","title":"Eyob Teshome","type":"people"},{"categories":null,"content":"Sukhi Toor is currently a fourth-year student pursuing a Biopsychology degree at UC Santa Barbara. She is interested in psychopharmacology and visual neuroscience.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"b2bee57df896a2422ecda4cd0587329e","people":["toor_sukhi"],"permalink":"https://bionicvisionlab.org/people/toor_sukhi/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/toor_sukhi/","section":"people","summary":"Sukhi Toor is currently a fourth-year student pursuing a Biopsychology degree at UC Santa Barbara. She is interested in psychopharmacology and visual neuroscience.","title":"Sukhi Toor","type":"people"},{"categories":null,"content":"Lily Turkstra is a PhD student in the Bionic Vision Lab at UC Santa Barbara.\nShe has extensive research experience with human psychophysics, has worked with clinical populations, and is well versed in statistical software analysis and programming.\nBefore joining the PBS department as a graduate student, Lily served as lab manager from Fall \u0026lsquo;22 to Summer \u0026lsquo;23. Before that, she was a Behavioral Health and Performance Intern at NASA and a Software Quality Assurance specialist at Tapestry Solutions. She also worked as a member of the Multisensory Perception Lab at Cal Poly and as a children’s behavioral therapist with California PsychCare.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"7c45c0abd1782c170bfc40cc395e222e","people":["turkstra_lily"],"permalink":"https://bionicvisionlab.org/people/turkstra_lily/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/turkstra_lily/","section":"people","summary":"Lily Turkstra is a PhD student in the Bionic Vision Lab at UC Santa Barbara.\nShe has extensive research experience with human psychophysics, has worked with clinical populations, and is well versed in statistical software analysis and programming.\nBefore joining the PBS department as a graduate student, Lily served as lab manager from Fall \u0026lsquo;22 to Summer \u0026lsquo;23. Before that, she was a Behavioral Health and Performance Intern at NASA and a Software Quality Assurance specialist at Tapestry Solutions.","title":"Lily M. Turkstra","type":"people"},{"categories":null,"content":"Apurv Varshney is currently a first-year PhD student pursuing a PhD in Computer Science at UC Santa Barbara. He is interested in improving Bionic Vision using Computer vision and human computer interaction (HCI) techniques.\nIn his free time he enjoys hiking and playing tennis.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"283fe3910514662d9abab07376970c6f","people":["varshney_apurv"],"permalink":"https://bionicvisionlab.org/people/varshney_apurv/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/varshney_apurv/","section":"people","summary":"Apurv Varshney is currently a first-year PhD student pursuing a PhD in Computer Science at UC Santa Barbara. He is interested in improving Bionic Vision using Computer vision and human computer interaction (HCI) techniques.\nIn his free time he enjoys hiking and playing tennis.","title":"Apurv Varshney","type":"people"},{"categories":null,"content":"Alvin Wang is a second year undergraduate student pursuing a Computer Science degree at UC Santa Barbara. He is especially interested in the fields of machine learning, computer vision, and artificial intelligence regulation.\nIn his free time, he enjoys cooking and playing basketball as well as hiking the numerous breathtaking trails Santa Barbara has to offer.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"f0732b46f88e8ceefeecaaa7f5b6c460","people":["wang_alvin"],"permalink":"https://bionicvisionlab.org/people/wang_alvin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/wang_alvin/","section":"people","summary":"Alvin Wang is a second year undergraduate student pursuing a Computer Science degree at UC Santa Barbara. He is especially interested in the fields of machine learning, computer vision, and artificial intelligence regulation.\nIn his free time, he enjoys cooking and playing basketball as well as hiking the numerous breathtaking trails Santa Barbara has to offer.","title":"Alvin Wang","type":"people"},{"categories":null,"content":"Aiwen Xu is a PhD student in Computer Science. Prior to UC Santa Barbara, she received a BS in Computer Science and a BS in Mathematics from New York University Shanghai. She hopes to utilize mathematical modeling and machine learning techniques to improve bionic vision.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"8f8cb324f0e2fc7e16448789c3667a8d","people":["xu_aiwen"],"permalink":"https://bionicvisionlab.org/people/xu_aiwen/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/xu_aiwen/","section":"people","summary":"Aiwen Xu is a PhD student in Computer Science. Prior to UC Santa Barbara, she received a BS in Computer Science and a BS in Mathematics from New York University Shanghai. She hopes to utilize mathematical modeling and machine learning techniques to improve bionic vision.","title":"Aiwen Xu","type":"people"},{"categories":null,"content":"Daisy Zhong is a second-year undergraduate studying Computer Science at UC Santa Barbara. She is interested in human-computer interaction, software, and psychology.\nIn her free time, Daisy enjoys hiking, baking, and hanging out with friends.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"32c4ca4b01b72b190daaf033e19d173c","people":["zhong_wanqian"],"permalink":"https://bionicvisionlab.org/people/zhong_wanqian/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/zhong_wanqian/","section":"people","summary":"Daisy Zhong is a second-year undergraduate studying Computer Science at UC Santa Barbara. She is interested in human-computer interaction, software, and psychology.\nIn her free time, Daisy enjoys hiking, baking, and hanging out with friends.","title":"Wanqian (Daisy) Zhong","type":"people"},{"categories":null,"content":"Jennifer Zhu is an undergraduate student pursuing a Computer Science degree at UC Santa Barbara.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"0cb9ab29e854acdf9fa0d2b1ef6a4ea1","people":["zhu_jennifer"],"permalink":"https://bionicvisionlab.org/people/zhu_jennifer/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/zhu_jennifer/","section":"people","summary":"Jennifer Zhu is an undergraduate student pursuing a Computer Science degree at UC Santa Barbara.","title":"Jennifer Zhu","type":"people"},{"categories":null,"content":"PSY-221F is the new course number for PSY-265 formerly taught by Greg Ashby\nCourse Description This is a lecture course that surveys computational neuroscience, which is a branch of neuroscience that employs mathematical models, theoretical analysis, and abstractions of the brain to understand the principles that govern development, structure, physiology, and cognitive abilities of the nervous system. We will cover both classical (e.g., GLM, LIF, Hodgkin-Huxley model) and state-of-the-art methods (i.e., deep learning).\nBy the end of this course, you should be able to:\n describe how the brain \u0026ldquo;computes\u0026rdquo;, describe different methods that computational neuroscientists use to model neural coding, computationally model the biophysics of single neurons and the dynamics of neural networks, fit a computational model to experimental data.  You will gain experience both conceptually and practically, by homework assignments that involve solving problems and implementing computational models. However, this is not primarily a programming course - that is, the main goal is to learn the concepts, not to learn a programming language or particular programming techniques. Nevertheless, coding examples of the concepts is the best way to demonstrate (and facilitate) your knowledge of them. Lab sections will feature Python \u0026amp; math tutorials, hands-on examples, and guided programming sessions.\nPrerequisites The formal prerequisite is PSY-221B, but the only part of that course that is necessary is the introduction to matrix algebra.\nThe actual necessary background includes:\n calculus, some prior exposure to matrix algebra, some prior exposure to Python.  Desirable, but not strictly necessary:\n prior exposure to differential equations, basic knowledge of neuroscience.  More information coming soon.\n","date":1709251200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1709251200,"objectID":"18493551895cd1c8b557952374f639d8","people":null,"permalink":"https://bionicvisionlab.org/teaching/2024-spring-psy221f/","publishdate":"2024-03-01T00:00:00Z","relpermalink":"/teaching/2024-spring-psy221f/","section":"teaching","summary":"A lecture course that surveys computational neuroscience, which is a branch of neuroscience that employs mathematical models, theoretical analysis, and abstractions of the brain to understand the principles that govern development, structure, physiology, and cognitive abilities of the nervous system. We will cover both classical (e.g., GLM, LIF, Hodgkin-Huxley model) and state-of-the-art methods (i.e., deep learning).","title":"PSY-221F: Computational Neuroscience","type":"teaching"},{"categories":null,"content":"Prerequisite: CS-130A\nArtificial Intelligence is about building and understanding intelligent systems. AI means different things to different people. People have approached the study of AI from various perspectives: philosophy, neurophysiology, mathematics, linguistics, psychology, control systems, and computer science, to name a few. Part of what makes it so interesting is the range of activities, from trying to understand minds in the abstract, to building creatures that run around and do things. AI has made steady progress and contributed to much of what is now standard computer science and cognitive science. It has spawned several sub-areas (e.g., natural language processing, speech recognition, computer vision, robotics, expert systems, and machine learning).\nThis is an introductory course in artificial intelligence offered as part of a computer science curriculum, so we are not primarily concerned with the approaches of philosophy, cognitive science, etc., although we will come back to them from time to time. We will cover the following technical topics:\n Problem solving and intelligent agents Introduction to machine learning (classification) Probabilistic modeling and inference (Bayesian networks) Problem solving and search (blind, informed, adversarial) Introduction to reinforcement learning (Bandits, MDPs and Reinforcement Learning) Knowledge Representation and Reasoning (logic) Responsible AI (fairness, privacy, AI for social good)  Differences from CS165B: Note that CS165B is about machine learning (ML). In CS165A, we take a broader view of AI and cover a complementary set of topics (each one of them may have a learning component). There isn’t a right order in taking these two courses. You can go either way. You will have more ideas on applications of ML for decision making if you have completed CS165A when taking CS165B; meanwhile you will gain deeper understanding in CS165A topics if you have taken CS165B.\n","date":1704067200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1704067200,"objectID":"b7cdc7057cc439a2fb66846d1ce4e0dd","people":null,"permalink":"https://bionicvisionlab.org/teaching/2024-winter-cs165a/","publishdate":"2024-01-01T00:00:00Z","relpermalink":"/teaching/2024-winter-cs165a/","section":"teaching","summary":"Introduction to the field of artificial intelligence, which seeks to understand and build intelligent computational systems. Topics include intelligent agents, problem solving and heuristic search, knowledge representation and reasoning, uncertainty and probabilistic reasoning, machine learning, reinforcement learning, and responsible AI.","title":"CS-165A: Introduction to Artificial Intelligence","type":"teaching"},{"categories":null,"content":"","date":1702237680,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1702237680,"objectID":"e268b30ccd6e03c94d0b77a006d9e4be","people":["Galen Pogoncheff","Jacob Granley","Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2023-12-v1-monkey-neuroai/","publishdate":"2023-12-10T19:48:00Z","relpermalink":"/publications/2023-12-v1-monkey-neuroai/","section":"publications","summary":"We systematically incorporated neuroscience-derived architectural components into CNNs to identify a set of mechanisms and architectures that comprehensively explain neural activity in V1.","title":"Explaining V1 properties with a biologically constrained deep learning architecture","type":"publications"},{"categories":null,"content":"","date":1702234140,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1702234140,"objectID":"22ed88e37d64c0539737a121b619b730","people":["Jacob Granley","Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2023-12-hilo-stimulus-encoding/","publishdate":"2023-12-10T18:49:00Z","relpermalink":"/publications/2023-12-hilo-stimulus-encoding/","section":"publications","summary":"We propose a personalized stimulus encoding strategy that combines state-of-the-art deep stimulus encoding with preferential Bayesian optimization.","title":"Human-in-the-loop optimization for deep stimulus encoding in visual prostheses","type":"publications"},{"categories":null,"content":"","date":1702231200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1702231200,"objectID":"7b806ede64638425f8f76f5776ff8b40","people":["Aiwen Xu","Yuchen Hou","Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2023-12-v1-mouse/","publishdate":"2023-12-10T18:00:00Z","relpermalink":"/publications/2023-12-v1-mouse/","section":"publications","summary":"We introduce a multimodal recurrent neural network that integrates gaze-contingent visual input with behavioral and temporal dynamics to explain V1 activity in freely moving mice.","title":"Multimodal deep learning model unveils behavioral dynamics of V1 activity in freely moving mice","type":"publications"},{"categories":[],"content":"The lab had 3 papers accepted at NeurIPS \u0026lsquo;23:\n  PhD students Aiwen Xu and Yuchen Hou developed a multimodal recurrent neural net that well describes V1 activity in freely moving mice, revealing how some neurons lack pronounced visual RFs and that most neurons exhibit mixed selectivity:\nA Xu, Y Hou, CM Niell, M Beyeler (2023). Multimodal deep learning model unveils behavioral dynamics of V1 activity in freely moving mice. 37th Conference on Neural Information Processing Systems (NeurIPS) \u0026lsquo;23\n  The latest work by PhD students Galen Pogoncheff and Jacob Granley enriches ResNet50 (the previously best V1-aligned deep net) with layers that simulate the processing hallmarks of the early visual system and assesses how they affect model-brain alignment:\nG Pogoncheff, J Granley, M Beyeler (2023). Explaining V1 properties with a biologically constrained deep learning architecture. 37th Conference on Neural Information Processing Systems (NeurIPS) \u0026lsquo;23\n  And last but not least, Jacob Granley (in collab w/ Tristan Fauvel \u0026amp; Matthew Chalk from Sorbonne University) combined deep stimulus encoding with preferential Bayesian optimization to develop personalized stimulation strategies for neural prostheses:\nJ Granley, T Fauvel, M Chalk, M Beyeler (2023). Human-in-the-loop optimization for deep stimulus encoding in visual prostheses. 37th Conference on Neural Information Processing Systems (NeurIPS) \u0026lsquo;23\n  ","date":1695315540,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1695315540,"objectID":"e5c65e8e59dae10e21bf064026c1f195","people":["Michael Beyeler"],"permalink":"https://bionicvisionlab.org/news/2023-09-neurips/","publishdate":"2023-09-21T09:59:00-07:00","relpermalink":"/news/2023-09-neurips/","section":"news","summary":"Our latest work yields state-of-the-art predictions of primary visual cortex (V1) activity in mouse and monkey, plus a new way to optimize stimulation protocols for visual prostheses.","title":"3 papers accepted at NeurIPS '23","type":"news"},{"categories":null,"content":"","date":1692953340,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1692953340,"objectID":"ccb535fc7cefa9331b5907f6f0f4483b","people":["Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2023-08-eye-tracking-suite/","publishdate":"2023-08-25T08:49:00Z","relpermalink":"/publications/2023-08-eye-tracking-suite/","section":"publications","summary":"We developed EyeTTS, an eye tracking test suite to evaluate and compare different eye tracking devices on various augmented reality tasks and metrics, specifically for scenarios involving head movement and locomotion.","title":"EyeTTS: Evaluating and Calibrating Eye Tracking for Mixed-Reality Locomotion","type":"publications"},{"categories":null,"content":"","date":1690361340,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1690361340,"objectID":"0f796a8e0b0bb89539f032651fe46b3d","people":["Yuchen Hou","Jacob Granley","Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2023-07-argus-pairs/","publishdate":"2023-07-26T08:49:00Z","relpermalink":"/publications/2023-07-argus-pairs/","section":"publications","summary":"We retrospectively analyzed phosphene shape data collected form three Argus II patients to investigate which neuroanatomical and stimulus parameters predict paired-phosphene appearance and whether phospehenes add up linearly.","title":"Axonal stimulation affects the linear summation of single-point perception in three Argus II users","type":"publications"},{"categories":null,"content":"","date":1684368000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1684368000,"objectID":"337ae34472877e25b0b1837b8fae1de0","people":["Aiwen Xu","Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2023-05-retinal-degeneration/","publishdate":"2023-05-18T00:00:00Z","relpermalink":"/publications/2023-05-retinal-degeneration/","section":"publications","summary":"We present a biophysically detailed *in silico* model of retinal degeneration that simulates the network-level response to both light and electrical stimulation as a function of disease progression.","title":"Retinal ganglion cells undergo cell type--specific functional changes in a computational model of cone-mediated retinal degeneration","type":"publications"},{"categories":null,"content":"","date":1683223200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1683223200,"objectID":"a316ee61f21a99e784d263cd258f59f8","people":["Lily M. Turkstra","Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2023-05-information-needs-blind/","publishdate":"2023-05-04T18:00:00Z","relpermalink":"/publications/2023-05-information-needs-blind/","section":"publications","summary":"We present a mixed-methods approach that combines semi-structured interviews with a follow-up behavioral study to understand current and potential future use of technologies for daily activities around the home, especially for cooking.","title":"Information needs and technology use for daily living activities at home by people who are blind","type":"publications"},{"categories":null,"content":"","date":1683158400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1683158400,"objectID":"1fb89e3d563faf51751733186a868f20","people":["Justin Kasowski","Byron A. Johnson","Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2023-05-xr-systematic-review/","publishdate":"2023-05-04T00:00:00Z","relpermalink":"/publications/2023-05-xr-systematic-review/","section":"publications","summary":"We present a systematic literature review of 227 publications from 106 different venues assessing the potential of XR technology to further visual accessibility.","title":"A systematic review of extended reality (XR) for understanding and augmenting vision loss","type":"publications"},{"categories":null,"content":"","date":1682380800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1682380800,"objectID":"1d10c9afb2961d48e669e73445e22101","people":["Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2023-04-neuromorphic-lstm/","publishdate":"2023-04-25T00:00:00Z","relpermalink":"/publications/2023-04-neuromorphic-lstm/","section":"publications","summary":"We present a way to implement long short-term memory (LSTM) cells on spiking neuromorphic hardware.","title":"Long-short term memory (LSTM) cells on spiking neuromorphic hardware","type":"publications"},{"categories":null,"content":"","date":1680307200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1680307200,"objectID":"4efa58ff71127cb2aa61636362a9a035","people":["Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2023-04-snn-stdp-wta/","publishdate":"2023-04-01T00:00:00Z","relpermalink":"/publications/2023-04-snn-stdp-wta/","section":"publications","summary":"We present a SNN model that uses spike-latency coding and winner-take-all inhibition to efficiently represent visual objects with as little as 15 spikes per neuron.","title":"Efficient multi-scale representation of visual objects using a biologically plausible spike-latency code and winner-take-all inhibition","type":"publications"},{"categories":null,"content":"Prerequisites: PSY 111; open to Psychological \u0026amp; Brain Sciences, Biopsychology, and Interdisciplinary Studies majors only.\nThis course will focus on the biological basis of vision, including both the theory and recent research in visual neuroscience, with a focus on the retina and the early visual cortex. In specific, we will cover how the retinal image is represented by the neural response within the visual pathways, considering evidence from behavioral and biological approaches.\nUnderstanding how the visual system encodes light has implications for everything else the visual pathways do. Our understanding of the neural representation is based on work in several different disciplines. Throughout this course we will see that:\n there are many anatomically distinct types of neurons with various distinct functions, the different anatomical types of neurons respond to light stimulation in different ways and their signals are communicated to different destinations, the microcircuitry of the local neural connections is very precise, and not at all random.  All course materials can be found on GauchoSpace.\n","date":1677628800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1677628800,"objectID":"013accb3ec28b26abbfa1224eab5bebb","people":null,"permalink":"https://bionicvisionlab.org/teaching/2023-spring-psych132/","publishdate":"2023-03-01T00:00:00Z","relpermalink":"/teaching/2023-spring-psych132/","section":"teaching","summary":"An overview of theory and research in visual neuroscience. Topics may include: a focus on mammalian vision considering evidence from behavioral and biological approaches.","title":"PSY-132: Visual Neuroscience","type":"teaching"},{"categories":null,"content":"","date":1676023200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1676023200,"objectID":"fa1c01f2e29c5a2c3042eac3a0c7db22","people":["Galen Pogoncheff","Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2023-02-explainable-thresholds/","publishdate":"2023-02-10T10:00:00Z","relpermalink":"/publications/2023-02-explainable-thresholds/","section":"publications","summary":"We present explainable artificial intelligence (XAI) models fit on a large longitudinal dataset that can predict perceptual thresholds on individual Argus II electrodes over time.","title":"Explainable machine learning predictions of perceptual sensitivity for retinal prostheses","type":"publications"},{"categories":null,"content":"Overview of computer vision problems and techniques for analyzing the content of images and video. Topics include image formation, edge detection, image segmentation, pattern recognition, texture analysis, optical flow, stereo vision, shape representation and recovery techniques, issues in object recognition, and case studies of practical vision systems.\nMore info coming soon.\n","date":1672531200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672531200,"objectID":"a3783704b1256bf2f3b35b18c927cff4","people":null,"permalink":"https://bionicvisionlab.org/teaching/2023-winter-cs281b/","publishdate":"2023-01-01T00:00:00Z","relpermalink":"/teaching/2023-winter-cs281b/","section":"teaching","summary":"Overview of computer vision problems and techniques for analyzing the content of images and video. Topics include image formation, edge detection, image segmentation, pattern recognition, texture analysis, optical flow, stereo vision, shape representation and recovery techniques, issues in object recognition, and case studies of practical vision systems.","title":"CS/ECE-281B: Advanced Topics in Computer Vision","type":"teaching"},{"categories":null,"content":"","date":1669939200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1669939200,"objectID":"2ee90801938f9e1297598ca453d525a7","people":["Jacob Granley","Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2022-12-brain-like-phosphene-model/","publishdate":"2022-12-02T00:00:00Z","relpermalink":"/publications/2022-12-brain-like-phosphene-model/","section":"publications","summary":"We show that a neurologically-inspired decoding of CNN activations produces qualitatively accurate phosphenes, comparable to phosphenes reported by real patients.","title":"Adapting brain-like neural networks for modeling cortical visual prostheses","type":"publications"},{"categories":null,"content":"","date":1669680000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1669680000,"objectID":"2b89d352e0fc3f5e4b7701f2b59fbbc8","people":["Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2022-11-indoor-mobility/","publishdate":"2022-11-29T00:00:00Z","relpermalink":"/publications/2022-11-indoor-mobility/","section":"publications","summary":"We used a neurobiologically inspired model of simulated prosthetic vision in an immersive virtual reality environment to test the relative importance of semantic edges and relative depth cues to support the ability to avoid obstacles and identify objects.","title":"The relative importance of depth cues and semantic edges for indoor mobility using simulated prosthetic vision in immersive virtual reality","type":"publications"},{"categories":null,"content":"","date":1669593600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1669593600,"objectID":"ef4d91b2b9249770aa00fdf35cfad0ce","people":["Jacob Granley","Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2022-11-hybrid-neural-autoencoder/","publishdate":"2022-11-28T00:00:00Z","relpermalink":"/publications/2022-11-hybrid-neural-autoencoder/","section":"publications","summary":"What is the required stimulus to produce a desired percept? Here we frame this as an end-to-end optimization problem, where a deep neural network encoder is trained to invert a known, fixed forward model that approximates the underlying biological system.","title":"Hybrid neural autoencoders for stimulus encoding in visual and other sensory neuroprostheses","type":"publications"},{"categories":null,"content":"","date":1669593600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1669593600,"objectID":"fba714fa570547587274baef42438a77","people":["Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2022-11-smart-bionic-eye/","publishdate":"2022-11-28T00:00:00Z","relpermalink":"/publications/2022-11-smart-bionic-eye/","section":"publications","summary":"Rather than aiming to represent the visual scene as naturally as possible, a *Smart Bionic Eye* could provide visual augmentations through the means of artificial intelligence–based scene understanding, tailored to specific real-world tasks that are known to affect the quality of life of people who are blind.","title":"Towards a *Smart Bionic Eye*: AI-powered artificial vision for the treatment of incurable blindness","type":"publications"},{"categories":[],"content":"Prof. Beyeler aims to bring to the mainstream an artificial intelligence (AI)-powered bionic eye that can generate artificial vision, in an effort to increase the quality of life for patients who are blind or visually impaired.\n“I envision a smart bionic eye that could find misplaced keys on a counter, read out medication labels, inform a user about people’s gestures and facial expressions during social interactions, and warn a user of nearby obstacles and outline safe paths,” he said.\nFor his project, “Towards a Smart Bionic Eye: AI-Powered Artificial Vision for the Treatment of Incurable Blindness,” Beyeler has been selected for a National Institutes of Health (NIH) Director’s New Innovator Award. The five-year, $1.5 million grant was one of 72 awarded this week by the NIH to enable exceptionally creative early-career scientists to push the boundaries of biomedical science and pursue high-impact projects that aim to advance knowledge and enhance health.\n“I offer my sincerest congratulations to Professor Beyeler for having his innovative research recognized with the prestigious NIH Director\u0026rsquo;s New Innovator Award,” said Tresa Pollock, the interim dean of the College of Engineering and Alcoa Distinguished Professor of Materials. “His novel approach of using recent advances in computer vision, AI and neuroscience has tremendous potential to uncover new knowledge and provide millions of people with useful vision through a smart bionic eye.”\nRead the full article here.\n","date":1664902740,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1664902740,"objectID":"bfaa490bae8c16679721d3964316f122","people":["Michael Beyeler"],"permalink":"https://bionicvisionlab.org/news/2022-10-new-innovator/","publishdate":"2022-10-04T09:59:00-07:00","relpermalink":"/news/2022-10-new-innovator/","section":"news","summary":"Prof. Beyeler receives $1.5 million NIH Director's New Innovator award to enable a Smart Bionic Eye","title":"Towards a \u003ci\u003eSmart Bionic Eye\u003c/i\u003e","type":"news"},{"categories":[],"content":"Current epiretinal implants arrange their electrodes on a rectangular grid. \u0026ldquo;Some people have looked at where to place the whole implant on the retina\u0026rdquo;, says Prof. Beyeler. \u0026ldquo;Ashley was the first to ask, what if we moved every individual electrode around based on what we know about how these electrodes produce artificial vision?\u0026quot;\nHowever, moving every electrode presents the problem of combinatorial explosion. Even in current devices with only 60 electrodes, there are many possibilities for arranging them. It is not usually technically feasible to find a solution.\n\u0026ldquo;Ashley approached this as a greedy optimization problem, where one electrode is placed after another\u0026rdquo;, explains Prof. Beyeler. \u0026ldquo;We used a computational model of bionic vision to help predict what the vision would look like for a given electrode placement. By iterating over that, Ashley found a mathematically proven optimal solution.\u0026quot;\nRead the full article at rsipvision.com.\nThe paper has been accepted at MICCAI \u0026lsquo;22.\n","date":1663576140,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1663576140,"objectID":"f081acf70642846dae6eda5f84056cf0","people":["Michael Beyeler"],"permalink":"https://bionicvisionlab.org/news/2022-09-miccai-daily/","publishdate":"2022-09-19T01:29:00-07:00","relpermalink":"/news/2022-09-miccai-daily/","section":"news","summary":"The work of Ashley Bruce, CS's Outstanding MS Student of the Year awardee, was highlighted in MICCAI Daily magazine.","title":"Greedy optimization of electrode arrangement for epiretinal prostheses","type":"news"},{"categories":null,"content":"","date":1663545600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1663545600,"objectID":"943d856a76877a1c1a66dc87c930a112","people":["Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2022-09-epiretinal-design/","publishdate":"2022-06-03T00:00:00Z","relpermalink":"/publications/2022-09-epiretinal-design/","section":"publications","summary":"We optimize electrode arrangement of epiretinal implants to maximize visual subfield coverage.","title":"Greedy optimization of electrode arrangement for epiretinal prostheses","type":"publications"},{"categories":null,"content":"Same course as ECE 181. This year, CS/ECE 181 will be offered twice: in Fall 2022 and Winter 2023.\nPrerequisites: Upper-division standing in Electrical Engineering, Computer Engineering, Computer Science, Chemical Engineering or Mechanical Engineering.\nOverview of computer vision problems and techniques for analyzing the content of images and video. Topics include image formation, alignment and warping; stereo vision; feature extraction, matching, and tracking; deep learning-based object detection, recognition, and segmentation; and case studies of practical vision systems.\nAfter taking CS 181, students should be able to:\n explain \u0026amp; apply the fundamentals of image formation, alignment, and warping explain \u0026amp; apply the fundamentals of projective and epipolar geometry process image features using traditional \u0026amp; modern approaches summarize current approaches to object recognition, detection, and segmentation demonstrate expertise towards the implementation and programming practices of effective computer vision applications  ","date":1661990400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1661990400,"objectID":"7981ea9f46ce9dd391990a2500d6bc97","people":null,"permalink":"https://bionicvisionlab.org/teaching/2022-fall-cs181/","publishdate":"2022-09-01T00:00:00Z","relpermalink":"/teaching/2022-fall-cs181/","section":"teaching","summary":"Overview of computer vision problems and techniques for analyzing the content of images and video. Topics include image formation, alignment and warping; stereo vision; feature extraction, matching, and tracking; deep learning-based object detection, recognition, and segmentation; and case studies of practical vision systems.","title":"CS/ECE-181: Introduction to Computer Vision","type":"teaching"},{"categories":null,"content":"","date":1661299200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1661299200,"objectID":"05694a8455cf62a720fad6af5db9d731","people":["Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2022-08-factors-two-point-argus/","publishdate":"2022-08-24T00:00:00Z","relpermalink":"/publications/2022-08-factors-two-point-argus/","section":"publications","summary":"We explored the causes of high thresholds and poor spatial resolution within the Argus II epiretinal implant.","title":"Factors affecting two-point discrimination in Argus II patients","type":"publications"},{"categories":[],"content":"Ph.D. student Byron Johnson won not just one, but three travel awards for his exciting work using eye tracking to simulate artificial scotomas (damaged regions of the visual field) and their effects on visual processing and eye movements.\rIn late May, Byron's poster \"The Effect of a Simulated Scotoma on Rapid Scene Understanding\" was selected for a travel fellowship to present at the Center for Visual Science's 32nd Symposium on Active Vision, hosted at the University of Rochester/Memorial Art Gallery (see photo).\rIn July, Byron received a travel award from the Helmsley Charitable Trust to attend the prestigious three-week course for Computational Neuroscience: Vision at the Cold Spring Harbor Laboratory.\rAnd in August, Byron received a travel award to attend and give a talk about his research at the 2022 Biennial Perceptual Learning Workshop, held in Alyeska, Alaska. Congratulations, Byron!\nOver in Computer Science, M.S. student Ashley Bruce was recognized with the MS Student of the Year award, presented annually in recognition of a student who has excelled in both research and either department service or teaching.\rAshley's research involved the optimization of epiretinal implant designs, which was accepted to the main track at MICCAI '22.\rFrom faculty: “Looking at her success and productivity, it is sometimes easy to forget that Ashley did not come from a traditional CS background. This means that a lot of the computing skills at which she now excels were self-taught. Not only did she make it into our prestigious Masters program, but she has thrived in it.”\nMeanwhile Yuchen Hou earned one of the most prestigious awards of the Psychological \u0026 Brain Sciences (PBS) department: the Abdullah \u0026 Marjorie R. Nasser Memorial Scholarship Fund Award.\rThis award recognizes Yuchen's outstanding scholarship (she finished her BS with a 3.98 overall GPA) and dedication to research.\rWe are fortunate to have Yuchen continue as Ph.D. student in the lab.\nAnd the list goes on, with Tanya Bhatia winning the PBS Chairperson's Award - as well as the Exceptional Academic Performance Award alongside Yuchen Hou, Anvitha Akkaraju, and Ananth Mahes. In addition, Tanya and Anvitha completed innovative Honors Theses in the lab, which hopefully will see the light of the day as a peer-reviewed publication in the next couple of months.\nWhat a fantastic array of achievements. Congratulations everyone!\n","date":1659342540,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1659342540,"objectID":"21efcc51af401b482f6e5762695aa913","people":null,"permalink":"https://bionicvisionlab.org/news/2022-08-awards/","publishdate":"2022-08-01T01:29:00-07:00","relpermalink":"/news/2022-08-awards/","section":"news","summary":"With the academic year coming to a close, the work of multiple Bionic Vision Lab members was recognized by UCSB campus-wide as well as national awards.","title":"Bionic Vision Lab Member Awards 2022","type":"news"},{"categories":null,"content":"","date":1655856000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1655856000,"objectID":"1217f1e403d91b8b044fb7696f6e8ebf","people":["Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2022-06-motion-perception-stdp-h/","publishdate":"2022-06-22T00:00:00Z","relpermalink":"/publications/2022-06-motion-perception-stdp-h/","section":"publications","summary":"We developed a spiking neural network model that showed MSTd-like response properties can emerge from evolving spike-timing dependent plasticity with homeostatic synaptic scaling (STDP-H) parameters of the connections between area MT and MSTd.","title":"Cortical motion perception emerges from dimensionality reduction with evolved spike-timing dependent plasticity rules","type":"publications"},{"categories":[],"content":"\u0026ldquo;We started working on this project in an attempt to solve the long-standing problem of stimulus optimization in visual prostheses,\u0026rdquo; Jacob Granley, one of the researchers who carried out the study, told TechXplore. \u0026ldquo;One of the likely causes for the poor results achieved by visual prostheses is the naive stimulus encoding strategy that devices conventionally use. Previous works have suggested encoding strategies, but many are unrealistic, and none have given a general solution that could work across implants and patients.\u0026rdquo;\nRead the full article at techxplore.com.\nThe paper has been accepted at NeurIPS \u0026lsquo;22.\n","date":1655828940,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1655828940,"objectID":"6db51169b111943186ebe3b8b46fa953","people":["Jacob Granley","Michael Beyeler"],"permalink":"https://bionicvisionlab.org/news/2022-06-techxplore/","publishdate":"2022-06-21T09:29:00-07:00","relpermalink":"/news/2022-06-techxplore/","section":"news","summary":"What is the required stimulus to produce a desired percept? Our latest work on deep learning-based stimulus optimization was featured in a news article by TechXplore.","title":"A neural autoencoder to enhance sensory neuroprostheses","type":"news"},{"categories":null,"content":"","date":1655596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1655596800,"objectID":"faa9a03d09362bb4c8dd2abc464f6693","people":["Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2022-06-spike-latency-winner-take-all/","publishdate":"2022-05-23T00:00:00Z","relpermalink":"/publications/2022-06-spike-latency-winner-take-all/","section":"publications","summary":"We present a SNN model that uses spike-latency coding and winner-take-all inhibition to efficiently represent visual stimuli from the Fashion MNIST dataset.","title":"Efficient visual object representation using a biologically plausible spike-latency code and winner-take-all inhibition","type":"publications"},{"categories":null,"content":"Extended reality (XR) is a powerful tool for human behavioral research. The ability to create 3D visual scenes and measure responses to arbitrary visual stimuli enables the behavioral researcher to test hypotheses in a well-controlled environment. However, software packages such as SteamVR, OpenXR, and ARKit have been developed for game designers rather than behavioral researchers. While Unity is considered the most beginner-friendly platform, barriers still exist for inexperienced programmers. Toolboxes such as VREX and USE have focused on simplifying experimental design and remote data collection, but no tools currently exist to help with all aspects of an experiment.\nTo address this challenge, we have developed SimpleXR (sXR), an open-source Unity package that allows for creating complex experiments with relatively little code. The toolbox contains a plethora of tools that are particularly useful for the visual sciences, such as creating dynamic scenes, randomizing object locations, accessing eye-tracker data, and applying full-screen shader effects (e.g., blurring, gaze-contingent scotomas, edge detection) either in virtual reality (VR) or to the pass-through camera for augmented reality (AR) tasks. sXR also provides one-line commands for interacting with virtual objects, displaying stimuli and instructions, using timers, and much more. Additionally, it automatically switches between desktop and immersive VR modes. sXR creates separate user interfaces for the experimenter and participant, allowing the experimenter to track performance and monitor for anomalies. By using Unity’s Universal Rendering Pipeline, sXR allows researchers to develop across platforms, including VR headsets, AR glasses, and smartphones.\n","date":1653091200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1653091200,"objectID":"30a9394e245123ee7bfd3f0c8403a586","people":null,"permalink":"https://bionicvisionlab.org/code/simplexr/","publishdate":"2022-05-21T00:00:00Z","relpermalink":"/code/simplexr/","section":"code","summary":"SimpleXR is a Unity package designed to facilitate rapid development of visual and behavioral experiments using virtual and augmented reality.","title":"SimpleXR: An open-source Unity toolbox for simplified XR development","type":"code"},{"categories":null,"content":"\r\r","date":1646611200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1646611200,"objectID":"8efc4550929d5e5f7e0beac1472d6641","people":["Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2022-03-deep-stimulus-encoder/","publishdate":"2022-03-07T00:00:00Z","relpermalink":"/publications/2022-03-deep-stimulus-encoder/","section":"publications","summary":"We propose a perceptual stimulus encoder based on convolutional neural networks that is trained in an end-to-end fashion to predict the electrode activation patterns required to produce a desired visual percept. ","title":"Deep learning-based perceptual stimulus encoder for bionic vision","type":"publications"},{"categories":null,"content":"\r\r\r\r","date":1646611200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1646611200,"objectID":"b2024030dd8e104999ceff361e83f99e","people":["Justin Kasowski","Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2022-03-immersive-vr/","publishdate":"2022-03-07T00:00:00Z","relpermalink":"/publications/2022-03-immersive-vr/","section":"publications","summary":"We present VR-SPV, an open-source virtual reality toolbox for simulated prosthetic vision that uses a psychophysically validated computational model to allow sighted participants to 'see through the eyes' of a bionic eye user.","title":"Immersive virtual reality simulations of bionic vision","type":"publications"},{"categories":null,"content":"A major outstanding challenge in the field of bionic vision is predicting what people “see” when they use their devices. The limited field of view of current devices necessitates head movements to scan the scene, which is difficult to simulate on a computer screen. In addition, many computational models of bionic vision lack biological realism.\nTo address these challenges, we present BionicVisionXR, an open-source virtual reality toolbox for simulated prosthetic vision that uses a psychophysically validated computational model to allow sighted participants to “see through the eyes” of a bionic eye user.\n","date":1646092800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1646092800,"objectID":"aaac1b4b99b12c8538f8882d903955fc","people":null,"permalink":"https://bionicvisionlab.org/code/bionicvisionxr/","publishdate":"2022-03-01T00:00:00Z","relpermalink":"/code/bionicvisionxr/","section":"code","summary":"BionicVisionXR is an open-source virtual reality toolbox for simulated prosthetic vision that uses a psychophysically validated computational model to allow sighted participants to \"see through the eyes\" of a bionic eye recipient.","title":"BionicVisionXR: An Open-Source Virtual Reality Toolbox for Bionic Vision","type":"code"},{"categories":null,"content":"PSY-221F is the new course number for PSY-265 formerly taught by Greg Ashby\nCourse Description This is a lecture course that surveys computational neuroscience, which is a branch of neuroscience that employs mathematical models, theoretical analysis, and abstractions of the brain to understand the principles that govern development, structure, physiology, and cognitive abilities of the nervous system. We will cover both classical (e.g., GLM, LIF, Hodgkin-Huxley model) and state-of-the-art methods (i.e., deep learning).\nBy the end of this course, you should be able to:\n describe how the brain \u0026ldquo;computes\u0026rdquo;, describe different methods that computational neuroscientists use to model neural coding, computationally model the biophysics of single neurons and the dynamics of neural networks, fit a computational model to experimental data.  You will gain experience both conceptually and practically, by homework assignments that involve solving problems and implementing computational models. However, this is not primarily a programming course - that is, the main goal is to learn the concepts, not to learn a programming language or particular programming techniques. However, coding examples of the concepts is the best way to demonstrate (and facilitate) your knowledge of them. Lab sections will feature Python \u0026amp; math tutorials, hands-on examples, and guided programming sessions.\nPrerequisites The formal prerequisite is PSY-221B, but the only part of that course that is necessary is the introduction to matrix algebra.\nThe actual necessary background includes:\n calculus, some prior exposure to matrix algebra, some prior exposure to Python.  Desirable, but not strictly necessary:\n prior exposure to differential equations, basic knowledge of neuroscience.  Content Textbook: Dayan \u0026amp; Abbott (2001)\nTopics to be covered:\n Intro to CompNeuro: concepts, properties of neurons, cell types Neural encoding: spike trains and firing rates, early visual system Neuroelectronics: Electrical properties of neurons, Nernst equation Point neuron models: LIF, Izhikevich neurons, Hodgkin-Huxley neurons Morphological neuron models: synaptic conducances, cable equation, multi-compartment models Network models: firing rate models, feedforward/recurrent models, stochastic networks Plasticity \u0026amp; learning: short \u0026amp; long-term plasticity, reinforcement learning Machine and deep learning: model fitting, GLM, CNN, RNN Applications: sensory systems, language, decision-making, \u0026hellip;  Your grade will be determined by biweekly quizzes, homework assignments (drop the lowest) and a take-home final exam.\nMore information at: https://gauchospace.ucsb.edu/courses/course/view.php?id=10610.\n","date":1646092800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1646092800,"objectID":"690d235d8e7f4e8a8e3ea4e2083a195b","people":null,"permalink":"https://bionicvisionlab.org/teaching/2022-spring-psy221f/","publishdate":"2022-03-01T00:00:00Z","relpermalink":"/teaching/2022-spring-psy221f/","section":"teaching","summary":"A lecture course that surveys computational neuroscience, which is a branch of neuroscience that employs mathematical models, theoretical analysis, and abstractions of the brain to understand the principles that govern development, structure, physiology, and cognitive abilities of the nervous system. We will cover both classical (e.g., GLM, LIF, Hodgkin-Huxley model) and state-of-the-art methods (i.e., deep learning).","title":"PSY-221F: Computational Neuroscience","type":"teaching"},{"categories":[],"content":"Prof. Beyeler was mentioned in a recent article by The Guardian that discusses recent advances in machine learning and what data-driven discovery means for the classic methodology of hypothesizing, predicting, and testing.\n\rA tougher obstacle to the new science may be our human need to explain the world – to talk in terms of cause and effect. In 2019, neuroscientists Bingni Brunton and Michael Beyeler of the University of Washington, Seattle, wrote that this need for interpretability may have prevented scientists from making novel insights about the brain, of the kind that only emerges from large datasets. But they also sympathised. If those insights are to be translated into useful things such as drugs and devices, they wrote, “it is imperative that computational models yield insights that are explainable to, and trusted by, clinicians, end-users and industry”.\rLaura Spinny, The Guardian\r\rThe full article can be read here.\n","date":1641745740,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1641745740,"objectID":"c375d3cf9a926141c26a3665dcf1d2bd","people":["Michael Beyeler"],"permalink":"https://bionicvisionlab.org/news/2022-01-guardian/","publishdate":"2022-01-09T09:29:00-07:00","relpermalink":"/news/2022-01-guardian/","section":"news","summary":"Prof. Beyeler was mentioned in a recent article by The Guardian.","title":"Are we witnessing the dawn of post-theory science?","type":"news"},{"categories":null,"content":"","date":1640131200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640131200,"objectID":"10e800338dcbf02f3fd25a256ed0cc7d","people":["Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2021-learning-to-see-again/","publishdate":"2021-12-22T00:00:00Z","relpermalink":"/publications/2021-learning-to-see-again/","section":"publications","summary":"We show that sighted individuals can learn to adapt to the unnatural on- and off-cell population responses produced by electronic and optogenetic sight recovery technologies.","title":"Learning to see again: Perceptual learning of simulated abnormal on- off-cell population responses in sighted individuals","type":"publications"},{"categories":null,"content":"Rather than aiming to one day restore natural vision (which may remain elusive until we fully understand the neural code of vision), we might be better off thinking about how to create practical and useful artificial vision now. Specifically, a visual prosthesis has the potential to provide visual augmentations through the means of artificial intelligence (AI) based scene understanding (e.g., by highlighting important objects), tailored to specific real-world tasks that are known to affect the quality of life of people who are blind (e.g., face recognition, outdoor navigation, self-care).\nIn the future, these visual augmentations could be combined with GPS to give directions, warn users of impending dangers in their immediate surroundings, or even extend the range of visible light with the use of an infrared sensor (think bionic night-time vision). Once the quality of the generated artificial vision reaches a certain threshold, there are a lot of exciting avenues to pursue.\n","date":1639267200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1639267200,"objectID":"483f7439d7ffd8ed32df84fef3409470","people":null,"permalink":"https://bionicvisionlab.org/research/smart-bionic-eye/","publishdate":"2021-12-12T00:00:00Z","relpermalink":"/research/smart-bionic-eye/","section":"research","summary":"Rather than aiming to one day restore *natural* vision, we might be better off thinking about how to create practical and useful *artificial* vision now.","title":"Towards a Smart Bionic Eye","type":"research"},{"categories":null,"content":"The goal of this project is to obtain a nuanced understanding of the strategies that people who are blind or visually impaired (BVI) employ to perform different instrumental activities of daily living (iADLs).\nIdentifying useful and relevant visual cues that could support these iADLs, especially when the task involves some level of scene understanding, orientation, and mobility, will be essential to the success of near-future visual accessibility aids.\n","date":1638316800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1638316800,"objectID":"0436c06999d02c1a39549c55f7aa4543","people":null,"permalink":"https://bionicvisionlab.org/research/information-needs-blind-low-vision/","publishdate":"2021-12-01T00:00:00Z","relpermalink":"/research/information-needs-blind-low-vision/","section":"research","summary":"A nuanced understanding of the strategies that people who are blind or visually impaired employ to perform different instrumental activities of daily living (iADLs) is essential to the success of future visual accessibility aids.","title":"Understanding the Information Needs of People Who Are Blind or Visually Impaired","type":"research"},{"categories":null,"content":"","date":1635724800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1635724800,"objectID":"9a060bf8d239d3032bdf3b9c520fe632","people":["Jacob Granley","Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2021-biphasic-axon-map/","publishdate":"2021-11-01T00:00:00Z","relpermalink":"/publications/2021-biphasic-axon-map/","section":"publications","summary":"We present a phenomenological model that predicts phosphene appearance as a function of stimulus amplitude, frequency, and pulse duration.","title":"A computational model of phosphene appearance for epiretinal prostheses","type":"publications"},{"categories":null,"content":"A major outstanding challenge is predicting what people \u0026ldquo;see\u0026rdquo; when they use their devices.\nInstead of seeing focal spots of light, current visual implant users perceive highly distorted percepts, which vary in shape not just across subjects but also across electrodes and often fail to assemble into more complex percepts. Furthermore, phosphenes appear fundamentally different depending on whether they are generated with retinal or cortical implants.\nThe goal of this project is thus to combine psychophysical and neuroanatomical data that can inform phosphene models capable of linking electrical stimulation directly to perception.\n","date":1633132800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1633132800,"objectID":"b4577bf7255e69c478cf022f745b64e1","people":null,"permalink":"https://bionicvisionlab.org/research/predicting-visual-outcomes-visual-prostheses/","publishdate":"2021-10-02T00:00:00Z","relpermalink":"/research/predicting-visual-outcomes-visual-prostheses/","section":"research","summary":"What do visual prosthesis users see, and why? Clinical studies have shown that the vision provided by current devices differs substantially from normal sight.","title":"Predicting Visual Outcomes for Visual Prostheses","type":"research"},{"categories":null,"content":"Our lack of understanding of multi-electrode interactions severely limits current stimulation protocols. For example, current Argus II protocols simply attempt to minimize electric field interactions by maximizing phase delays across electrodes using ‘time-multiplexing’. The assumption is that single-electrode percepts act as atomic ‘building blocks’ of patterned vision. However, these building blocks often fail to assemble into more complex percepts.\nThe goal of this project is therefore to develop new stimulation strategies that minimize perceptual distortions. One potential avenue is to view this as an end-to-end optimization problem, where a deep neural network (encoder) is trained to predict the electrical stimulus needed to produce a desired percept (target).\nImportantly, this model would have to be trained with the phosphene model in the loop, such that the overall network would minimize a perceptual error between the predicted and target output. This is technically challenging, because a phosphene model must be:\n simple enough to be differentiable such that it can be included in the backward pass of a deep neural network, complex enough to be able to explain the spatiotemporal perceptual distortions observed in real prosthesis patients, and amenable to an efficient implementation such that the training of the network is feasible.  ","date":1633046400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1633046400,"objectID":"2c6fc964c5b613455122b2baa2413267","people":null,"permalink":"https://bionicvisionlab.org/research/end-to-end-optimization/","publishdate":"2021-10-01T00:00:00Z","relpermalink":"/research/end-to-end-optimization/","section":"research","summary":"Rather than predicting perceptual distortions, one needs to solve the inverse problem: What is the best stimulus to generate a desired visual percept?","title":"End-to-End Optimization of Bionic Vision","type":"research"},{"categories":null,"content":"Due to the unique requirements of working with bionic eye recipients (e.g., required assistance, increased setup time, travel cost), experimentation with different encoding methods remains challenging and expensive.\nInstead, embedding simulated prosthetic vision (SPV) models in immersive virtual reality (VR) allows sighted subjects to act as virtual patients by \u0026ldquo;seeing\u0026rdquo; through the eyes of the patient, taking into account their head and eye movements as they explore an immersive virtual environment.\nThis can speed up the development process by allowing us to test theoretical predictions in high-throughput experiments, the best of which can be validated and improved upon in an iterative process with the bionic eye recipient in the loop.\n","date":1633046400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1633046400,"objectID":"562dc6f51b794437707ec763e74b8907","people":null,"permalink":"https://bionicvisionlab.org/research/immersive-virtual-reality-simulations/","publishdate":"2021-10-01T00:00:00Z","relpermalink":"/research/immersive-virtual-reality-simulations/","section":"research","summary":"Embedding simulated prosthetic vision models in immersive virtual reality allows sighted subjects to act as virtual patients by \"seeing\" through the eyes of the patient.","title":"Immersive Virtual Reality Simulations of Bionic Vision","type":"research"},{"categories":null,"content":"","date":1632700800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1632700800,"objectID":"1ea7bfff6a164cada4127025bca057b9","people":["Jacob Granley","Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2021-hba-u-net/","publishdate":"2021-09-27T00:00:00Z","relpermalink":"/publications/2021-hba-u-net/","section":"publications","summary":"We propose HBA-U-Net: a U-Net backbone with hierarchical bottleneck attention to highlight retinal abnormalities that may be important for fovea and optic disc segmentation in the degenerated retina.","title":"U-Net with hierarchical bottleneck attention for landmark detection in fundus images of the degenerated retina","type":"publications"},{"categories":[],"content":"Prof. Beyeler was part of the Giz Asks series, where the focused turned to the prospect of using brain-machine interface technology to directly write in information to the brain.\nRead the full interview here.\n","date":1632155340,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1632155340,"objectID":"d4a0e49065c203f630cac27fbfa59336","people":["Michael Beyeler"],"permalink":"https://bionicvisionlab.org/news/2021-09-giz-asks/","publishdate":"2021-09-20T09:29:00-07:00","relpermalink":"/news/2021-09-giz-asks/","section":"news","summary":"Prof. Beyeler was featured in a Giz Asks article about the prospect of using brain-machine interfaces to directly write in information to the brain.","title":"Will it ever be possible to upload information to my brain?","type":"news"},{"categories":null,"content":"What would the world look like with a bionic eye?\nThis graduate course will introduce students to the multidisciplinary field of bionic vision viewed through the lens of computer science, neuroscience, and human-computer interaction.\nThe course will conclude with a programming project (teams of ≤ 4, any language/environment ok) in lieu of a final exam, giving students an opportunity to gain hands-on experience of working on open research problems using methods and tools best suited to their scientific background.\n         Instructor Michael Beyeler (first initial last name at ucsb dot edu)   Class F21, Tue/Thu 9:00 \u0026ndash; 10:50 am, Phelps 3526   Office Hours Tue 2\u0026ndash;4 pm Zoom (schedule a meeting)    \rChangelog:\r 2021-10-09: Switched order of mid-quarter content 2021-09-27: Updated office hours and assigned reading for Week 1 2021-09-15: Posted initial schedule  \rCourse Objectives The course will give an overview of current bionic eye technology designed to restore vision to people living with incurable blindness. By the end of the course, you should be able to:\n identify various types of bionic eye technologies, their differences and similarities explain how the retina and visual cortex support our sense of seeing apply common computer vision \u0026amp; machine learning techniques for stimulus encoding give a nuanced review of the HCI \u0026amp; ethics issues associated with implantable neurotechnology demonstrate your hands-on experience of working on open problems in the field  The course is targeted to a diverse audience spanning computer science (computer vision, human factors, deep learning) to psychology (vision, psychophysics) and brain sciences (computational neuroscience, neuroengineering).\nPrerequisites  There are no official prerequisites for this course. The instructor will do his best to make the course content self-contained, including a crash course in neuroscience \u0026amp; computational vision. However, homeworks and final projects will require programming. Homeworks will be based around pulse2percept, a Python-based simulation framework for bionic vision. Any suitable programming language/framework is ok for the final project.  FAQ  Will classes be in person? Yes, and you are strongly encouraged to attend. What about office hours? I will offer both in-person and virtual office hours. Do instructors and students need to wear a mask in class? Yes. There will be no exceptions to this policy. Sure, it\u0026rsquo;ll be a little weird at first, but I\u0026rsquo;m sure we\u0026rsquo;ll all adjust pretty quickly. What if I can\u0026rsquo;t make a lecture? Send me a quick email before the lecture. You don\u0026rsquo;t need a reason for your first 3 absences. I will do my best to record the lectures and upload them to GauchoCast for those who cannot make a lecture, but I am unable to make any remote accommodations beyond that. What if I\u0026rsquo;m sick or need to quarantine or isolate? Now more important than ever, do not come in if you feel under the weather. Email me, then follow UCSB testing \u0026amp; quarantine protocol. What if the instructor needs to quarantine? In this case we will temporarily shift to remote instruction. What if my question isn\u0026rsquo;t answered here? I\u0026rsquo;m happy to answer your question via email.  Schedule Note: This schedule is subject to slight change over the course of the quarter.\n\r\rWk\rDate\rReading\rTopics\rAction\rHWout\rHWdue\rQuiz\r\r\r\r\r0\rThu\rSep 23\r\rR1\r\r\r\rL1: Introduction\rL2: Bionic Vision - Then \u0026 Now\r\r\r\r\r\r\r\r\r\r1\rTue\rSep 28\rR2, R3\r\r\rL3: Sight Recovery Technologies\rL4: Foundations of Vision\r \r\rHW1\r\r\r\r\rThu\rSep 30\r\r\r\rL5: Computational Neuroscience\rA1: Introduction to Google Colab \u0026 Python\r\r Quiz 1 (Q1) due by Sun, Oct 3, 11:59 pm.\r\r\r\rA1\r\r\rQ1\r\r\r2\rTue\rOct 5\rR4\r\rGuest lecture by Aiwen Xu\r\rL6: Retina in Health \u0026 Disease\r\r\r\r\r\r\r\r\rThu\rOct 7\rR5\r\r\rL7: Retinal Prostheses\r\r Homework 1 (HW1) due by Sun, Oct 10, 11:59 pm.\r\r\r\r\r\rHW1\r\r\r\r3\rTue\rOct 12\rR6\r\r\rL8: Computational Models of Bionic Vision\r\r\r\r\r\r\r\r\rThu\rOct 14\rR7\r\r\rA2: Introduction to pulse2percept in Python\rA3: Group Project Discussion\r\r Quiz 2 (Q2) due by Sun, Oct 17, 11:59 pm.\r\r\r\rA2, A3\rHW2\r\rQ2\r\r\r4\rTue\rOct 19\rR8\r\r\rL9: The Role of Machine Learning in Bionic Vision\r\r\r\r\r\r\r\r\rThu\rOct 21\rR9\r\r\rL10: Optimizing Electrical Stimulation in an Artificial Retina\r\r Homework 2 (HW2) due by Sun, Oct 24, 11:59 pm.\r\r\r\r\r\rHW2\r\r\r\r5\rTue\rOct 26\rR10, R11\r\r\rL11: The Role of Mixed Reality in Bionic Vision\r\r\rA4\r\r\r\r\r\rThu\rOct 28\r\r\rA4: Project Progress Presentations \rTeam \u0026 project description (TPD) due by Sun, Oct 31, 11:59 pm.\r\r  A5\r\rTPD\r\r\r\r6\rTue\rNov 2\rR12\r\r\rL12: The Role of Image Processing in Bionic Vision\rA5: BionicVisionVR Demo by Justin Kasowski\r\r\r\r\r\r\r\r\rThu\rNov 4\rR13\r\r\rL13: The Role of Computer Vision in Bionic Vision\rA6: Smart Bionic Eye\r\r Quiz 3 (Q3) due by Sun, Nov 7, 11:59 pm.\r\r\r\rA6\r\r\rQ3\r\r\r7\rTue\rNov 9\rR14, R15\r\r\rL14: Cortical Prostheses - Approaches \u0026 Challenges\rL15: Phosphene Models for Cortical Prostheses\r\r\r\r\r\r\r\rThu\rNov 11\r\r\rVeterans' Day\r\r\r\r\r\r\r\r8\rTue\rNov 16\rR16, R17\r\r\rL16: Learning to See Again with a Bionic Eye\r\r\r\r\r\r\r\r\rThu\rNov 18\r\r\rA7: Guest Visit by Jason Esterhuizen, ORION implantee \r Quiz 4 (Q4) due by Sun, Nov 21, 11:59 pm.\r\r\r\r\rA7\r\r\r\r\rQ4\r\r\r9\rTue\rNov 23\r\r\rA8: Project Progress Presentations\r\rA8\r\r\r\r\rThu\rNov 25\r\r\r\rThanksgiving Day\r\r\r\r\r\r\r\r10\rTue\rNov 30\r\r\r\r\rL17: The Future of Bionic Vision\r\r\r\r\r\r\r\r\rThu\rDec 2\r\r\r\r\rA9: Quarter Review\r\r\rProject report (PR) \u0026amp; source code (SC) due Sun, Dec 5, 11:59 pm.\r\r\r\r\rA9\r\r\rPR\u0026amp;SC\r\r\r11\rTue\rDec 7\r\rA10: Final Project Presentations\rA10\r\r\r\r\r\r\rCourse Requirements \u0026amp; Grading Your final grade will be determined as follows:\n 20% Homework assignments:  10% Homework 1 10% Homework 2   30% \u0026ldquo;Check Your Knowledge\u0026rdquo; quizzes  10% per quiz Lowest-scoring quiz will be dropped   50% Final project implementation, documentation, and presentation  5% Project proposal presentation (1 slide) 5% Project progress presentation (2 slides: what have you done, what\u0026rsquo;s left to do) 20% Project final presentation 20% Project final report (+5% extra credit if project shows promise of turning into a publication)    Lateness Policy All assignments are due at 11:59:59 pm on the scheduled due date, typically a Sunday (timestamp of the online submission system).\n Each student will be allowed 3 \u0026ldquo;late days\u0026rdquo; over the course of the quarter for which lateness will not be penalized. Late days cannot be applied to project deadlines. Late days may be applied to the quizzes and homework assignments: Anything turned in between 12:00:00 am and 11:59:59 pm the next day is one day late; every day thereafter that an assignment is late, including weekends and holidays, counts as an additional late day. No late work will be accepted after the deadline if you have used up all your late days. If you\u0026rsquo;re not done on time, you should turn in what you have to receive partial credit. No exceptions will be made for the final project report.  Please make sure you understand this policy.\n\u0026ldquo;Check Your Knowledge\u0026rdquo; Quizzes We will have 4 GauchoSpace quizzes over the quarter that test your theoretical/conceptual knowledge of the course content (this includes lectures and assigned reading materials).\nThe following rules apply:\n Quizzes must be completed by Sunday 11:59 pm of the respective week (lateness policy applies) You have 30 mins per attempt A quiz can be taken twice. If you decide to take the quiz again, only your second attempt will be counted (that is, the score from your first attempt will be dropped, this is called \u0026ldquo;grading method: last attempt\u0026rdquo; on GauchoSpace) At the end of the quarter, the lowest-scoring quiz will be dropped. (Each of the 3 highest-scoring quizzes will thus account for 10% of your grade)  Final Project In lieu of a final exam, students will conduct a programming project (team size ≤ 4). The goal of the project is to gain hands-on experience working on open research questions in bionic vision using tools and methods best suited to their scientific background.\nAll projects must address a research question and have a programming component. Students are free to use any programming language and development environment they choose. Building a project based on pulse2percept is encouraged (especially for students with relatively little programming experience) but is by no means required. Reproducing key research findings in the literature is allowed. No pure literature reviews, please.\nProjects that show promise of turning into a publication will receive extra credit.\nStudents will present their project to the rest of the class during finals week. In addition, students will submit a write-up of their project and hand in their source code (see Milestones).\nThe project will be evaluated based on the:\n originality/novelty of the idea technical strength of the work (emphasis on the research, not the programming expertise) organization, clarity, and style of the project report effort and completeness of the work (normalized by the number of team members)  Project Milestones    Date Time Deliverable due     Thu, Oct 14 9:00 am Students start forming teams and discussing project ideas in class.   Thu, Oct 28 9:00 am Teams present their project ideas in class.   Sun, Oct 31 11:59 pm Teams submit a project title and 2-3 sentence project description.   Tue, Nov 23 9:00 am Teams present their project progress in class.   Sun, Dec 5 11:59 pm Teams hand in their final project report and all source code.   Tue, Dec 7 9:00 am Teams make their final project presentations in class.    Students are encouraged to discuss ideas with the instructors, so that feedback can be incorporated early in the process.\nLate days cannot be used on these project deadlines.\nAcademic Integrity The University of California has formal policies related to academic integrity.\nAny act of academic dishonesty, such as cheating or plagiarism, will result in a University disciplinary action and an \u0026ldquo;F\u0026rdquo; in this course. In addition to academic integrity, I also expect everyone in this class to treat their fellow students and course staff with respect.\nBasic Needs If you are facing any challenges securing food or housing and believe this may affect your performance in the class, you are urged to meet with a Food Security and Calfresh Advocate who is aware of the broad variety of resources that UCSB has to offer (see their drop-in hours at food.ucsb.edu). You are also urged to contact the professor if you are comfortable doing so.\nPlease visit food.ucsb.edu for additional resources including Calfresh, the AS Food Bank, and more.\n","date":1628985600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1628985600,"objectID":"2dad7ab16b905e022d4e43580bb840eb","people":null,"permalink":"https://bionicvisionlab.org/teaching/2021-fall-cs291a/","publishdate":"2021-08-15T00:00:00Z","relpermalink":"/teaching/2021-fall-cs291a/","section":"teaching","summary":"This graduate course will introduce students to the multidisciplinary field of bionic vision viewed through the lens of computer science, neuroscience, and human-computer interaction.","title":"CS-291A: Bionic Vision","type":"teaching"},{"categories":null,"content":"Understanding the early visual system in health and disease is a key issue for neuroscience and neuroengineering applications such as visual prostheses.\nAlthough the processing of visual information in the healthy retina and early visual cortex (EVC) has been studied in detail, no comprehensive computational model exists that captures the many cell-level and network-level biophysical changes common to retinal degenerative diseases and other sources of visual impairment.\nTo address this challenge, we are developing computational models of the retina and EVC to elucidate the neural code of vision.\n","date":1627776000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1627776000,"objectID":"2b86195429a6dd5c19256f15a02306aa","people":null,"permalink":"https://bionicvisionlab.org/research/computational-models-visual-system/","publishdate":"2021-08-01T00:00:00Z","relpermalink":"/research/computational-models-visual-system/","section":"research","summary":"Understanding the visual system in health and disease is a key issue for neuroscience and neuroengineering applications such as visual prostheses.","title":"Computational Models of the Visual System","type":"research"},{"categories":null,"content":"How are visual acuity and daily activities affected by visual impairment?\nPrevious studies with people who have retinal degeneration have shown that vision is altered and impaired in the presence of a scotoma. This is also the case when a sighted person is tested under simulated low vision (SLV) conditions. However, the extent to which patient-specific factors affect vision and quality of life is not well understood.\nTesting sighted participants with SLV allows us to compare performance to real patients, design simulations to be as naturalistic as possible, and assess changes in vision for real life tasks instead of relying on acuity alone.\n","date":1622505600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1622505600,"objectID":"8f35d635d63daf950223aa36a8f607ce","people":null,"permalink":"https://bionicvisionlab.org/research/simulated-visual-impairment/","publishdate":"2021-06-01T00:00:00Z","relpermalink":"/research/simulated-visual-impairment/","section":"research","summary":"How are visual acuity and daily activities affected by visual impairment? Previous studies have shown that vision is altered and impaired in the presence of a scotoma, but the extent to which patient-specific factors affect vision and quality of life is not well understood.","title":"Simulating Visual Impairment","type":"research"},{"categories":null,"content":"","date":1620086400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1620086400,"objectID":"ce7e87355e58295ded0c12942f667a7c","people":["Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2021-explainable-ai/","publishdate":"2021-05-04T00:00:00Z","relpermalink":"/publications/2021-explainable-ai/","section":"publications","summary":"We present an explainable artificial intelligence (XAI) model fit on a large longitudinal dataset that can predict electrode deactivation in Argus II.","title":"Explainable AI for retinal prostheses: Predicting electrode deactivation from routine clinical measures","type":"publications"},{"categories":null,"content":"pulse2percept is a BSD-licensed, open-source Python package for simulated prosthetic vision (SPV).\nBuilt on the NumPy and SciPy stacks, as well as contributions from the broader Python community, pulse2percept provides an open-source implementation of several phosphene models for a wide range of state-of-the-art retinal prostheses, to provide insight into the visual experience provided by these devices.\nAs pulse2percept continues to be adopted by several research labs around the globe, we continue to improve its functionality and performance as well as add new implants, models, and datasets.\n","date":1619827200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1619827200,"objectID":"378142164076a4135229e041fb38c801","people":null,"permalink":"https://bionicvisionlab.org/code/pulse2percept/","publishdate":"2021-05-01T00:00:00Z","relpermalink":"/code/pulse2percept/","section":"code","summary":"pulse2percept is an open-source Python simulation framework used to predict the perceptual experience of retinal prosthesis patients across a wide range of implant configurations.","title":"pulse2percept: A Python-Based Simulation Framework for Bionic Vision","type":"code"},{"categories":[],"content":"Research by the Bionic Vision Lab was featured in NVIDIA\u0026rsquo;s I AM AI trailer, which was premiered at NVIDIA GTC 2021:\n","date":1619022540,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1619022540,"objectID":"156026ccc247500095ad40f0c3070210","people":["Aiwen Xu","Michael Beyeler"],"permalink":"https://bionicvisionlab.org/news/2021-04-nvidia-i-am-ai/","publishdate":"2021-04-21T09:29:00-07:00","relpermalink":"/news/2021-04-nvidia-i-am-ai/","section":"news","summary":"Our recent research was featured in NVIDIA's I AM AI trailer, premiered at NVIDIA GTC 2021","title":"Bionic Vision Lab featured in NVIDIA's I AM AI trailer","type":"news"},{"categories":[],"content":"Over the years, cyberpunk tales and sci-fi series have featured characters with cybernetic vision—most recently Star Trek Discovery\u0026rsquo;s Lieutenant Keyla Detmer and her ocular implants. In the real world, restoring “natural” vision is still a complex puzzle, though researchers at UC Santa Barbara are developing a smart prosthesis that provides cues to the visually impaired, much like a computer vision system talks to a self-driving car.\nToday, over 10 million people worldwide are living with profound visual impairment, many due to retinal degeneration diseases. Ahead of this week\u0026rsquo;s Augmented Humans International Conference, we spoke with Dr. Michael Beyeler, Assistant Professor in Computer Science and Psychological \u0026amp; Brain Sciences at UCSB, who is forging ahead with synthetic sight trials at his Bionic Vision Lab and will be presenting a paper at the conference.\nRead the full interview here.\n","date":1614097740,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1614097740,"objectID":"9ef4e2280812af8ef569089d069a0146","people":["Michael Beyeler"],"permalink":"https://bionicvisionlab.org/news/2021-02-pcmag/","publishdate":"2021-02-23T09:29:00-07:00","relpermalink":"/news/2021-02-pcmag/","section":"news","summary":"Instead of focusing on one day restoring ‘natural’ vision, we may be better off thinking about how to create ‘practical’ and ‘useful’ artificial vision now.","title":"PCMag: Building the bionic eye... with car tech?","type":"news"},{"categories":null,"content":"\r","date":1614038400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1614038400,"objectID":"44c941643b53b9b8fe1d9d80e20ef966","people":["Justin Kasowski","Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2021-towards-immersive-vr/","publishdate":"2021-02-23T00:00:00Z","relpermalink":"/publications/2021-towards-immersive-vr/","section":"publications","summary":"We propose to embed biologically realistic models of simulated prosthetic vision in immersive virtual reality so that sighted subjects can act as 'virtual patients' in real-world tasks.","title":"Towards immersive virtual reality simulations of bionic vision","type":"publications"},{"categories":null,"content":"\r","date":1613952000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1613952000,"objectID":"f4d31dde088561df71570dfd3af2cf11","people":["Aiwen Xu","Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2021-scene-simplification/","publishdate":"2021-02-01T00:00:00Z","relpermalink":"/publications/2021-scene-simplification/","section":"publications","summary":"We combined deep learning-based scene simplification strategies with a psychophysically validated computational model of the retina to generate realistic predictions of simulated prosthetic vision.","title":"Deep learning-based scene simplification for bionic vision","type":"publications"},{"categories":null,"content":"Same course as ECE 181. Not open for credit to students who have completed ECE/CMPSC 181B with a grade of C or better. ECE/CMPSC 181 is a legal repeat of ECE/CMPSC 181B.\nPrerequisites: Upper-division standing in Electrical Engineering, Computer Engineering, Computer Science, Chemical Engineering or Mechanical Engineering.\n","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"ae5ee224e19cf700fc8876dd2c5037bf","people":null,"permalink":"https://bionicvisionlab.org/teaching/2021-winter-cs181/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/teaching/2021-winter-cs181/","section":"teaching","summary":"Overview of computer vision problems and techniques for analyzing the content of images and video. Topics include image formation, edge detection, image segmentation, pattern recognition, texture analysis, optical flow, stereo vision, shape representation and recovery techniques, issues in object recognition, and case studies of practical vision systems.","title":"CS/ECE-181: Introduction to Computer Vision","type":"teaching"},{"categories":[],"content":"Dr. Beyeler sat down with Luming Cao from SciSection\u0026rsquo;s Human and Science platform to talk about how bionic vision, as sci-fi as it sounds, is already helping to restore vision to the blind.\nThe transcript of this informal interview is now available, and a podcast will follow soon.\nRead the full interview here.\n","date":1601742540,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1601742540,"objectID":"4a7cc3efbf54119e45e4cf35151fa11c","people":["Michael Beyeler"],"permalink":"https://bionicvisionlab.org/news/2020-10-scisection/","publishdate":"2020-10-03T09:29:00-07:00","relpermalink":"/news/2020-10-scisection/","section":"news","summary":"Prof. Beyeler talks about how bionic vision, as sci-fi as it sounds, is already helping to restore vision to the blind.","title":"SciSection: Interview with Michael Beyeler","type":"news"},{"categories":null,"content":"PSY 110A is the former number of PSY 130. Students who have completed PSY110A with a C- or below may take PSY 130 as a legal repeat.\nPrerequisites: Open to Psychological \u0026amp; Brain Sciences, Biopsychology, and Interdisciplinary Studies majors only.\nWe take our ability to see for granted. It is for the most part automatic and effortless and thus might seem relatively simple. But behind the scenes our brains dedicate over a 1/4 of their machinery to analyze and interpret the light falling on our eyes. How does the brain do it?\nIn this course we will learn how the brain gives rise to our visual experience from seeing depth, color, and motion, to recognizing faces and objects. Importantly, the course illustrates an approach to study psychology and the brain combining behavioral research, neurophysiology and computational theory.\n","date":1601424000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1601424000,"objectID":"42140d1938d80b337f7aa7055292a764","people":null,"permalink":"https://bionicvisionlab.org/teaching/2020-fall-psych130/","publishdate":"2020-09-30T00:00:00Z","relpermalink":"/teaching/2020-fall-psych130/","section":"teaching","summary":"An overview of theory and research into the human performance and biological processes of visual perception. Typical topics may range from the detection of simple stimuli to the identification of objects and events.","title":"PSY-130: Perception - Vision","type":"teaching"},{"categories":[],"content":"Michael Beyeler and the Bionic Vision Lab are featured heavily in the Spring Edition of UCSB\u0026rsquo;s College of Engineering Convergence Magazine:\n\rThere is research to try to understand the brain—how it works on a mechanistic and algorithmic level—and then there's applying that to an engineered system that can interface with the brain. Brain-computer interfaces can be used both for treating neurological and mental disorders as well as for understanding brain function.\r\rRead the full article here.\n","date":1588350540,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1588350540,"objectID":"bfbbcf294ec41d730fd11d17e0061182","people":["Michael Beyeler"],"permalink":"https://bionicvisionlab.org/news/2020-05-convergence/","publishdate":"2020-05-01T09:29:00-07:00","relpermalink":"/news/2020-05-convergence/","section":"news","summary":"In UCSB's College of Engineering, the phrase 'reverse engineering the brain' tends to relate to emerging technologies in neural networks and new machine-learning models that function more like the human brain.","title":"UCSB Convergence: Reverse engineering the brain","type":"news"},{"categories":null,"content":"How does cortical circuitry perform the visual scene analysis needed to support navigation through the environment?\nMost studies of central visual processing are focused on detection or discrimination of specific features of simple artificial stimuli (e.g., orientation, direction of motion, object identity). However, navigation through the environment involves a very different set of computational goals, such as identifying landmarks and using optic flow to avoid obstacles. Furthermore, these computations occur under a very different stimulus regime, with the animal actively sampling a complex and continually moving sensory scene.\nOur goal is to determine how the brain extracts relevant visual features from the rich, dynamic visual input that typifies active exploration, and develop (deep) predictive models of brain activity based on visual input and several behavioral variables. The data includes one-of-a-kind measures of neural activity in mice navigating through real-world and virtual environments, collected using 2-photon imaging and electrophysiology by our collaborators Spencer Smith, Michael Goard, and Cris Niell.\nThe results of this project will provide knowledge about normal visual function and insights for treating impaired vision via prosthetic or assistive devices.\n","date":1577923200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577923200,"objectID":"e1165442b451c1b4848a6243964ca32d","people":null,"permalink":"https://bionicvisionlab.org/research/mouse-visual-navigation/","publishdate":"2020-01-02T00:00:00Z","relpermalink":"/research/mouse-visual-navigation/","section":"research","summary":"How does the brain extract relevant visual features from the rich, dynamic visual input that typifies active exploration, and how does the neural representation of these features support visual navigation?","title":"Cortical Visual Processing for Navigation","type":"research"},{"categories":null,"content":"What would the world look like with a bionic eye?\nThis graduate course will introduce students to the multidisciplinary field of bionic vision, with an emphasis on both the computer science and neuroscience of the field.\nThe course will conclude with a programming project (teams of ≤ 3, any language/environment ok) in lieu of a final exam, giving students an opportunity to gain hands-on experience of working on open research problems using methods and tools best suited to their scientific background.\n         Instructor Michael Beyeler (first initial last name at ucsb dot edu)   Class WQ 2020, Tue/Thu 9:00 \u0026ndash; 10:50 am, Phelps 3526   Office Hours Tue 4:00 \u0026ndash; 5:00 pm or by appointment, Psych East 3822    This website and the Piazza Forum will be used as centers for communication. Homework submission will occur through GauchoSpace. Make sure you are enrolled! (Come to class to get an add code.)\nTable of Contents\r Course Objectives Prerequisites Schedule Course Requirements \u0026amp; Grading Lateness Policy Final Project  Project Milestones Project Presentation Project Report   Academic Integrity Basic Needs  \rCourse Objectives The course will give an overview of current bionic eye technology designed to restore vision to people living with incurable blindness. By the end of the course, you should be able to:\n Identify various types of bionic eye technologies, their differences and similarities Have a basic understanding of the neuroscience of the human visual system Be familiar with common preprocessing, encoding, and electrical stimulation methods Understand the limitations of current bionic eye technologies Have hands-on experience of working on open problems in the field  The course is targeted to a diverse audience spanning from computer science (human factors, neural networks, computer vision) to psychology (vision, psychophysics) and brain sciences (computational neuroscience, neuroengineering).\nPrerequisites  There are no official prerequisites for this course. The instructor will do his best to make the course content self-contained. However, prior programming experience (e.g., Python, Matlab, C++) will be highly beneficial as Homework 2 (HW2) and the final project require programming. Students will be introduced to pulse2percept, a Python-based simulation framework for bionic vision, which will form the basis for HW2 and (optionally) the final project.  Schedule Import calendar:  Note: This schedule is subject to change over the course of the quarter.\n\r\rWk\rDate\rReading\rTopics\rAction\rHW out\rHW due\r\r\r\r\r1\rTue\rJan 7\r\r\r\rIntroduction: Class requirements, policies\rBionic vision: then \u0026amp; now\r\r\r\r\r\r\r\rThu\rJan 9\r\rR1,\rR2\r\r\r\rBlinding eye diseases\rSight restoration approaches \u0026amp; challenges\r\r\r\r\rHW1\r\r\r\r\r2\rTue\rJan 14\r\rR3\r\r\r\rFundamentals of neuroscience\rThe visual system\r\r\r\r\r\r\r\rThu\rJan 16\r\rR4\r\r\r\rComputational neuroscience\rIntroduction to Python\r\r\rHomework 1 (HW1) due by Sun, Jan 19, 11:59 pm.\r\r\r\r\rA1\t\r\rHW1\r\r\r3\rTue\rJan 21\r\rR5,\rR6\r\r\r\rRetina in health \u0026amp; disease\rRetinal prostheses\r\r\r\r\r\r\r\rThu\rJan 23\r\rR7\r\r\r\rIntroduction to pulse2percept in Python\rProject ideas: Discussion \u0026amp; brainstorming\r\r\r\rA2\r\r\r\r\r\r4\rTue\rJan 28\r\rR8\r\r\r\rVisual psychophysics for retinal prostheses\rPhosphene models: Scoreboard, axon map\r\r\r\r\r\r\r\rThu\rJan 30\r\r\rTeams present their project ideas \rTeam \u0026 project description (TPD) due by Sun, Feb 2, 11:59 pm.\r\r\r\r\r\rTPD\r\r\r5\rTue\rFeb 4\r\rR9\r\r\r\rCortical prostheses: approaches, challenges\rPhosphene models for cortical prostheses\r\r\r\r\rHW2\r\r\r\r\rThu\rFeb 6\r\r\r\rMid-quarter review\r\r\r\rA3\r\r\r\r\r\r6\rTue\rFeb 11\r\rR10,\rR11\r\r\r\rTraining \u0026amp; rehabilitation\rCortical plasticity \u0026amp; perceptual learning\r\r\r\r\r\r\r\rThu\rFeb 13\r\r\rGuest Visit: Jason Esterhuizen, ORION implantee\r \rA4\r\r\r\r\r\r7\rTue\rFeb 18\r\rR12, \rR13\r\r\r\rImproving visual outcomes in bionic eye technologies\rAdvanced stimulation strategies\r\r\r\r\r\r\r\rThu\rFeb 20\r\rR14\r\r\r\rOptimizing electrical stimulation in an artificial retina\r\r\rHomework 2 (HW2) due by Sun, Feb 23, 11:59 pm.\r\r\r\r\r\rHW2\r\r\r8\rTue\rFeb 25\r\rR15, \rR16\r\r\r\rScene representation for future bionic eye technologies\rAdvanced encoding methods\r\r\r\r\r\r\r\rThu\rFeb 27\r\r\rTeams present project progress\r\r\r\r\r\r9\rTue\rMar 3\r\rTeams work on projects -- Instructor out of the country\r\r\r\r\r\rThu\rMar 5\r\rTeams work on projects -- Instructor out of the country\r\r\r\r\r\r\r10\rTue\rMar 10\r\rR17\r\r\rGuest Lecture: Dr. Noelle Stiles, USC/Caltech\r\r\r\r\r\r\rThu\rMar 12\r\rR18\r\r\r\rOutlook: Future of bionic vision\rAlternatives to brain-computer interfaces\r\r\rProject report (PR) \u0026amp; source code (SC) due Sun, Mar 15, 11:59 pm.\r\r\r\r\r\rPR\u0026amp;SC\r\r11\rTue\rMar 17\r\rTeams make their final project presentations\r\r\r\r\r\r\rCourse Requirements \u0026amp; Grading Your final grade will be determined as follows:\n 15% Class participation and attendance:  Students are expected to attend all class sessions and actively participate in class discussions and activities. If a student must miss a session, they should email the instructor beforehand. Each student will be allowed 3 excused absences (no detailed explanation required) before their absence will start to negatively affect their participation grade. However, late arrivals and unexcused absences will most definitely have a negative effect on a student\u0026rsquo;s participation grade.   30% Homework assignments:  10% Homework 1 20% Homework 2   55% Final project implementation, documentation, and presentation  5% Project idea presentation (1 slide) 10% Project progress presentation (2 slides: what have you done, what\u0026rsquo;s left to do) 20% Project final presentation 20% Project final report (+5% extra credit if project shows promise of turning into a publication)    Lateness Policy All assignments are due at 11:59:59 pm on the scheduled due date, typically a Sunday (timestamp of the online submission system).\n Each student will be allowed 3 \u0026ldquo;late days\u0026rdquo; over the course of the quarter for which lateness will not be penalized. Late days cannot be applied to project deadlines. Late days may be applied to one or both homework assignments: Anything turned in between 12:00:00 am and 11:59:59 pm the next day is one day late; every day thereafter that an assignment is late, including weekends and holidays, counts as an additional late day. Absolutely no late work will be accepted after the deadline if you have used up all your late days. If you\u0026rsquo;re not done on time, you must turn in what you have to receive partial credit. There will be no exceptions from this rule. No exceptions will be made for the final project report.  Please make sure you understand this policy.\nFinal Project In lieu of a final exam, students will conduct a programming project (team size ≤ 3). The goal of the project is to gain hands-on experience working on open research questions in bionic vision using tools and methods best suited to their scientific background.\nAll projects must address a research question and have a programming component. Students are free to use any programming language and development environment they choose. Building a project based on pulse2percept is encouraged (especially for students with relatively little programming experience) but is by no means required. Reproducing key research findings in the literature is allowed. No pure literature reviews, please.\nProjects that show promise of turning into a publication will receive extra credit.\nStudents will present their project to the rest of the class during finals week. In addition, students will submit a write-up of their project and hand in their source code (see Milestones).\nThe project will be evaluated based on the:\n originality/novelty of the idea technical strength of the work (emphasis on the research, not the programming expertise) organization, clarity, and style of the project report effort and completeness of the work (normalized by the number of team members)  Project Milestones    Date Time Deliverable due     Thu, Jan 23 9:00 am Students start forming teams and discussing project ideas in class.   Thu, Jan 30 9:00 am Teams present their project ideas in class.   Sun, Feb 2 11:59 pm Teams submit a project title and 2-3 sentence project description.   Thu, Feb 27 9:00 am Teams present their project progress in class.   Sun, Mar 15 11:59 pm Teams hand in their final project report and all source code.   Tue, Mar 17  Teams make their final project presentations in class.    Students are encouraged to discuss ideas with the instructors, so that feedback can be incorporated early in the process.\nLate days cannot be used on these project deadlines.\nProject Presentation Teams will present their project via Zoom on Tue, Mar 17.\nEach team will have 20 mins to present (+5 mins for Questions \u0026amp; Answers). Sign up for a time slot here.\nBefore the meeting, decide who will host the slides/demo. This person will share their screen during the meeting. Other team members can choose to be physically present with the person sharing the screen or simply log in from their own computer.\nThere are at least two strategies to present your work:\n Strategy A: Follow the outline of your report  Introduction, Methods, Results, Discussion   Strategy B: Top-down  Give an overview of the project\u0026rsquo;s end result Follow with a detailed discussion of the various features/techniques    Make sure to address the challenges you faced and how you overcame them! What have you learned?\nEvery student in the team must say something.\nProject Report Each team will also submit a write-up of their project:\n Use the CHI Extended Abstracts template Structure your report like a short research paper (~4 pages):  Abstract: ~150 words Introduction (1-2 paragraphs)  What did you study and why?   Related work (1/2 page)  Brief summary of the relevant literature. Make sure to point out gaps in the literature that your project is trying to address.   Methods (1-2 pages)  First paragraph: Describe the big-picture idea behind your system/model/approach. Subsections: Walk the reader through all the steps/features (with pictures/schematics).   Results (1-2 pages)  Structure based on research question(s) and/or experiments. Have 2-3 figures to support your claims. Explain each figure and summarize the findings.   Discussion (1/2 page)  First sentence: Summarize your findings. Discuss: What does it all mean? What have you learned? Future work?      When you\u0026rsquo;re done, zip up the PDF/DOC together with all your source code and upload the zip file to GauchoSpace.\nDon\u0026rsquo;t forget to submit your source code.\nAcademic Integrity The University of California has formal policies related to academic integrity.\nAny act of academic dishonesty, such as cheating or plagiarism, will result in a University disciplinary action and an \u0026ldquo;F\u0026rdquo; in this course. In addition to academic integrity, I also expect everyone in this class to treat their fellow students and course staff with respect.\nBasic Needs If you are facing any challenges securing food or housing and believe this may affect your performance in the class, you are urged to meet with a Food Security and Calfresh Advocate who is aware of the broad variety of resources that UCSB has to offer (see their drop-in hours at food.ucsb.edu). You are also urged to contact the professor if you are comfortable doing so.\nPlease visit food.ucsb.edu for additional resources including Calfresh, the AS Food Bank, and more.\n","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577836800,"objectID":"e575d5ab26bf85a2b9d88aa8cefe5cd2","people":null,"permalink":"https://bionicvisionlab.org/teaching/2020-winter-cs291i/","publishdate":"2020-01-01T00:00:00Z","relpermalink":"/teaching/2020-winter-cs291i/","section":"teaching","summary":"This graduate course will introduce students to the multidisciplinary field of bionic vision, with an emphasis on both the computer science and neuroscience of the field.","title":"CS-291I: Bionic Vision","type":"teaching"},{"categories":null,"content":"Neuromorphic event‐based vision sensors are poised to dramatically improve the latency, robustness and power in applications ranging from smart sensing to autonomous driving and assistive technologies for people who are blind.\nSoon these sensors may power low vision aids and retinal implants, where the visual scene has to be processed quickly and efficiently before it is displayed. However, novel methods are needed to process the unconventional output of these sensors in order to unlock their potential.\n","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577836800,"objectID":"fd8775517ff4ebf614b1c8406a8ad65c","people":null,"permalink":"https://bionicvisionlab.org/research/event-based-vision/","publishdate":"2020-01-01T00:00:00Z","relpermalink":"/research/event-based-vision/","section":"research","summary":"Neuromorphic event-based vision sensors may soon power low vision aids and retinal implants, where the visual scene has to be processed quickly and efficiently before it is displayed.","title":"Event-Based Vision at the Edge","type":"research"},{"categories":null,"content":"There are known individual differences in both ability to learn the layout of novel environments and flexibility of strategies for navigating known environments. It is unclear, however, how navigational abilities and situational awareness are impacted by high-stress scenarios and whether augmented reality (AR) could be employed to enhance performance and situational awareness.\nThis project will investigate three core questions:\n How does a person\u0026rsquo;s navigational abilities change in extreme situations? How can we best train them for these situations? How can vision augmentation be employed to improve situational awareness?  ","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577836800,"objectID":"6d1aaa1b527886d7de38a9b9acd81f7c","people":null,"permalink":"https://bionicvisionlab.org/research/hight-stress-navigation/","publishdate":"2020-01-01T00:00:00Z","relpermalink":"/research/hight-stress-navigation/","section":"research","summary":"How do people's navigatioal abilities change in stressful conditions? How can we best train them for these situations? And how can vision augmentation be employed to improve situational awareness?","title":"Visual Navigation Under High-Stress Conditions","type":"research"},{"categories":[],"content":"","date":1570742503,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570742503,"objectID":"01d43ae4db26724f7e05489e59bab7d8","people":["Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2019-optimal-surgical-placement/","publishdate":"2019-10-10T14:21:43-07:00","relpermalink":"/publications/2019-optimal-surgical-placement/","section":"publications","summary":"We systematically explored the space of possible implant configurations to make recommendations for optimal intraocular positioning of Argus II.","title":"Model-based recommendations for optimal surgical placement of epiretinal implants","type":"publications"},{"categories":null,"content":"","date":1563321600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1563321600,"objectID":"a3097d298d06cb569e35f87e6e81a170","people":["Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2019-data-driven-models-human-neuroscience-neuroengineering/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publications/2019-data-driven-models-human-neuroscience-neuroengineering/","section":"publications","summary":"In this review, we provide an accessible primer to modern modeling approaches and highlight recent data-driven discoveries in the domains of neuroimaging, single-neuron and neuronal population responses, and device neuroengineering.","title":"Data-driven models in human neuroscience and neuroengineering","type":"publications"},{"categories":[],"content":"A new article appeared in PCMag to celebrate the inauguration of the Bionic Vision Lab at UCSB:\n Bionic vision might sound like science fiction, but Dr. Michael Beyeler is working on just that.\n  Originally from Switzerland, Dr. Beyeler is wrapping up his postdoctoral fellow at the University of Washington before moving to the University of California Santa Barbara this fall to head up the newly formed Bionic Vision Lab in the Departments of Computer Science and Psychological \u0026amp; Brain Sciences.\n  We spoke with him about this \u0026ldquo;deep fascination with the brain\u0026rdquo; and how he hopes his work will eventually be able to restore vision to the blind. Here are edited and condensed excerpts from our conversation.\n Read the full article here.\n","date":1562689740,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562689740,"objectID":"cc65e45a3acf72adeb393cedd3b10561","people":["Michael Beyeler"],"permalink":"https://bionicvisionlab.org/news/2019-07-pcmag/","publishdate":"2019-07-09T09:29:00-07:00","relpermalink":"/news/2019-07-pcmag/","section":"news","summary":"Michael Beyeler recently sat down with PCMag to talk about bionic vision and his move to UC Santa Barbara.","title":"PCMag: Restoring vision with bionic eyes - no longer science fiction","type":"news"},{"categories":null,"content":"","date":1561593600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1561593600,"objectID":"386c91297fe76d33fc00b9225d6ec9dd","people":["Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2019-neural-correlates-sparse-coding-dimensionality-reduction/","publishdate":"2019-06-27T00:00:00Z","relpermalink":"/publications/2019-neural-correlates-sparse-coding-dimensionality-reduction/","section":"publications","summary":"Brains face the fundamental challenge of extracting relevant information from high-dimensional external stimuli in order to form the neural basis that can guide an organism's behavior and its interaction with the world. One potential approach to addressing this challenge is to reduce the number of variables required to represent a particular input space (i.e., dimensionality reduction). We review compelling evidence that a range of neuronal responses can be understood as an emergent property of nonnegative sparse coding (NSC)—a form of efficient population coding due to dimensionality reduction and sparsity constraints.","title":"Neural correlates of sparse coding and dimensionality reduction","type":"publications"},{"categories":null,"content":"","date":1561334400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1561334400,"objectID":"9aade570f250a8bdf7d19bf2115101b8","people":["Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2019-axon-map-model/","publishdate":"2019-06-24T00:00:00Z","relpermalink":"/publications/2019-axon-map-model/","section":"publications","summary":"We show that the perceptual experience of retinal implant users can be accurately predicted using a computational model that simulates each individual patient’s retinal ganglion axon pathways.","title":"A model of ganglion axon pathways accounts for percepts elicited by retinal implants","type":"publications"},{"categories":null,"content":"","date":1558310400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1558310400,"objectID":"c444c103408be4d6a1dbd752616ec318","people":["Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2019-biophysical-model-axonal-stimulation/","publishdate":"2019-05-20T00:00:00Z","relpermalink":"/publications/2019-biophysical-model-axonal-stimulation/","section":"publications","summary":"To investigate the effect of axonal stimulation on the retinal response, we developed a computational model of a small population of morphologically and biophysically detailed retinal ganglion cells, and simulated their response to epiretinal electrical stimulation. We found that activation thresholds of ganglion cell somas and axons varied systematically with both stimulus pulse duration and electrode-retina distance. These findings have important implications for the improvement of stimulus encoding methods for epiretinal prostheses.","title":"Biophysical model of axonal stimulation in epiretinal visual prostheses","type":"publications"},{"categories":null,"content":"","date":1557446400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557446400,"objectID":"7364a8adf91ea84cc0fbbd0c04424708","people":["Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2019-retinal-sheet-transplants/","publishdate":"2019-05-10T00:00:00Z","relpermalink":"/publications/2019-retinal-sheet-transplants/","section":"publications","summary":"A Commentary on: Detailed Visual Cortical Responses Generated by Retinal Sheet Transplants in Rats with Severe Retinal Degeneration by AT Foik et al. (2018).","title":"Commentary: Detailed visual cortical responses generated by retinal sheet transplants in rats with severe retinal degeneration","type":"publications"},{"categories":null,"content":"","date":1531440000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1531440000,"objectID":"096961db4e57e2fb4d3906e8230e49cf","people":["Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2018-carlsim4/","publishdate":"2018-07-13T00:00:00Z","relpermalink":"/publications/2018-carlsim4/","section":"publications","summary":"We have developed CARLsim 4, a user-friendly SNN library written in C++ that can simulate large biologically detailed neural networks. Improving on the efficiency and scalability of earlier releases, the present release allows for the simulation using multiple GPUs and multiple CPU cores concurrently in a heterogeneous computing cluster. Benchmarking results demonstrate simulation of 8.6 million neurons and 0.48 billion synapses using 4 GPUs and up to 60x speedup for multi-GPU implementations over a single-threaded CPU implementation, making CARLsim 4 well-suited for large-scale SNN models in the presence of real-time constraints.","title":"CARLsim 4: An open source library for large scale, biologically detailed spiking neural network simulation using heterogeneous clusters","type":"publications"},{"categories":null,"content":"","date":1503360000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1503360000,"objectID":"b5e80da46501c93df7df8c6fb3c5fc7f","people":["Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2017-learning-to-see-again/","publishdate":"2017-08-22T00:00:00Z","relpermalink":"/publications/2017-learning-to-see-again/","section":"publications","summary":"The goal of this review is to summarize the vast basic science literature on developmental and adult cortical plasticity with an emphasis on how this literature might relate to the field of prosthetic vision.","title":"Learning to see again: Biological constraints on cortical plasticity and the implications for sight restoration technologies","type":"publications"},{"categories":null,"content":"\r","date":1498867200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1498867200,"objectID":"0f9bbe69fd665667e284936ab7bda6e7","people":["Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2017-pulse2percept/","publishdate":"2017-07-01T00:00:00Z","relpermalink":"/publications/2017-pulse2percept/","section":"publications","summary":"*pulse2percept* is an open-source Python simulation framework used to predict the perceptual experience of retinal prosthesis patients across a wide range of implant configurations.","title":"pulse2percept: A Python-based simulation framework for bionic vision","type":"publications"},{"categories":null,"content":"","date":1470009600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1470009600,"objectID":"6010a0be9a85e86c6ad356a4d230a9e2","people":["Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2016-sparse-decomposition-model/","publishdate":"2016-08-01T00:00:00Z","relpermalink":"/publications/2016-sparse-decomposition-model/","section":"publications","summary":"Using a dimensionality reduction technique known as non-negative matrix factorization, we found that a variety of medial superior temporal (MSTd) neural response properties could be derived from MT-like input features. The responses that emerge from this technique, such as 3D translation and rotation selectivity, spiral tuning, and heading selectivity, can account for a number of empirical results. These findings (1) provide a further step toward a scientific understanding of the often nonintuitive response properties of MSTd neurons; (2) suggest that response properties, such as complex motion tuning and heading selectivity, might simply be a byproduct of MSTd neurons performing dimensionality reduction on their inputs; and (3) imply that motion perception in the cortex is consistent with ideas from the efficient-coding and free-energy principles.","title":"3D visual response properties of MSTd emerge from an efficient, sparse population code","type":"publications"},{"categories":null,"content":"","date":1448928000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1448928000,"objectID":"de49b660f9fc238f3af998f4dfc28f79","people":["Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2015-gpu-visually-guided-robot-navigation/","publishdate":"2015-12-01T00:00:00Z","relpermalink":"/publications/2015-gpu-visually-guided-robot-navigation/","section":"publications","summary":"We present a cortical neural network model for visually guided navigation that has been embodied on a physical robot exploring a real-world environment. The model includes a rate based motion energy model for area V1, and a spiking neural network model for cortical area MT. The model generates a cortical representation of optic flow, determines the position of objects based on motion discontinuities, and combines these signals with the representation of a goal location to produce motor commands that successfully steer the robot around obstacles toward the goal. This study demonstrates how neural signals in a model of cortical area MT might provide sufficient motion information to steer a physical robot on human-like paths around obstacles in a real-world environment.","title":"A GPU-accelerated cortical neural network model for visually guided robot navigation","type":"publications"},{"categories":null,"content":"","date":1436659200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1436659200,"objectID":"4c7bedf1cb0d806fe2aece390417d28c","people":["Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2015-carlsim3/","publishdate":"2015-07-12T00:00:00Z","relpermalink":"/publications/2015-carlsim3/","section":"publications","summary":"We have developed CARLsim 3, a user-friendly, GPU-accelerated SNN library written in C/C++ that is capable of simulating biologically detailed neural models. The present release of CARLsim provides a number of improvements over our prior SNN library to allow the user to easily analyze simulation data, explore synaptic plasticity rules, and automate parameter tuning. In the present paper, we provide examples and performance benchmarks highlighting the library's features.","title":"CARLsim 3: A user-friendly and highly optimized library for the creation of neurobiologically detailed spiking neural networks","type":"publications"},{"categories":null,"content":"","date":1401580800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1401580800,"objectID":"9dfaef9074cb247761c6511079679203","people":["Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2014-vision-road-lane-detection/","publishdate":"2014-06-01T00:00:00Z","relpermalink":"/publications/2014-vision-road-lane-detection/","section":"publications","summary":"This paper presents an integrative approach to ego-lane detection that aims to be as simple as possible to enable real-time computation while being able to adapt to a variety of urban and rural traffic scenarios. The approach at hand combines and extends a road segmentation method in an illumination-invariant color image, lane markings detection using a ridge operator, and road geometry estimation using RANdom SAmple Consensus (RANSAC). The power and robustness of this algorithm has been demonstrated in a car simulation system as well as in the challenging KITTI data base of real-world urban traffic scenarios.","title":"Vision-based robust road lane detection in urban environments","type":"publications"},{"categories":null,"content":"","date":1391558400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1391558400,"objectID":"a53663b6b62012e138a0743d6e6dfef2","people":["Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2014-snn-pattern-motion/","publishdate":"2014-01-20T00:00:00Z","relpermalink":"/publications/2014-snn-pattern-motion/","section":"publications","summary":"We present a two-stage model of visual area MT that we believe to be the first large-scale spiking network to demonstrate pattern direction selectivity. In this model, component-direction-selective (CDS) cells in MT linearly combine inputs from V1 cells that have spatiotemporal receptive fields according to the motion energy model of Simoncelli and Heeger. Pattern-direction-selective (PDS) cells in MT are constructed by pooling over MT CDS cells with a wide range of preferred directions. Responses of our model neurons are comparable to electrophysiological results for grating and plaid stimuli as well as speed tuning.","title":"Efficient spiking neural network model of pattern motion selectivity in visual cortex","type":"publications"},{"categories":null,"content":"","date":1390176000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1390176000,"objectID":"da2f3225cbcc97db91c2933db3c0c0ee","people":["Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2014-gpgpu-accelerated-simulation-parameter-tuning/","publishdate":"2014-01-20T00:00:00Z","relpermalink":"/publications/2014-gpgpu-accelerated-simulation-parameter-tuning/","section":"publications","summary":"We describe a simulation environment that can be used to design, construct, and run spiking neural networks (SNNs) quickly and efficiently using graphics processing units (GPUs). We then explain how the design of the simulation environment utilizes the parallel processing power of GPUs to simulate large-scale SNNs and describe recent modeling experiments performed using the simulator. Finally, we present an automated parameter tuning framework that utilizes the simulation environment and evolutionary algorithms to tune SNNs.","title":"GPGPU accelerated simulation and parameter tuning for neuromorphic applications","type":"publications"},{"categories":null,"content":"","date":1385856000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1385856000,"objectID":"e469311b24ad43d62ae7a26f056d1942","people":["Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2013-categorization-mnist-stdp/","publishdate":"2013-12-01T00:00:00Z","relpermalink":"/publications/2013-categorization-mnist-stdp/","section":"publications","summary":"We present a large-scale model of a hierarchical spiking neural network (SNN) that integrates a low-level memory encoding mechanism with a higher-level decision process to perform a visual classification task in real-time. The model consists of Izhikevich neurons and conductance-based synapses for realistic approximation of neuronal dynamics, a spike-timing-dependent plasticity (STDP) synaptic learning rule with additional synaptic dynamics for memory encoding, and an accumulator model for memory retrieval and categorization. The full network, which comprised 71,026 neurons and approximately 133 million synapses, ran in real-time on a single off-the-shelf graphics processing unit (GPU). The network achieved 92% correct classifications on MNIST in 100 rounds of random sub-sampling, which is comparable to other SNN approaches and provides a conservative and reliable performance metric. Additionally, the model correctly predicted reaction times from psychophysical experiments. Because of the scalability of the approach and its neurobiological fidelity, the current model can be extended to an efficient neuromorphic implementation that supports more generalized object recognition and decision-making architectures found in the brain.","title":"Categorization and decision-making in a neurobiologically plausible spiking network using a STDP-like plasticity rule","type":"publications"},{"categories":null,"content":"","date":1288569600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1288569600,"objectID":"1df3e4d282d890015a5345a70810e5d6","people":["Michael Beyeler"],"permalink":"https://bionicvisionlab.org/publications/2010-exploring-olfactory-networks/","publishdate":"2010-11-01T00:00:00Z","relpermalink":"/publications/2010-exploring-olfactory-networks/","section":"publications","summary":"Olfactory stimuli are represented in a high-dimensional space by neural networks of the olfactory system. While a number of studies have illustrated the importance of inhibitory networks within the olfactory bulb or the antennal lobe for the shaping and processing of olfactory information, it is not clear how exactly these inhibitory networks are organized to provide filtering and contrast enhancement capabilities. In this work the aim is to study the topology of the proposed networks by using software simulations and hardware implementation. While we can study the dependence of the activity on each parameter of the theoretical models with the simulations, it is important to understand whether the models can be used in robotic applications for real-time odor recognition. We present the results of a linear simulation, a spiking simulation with I\u0026F neurons and a real-time hardware emulation using neuromorphic VLSI chips.","title":"Exploring olfactory sensory networks: Simulations and hardware emulation","type":"publications"},{"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"0345abb3184f3021cfe981d9c1b0ead1","people":[],"permalink":"https://bionicvisionlab.org/collaborators/boynton_geoff/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/collaborators/boynton_geoff/","section":"collaborators","summary":"","title":"","type":"collaborators"},{"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"e81cc6a213259bcccd0481e866fc4f73","people":[],"permalink":"https://bionicvisionlab.org/collaborators/brunton_bing/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/collaborators/brunton_bing/","section":"collaborators","summary":"","title":"","type":"collaborators"},{"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"d159791a8442e301af2f6ce0f7b65bb5","people":[],"permalink":"https://bionicvisionlab.org/collaborators/dagnelie_gislin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/collaborators/dagnelie_gislin/","section":"collaborators","summary":"","title":"","type":"collaborators"},{"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"cbd88cd6538699a558bbbcd23229ab06","people":[],"permalink":"https://bionicvisionlab.org/collaborators/eckstein_miguel/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/collaborators/eckstein_miguel/","section":"collaborators","summary":"","title":"","type":"collaborators"},{"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"e0941d3038b77f624edd5c354cfe2612","people":[],"permalink":"https://bionicvisionlab.org/collaborators/fernandez_eduardo/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/collaborators/fernandez_eduardo/","section":"collaborators","summary":"","title":"","type":"collaborators"},{"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"bd76d6c0532e954c7a69a73fc2b83f16","people":[],"permalink":"https://bionicvisionlab.org/collaborators/fine_ione/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/collaborators/fine_ione/","section":"collaborators","summary":"","title":"","type":"collaborators"},{"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"124fe87861e790e184e6a15a299416f0","people":[],"permalink":"https://bionicvisionlab.org/collaborators/giesbrecht_barry/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/collaborators/giesbrecht_barry/","section":"collaborators","summary":"","title":"","type":"collaborators"},{"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"08cb4baf0e819a154a89d51ccf472b0a","people":[],"permalink":"https://bionicvisionlab.org/collaborators/goard_michael/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/collaborators/goard_michael/","section":"collaborators","summary":"","title":"","type":"collaborators"},{"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"5aa56499202dd4f4d2674829cdead929","people":[],"permalink":"https://bionicvisionlab.org/collaborators/grafton_scott/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/collaborators/grafton_scott/","section":"collaborators","summary":"","title":"","type":"collaborators"},{"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"4c0e7e578fe0a2de11ccdf2b92688825","people":[],"permalink":"https://bionicvisionlab.org/collaborators/hegarty_mary/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/collaborators/hegarty_mary/","section":"collaborators","summary":"","title":"","type":"collaborators"},{"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"826508bc3d1b39eb7e478070cf266785","people":[],"permalink":"https://bionicvisionlab.org/collaborators/montezuma_sandra/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/collaborators/montezuma_sandra/","section":"collaborators","summary":"","title":"","type":"collaborators"},{"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"6c8afc0395cca73b0f99c53bfdf0e212","people":[],"permalink":"https://bionicvisionlab.org/collaborators/niell_cris/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/collaborators/niell_cris/","section":"collaborators","summary":"","title":"","type":"collaborators"},{"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"74edf1fcd71e82ad16afe5f271aa8723","people":[],"permalink":"https://bionicvisionlab.org/collaborators/open_ra/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/collaborators/open_ra/","section":"collaborators","summary":"","title":"","type":"collaborators"},{"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"b194678a7a6a010af51b3a392b87fdf4","people":[],"permalink":"https://bionicvisionlab.org/collaborators/open_student/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/collaborators/open_student/","section":"collaborators","summary":"","title":"","type":"collaborators"},{"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"a53ebfbe9e0f7c87114a1f4ff9c06cf1","people":[],"permalink":"https://bionicvisionlab.org/collaborators/rokem_ariel/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/collaborators/rokem_ariel/","section":"collaborators","summary":"","title":"","type":"collaborators"},{"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"0302f9c6a7657d8d70c47c800a1047ae","people":[],"permalink":"https://bionicvisionlab.org/collaborators/second_sight/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/collaborators/second_sight/","section":"collaborators","summary":"","title":"","type":"collaborators"},{"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"6636f6af3ca44951f03a6496c0f51b51","people":[],"permalink":"https://bionicvisionlab.org/collaborators/smith_spencer/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/collaborators/smith_spencer/","section":"collaborators","summary":"","title":"","type":"collaborators"},{"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f19bf5bee0480291e98f9538f6ec0325","people":[],"permalink":"https://bionicvisionlab.org/collaborators/weiland_jim/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/collaborators/weiland_jim/","section":"collaborators","summary":"","title":"","type":"collaborators"},{"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"a1b2db76f8bcd92aee74d434c799bf16","people":[],"permalink":"https://bionicvisionlab.org/grants/2021-r01-mouse/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/grants/2021-r01-mouse/","section":"grants","summary":"","title":"Cortical visual processing for navigation","type":"grants"},{"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"d1700e2bc315bd058766abe8cb79f635","people":[],"permalink":"https://bionicvisionlab.org/grants/2021-ucsb-academic-senate/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/grants/2021-ucsb-academic-senate/","section":"grants","summary":"","title":"Event-based scene understanding for bionic vision","type":"grants"},{"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"5f9f1c6b4bbfb3b16bb7ad8059923366","people":[],"permalink":"https://bionicvisionlab.org/grants/2022-dp2-new-innovator/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/grants/2022-dp2-new-innovator/","section":"grants","summary":"","title":"Towards a Smart Bionic Eye: AI-Powered Artificial Vision for the Treatment of Incurable Blindness","type":"grants"},{"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"449e696159cfd0650277154e94d8219e","people":[],"permalink":"https://bionicvisionlab.org/grants/2020-r00-virtual-prototyping/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/grants/2020-r00-virtual-prototyping/","section":"grants","summary":"","title":"Virtual prototyping for retinal prosthesis patients","type":"grants"},{"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"4e6594480155b2f52ee673351ff91384","people":[],"permalink":"https://bionicvisionlab.org/grants/2021-icb-army/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/grants/2021-icb-army/","section":"grants","summary":"","title":"Visual navigation under high-stress conditions","type":"grants"}]