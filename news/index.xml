<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>In the News on Bionic Vision Lab</title>
    <link>https://bionicvisionlab.org/news/</link>
    <description>Recent content in In the News on Bionic Vision Lab</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator>
    <language>en-us</language>
    <copyright>&amp;copy; {year}</copyright>
    <lastBuildDate>Fri, 09 May 2025 09:59:00 +0000</lastBuildDate>
    
	    <atom:link href="https://bionicvisionlab.org/news/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Eye on Vision podcast features Lily Turkstra’s research on home-based assistive technology</title>
      <link>https://bionicvisionlab.org/news/2025-05-wypl-fm-eye-on-vision/</link>
      <pubDate>Fri, 09 May 2025 09:59:00 +0000</pubDate>
      
      <guid>https://bionicvisionlab.org/news/2025-05-wypl-fm-eye-on-vision/</guid>
      <description>&lt;p&gt;In the May 9 episode of WYPL-FM’s Eye on Vision, PhD student Lily Turkstra discussed the findings of her recent Scientific Reports paper, which draws on 16 interviews to reveal how blind and low-vision individuals adapt instrumental daily tasks at home.&lt;/p&gt;
&lt;p&gt;She highlighted persistent challenges such as locating misplaced objects, the cascading impact of software updates on accessibility, and the limited awareness of formal training programs. The conversation underscored the study’s call for more seamlessly integrated assistive technologies that align with users’ existing problem-solving strategies and ultimately enhance everyday independence.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://eyeonvision.blogspot.com/2025/05/assistive-technology-use-in-home-and-ai.html&#34;&gt;https://eyeonvision.blogspot.com/2025/05/assistive-technology-use-in-home-and-ai.html&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Michael Beyeler receives Harold J. Plous Memorial Award 2024-25</title>
      <link>https://bionicvisionlab.org/news/2024-11-beyeler-plous-award/</link>
      <pubDate>Fri, 01 Nov 2024 09:59:00 +0000</pubDate>
      
      <guid>https://bionicvisionlab.org/news/2024-11-beyeler-plous-award/</guid>
      <description>&lt;p&gt;Dr. Michael Beyeler of the departments of Computer Science and Psychlogical &amp;amp; Brain Sciences is the recipient of the Harold J. Plous Memorial Award 2024-25. The honor recognizes Dr. Beyeler&amp;rsquo;s oustanding contributions in research, teaching, and service, embodying the spirit of excellence and innovation that defines the UCSB academic community.&lt;/p&gt;
&lt;p&gt;Dr. Beyeler has established himself as a leading interdisciplinary researcher, making groundbreaking advances in both theoretical understanding of vision and the development of technologies that improve the quality of life for individuals with visual impairments. His research focuses on bridging neuroscience, computer science, engineering, and psychology to enhance sight recovery techniques, specifically retinal implants — often referred to as bionic eyes. His work has significantly advanced our understanding of how the brain processes visual information, offering insights that can be applied to developing artificial vision systems.&lt;/p&gt;
&lt;p&gt;One of Dr. Beyeler&amp;rsquo;s most notable contributions is his development of computational models that predict how users of visual prostheses perceive their surroundings. His work has been pivotal in enhancing the spatial resolution of current retinal implants, providing cruical insights into improving these technologies. This line of research has had a profound impact on the field of neuroscience, and Dr. Beyeler&amp;rsquo;s innovations have earned international recognition, including being featued in the NIH documentary &amp;ldquo;Toward a Smart Bionic Eye.&amp;rdquo; With 38 publications in top-tier journals and conference proceedings, over $2 million in active research funding, and numerous awards — including the highly prestigious NIH New Innovator Award — Dr. Beyeler&amp;rsquo;s accomplishments in research and service are truly remarkable.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://cs.ucsb.edu/happenings/awards/michael-beyeler-receives-harold-j-plous-memorial-award-2024-25&#34;&gt;https://cs.ucsb.edu/happenings/awards/michael-beyeler-receives-harold-j-plous-memorial-award-2024-25&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>BionicVisionXR featured at Unite 2024</title>
      <link>https://bionicvisionlab.org/news/2024-10-unity-sentis/</link>
      <pubDate>Thu, 17 Oct 2024 09:59:00 +0000</pubDate>
      
      <guid>https://bionicvisionlab.org/news/2024-10-unity-sentis/</guid>
      <description>&lt;p&gt;Our latest research on simulating prosthetic vision was highlighted at Unite 2024 during a presentation on Unity Sentis, Unity&amp;rsquo;s AI neural engine. The presentation showcased how Unity Sentis enables real-time execution of computationally expensive AI models within Unity Runtime.&lt;/p&gt;
&lt;p&gt;Our project focuses on using neurophysiologically inspired and psychophysically validated models to simulate the visual experiences that could be generated by future bionic eye implants. These models are integrated into immersive virtual reality (VR) environments, updating in real time based on user head and eye movements. By leveraging Unity Sentis, we can run these models efficiently, allowing us to create realistic simulations of what individuals with prosthetic vision may experience.&lt;/p&gt;
&lt;iframe width=&#34;800&#34; height=&#34;450&#34; src=&#34;https://www.youtube.com/embed/T-sbHvDF6Bw?si=IKpqfGzAsatdlYo_&amp;amp;start=581&#34; title=&#34;YouTube video player&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share&#34; allowfullscreen&gt;&lt;/iframe&gt;
&lt;p&gt;Big thanks to Unity&amp;rsquo;s Bill Cullen and Alexandre Ribard for making this happen!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Towards a Smart Bionic Eye</title>
      <link>https://bionicvisionlab.org/news/2024-02-nih-smart-bionic-eye/</link>
      <pubDate>Wed, 28 Feb 2024 09:59:00 +0000</pubDate>
      
      <guid>https://bionicvisionlab.org/news/2024-02-nih-smart-bionic-eye/</guid>
      <description>&lt;p&gt;“There’s up to six million people worldwide who live with profound blindness,” Prof. Beyeler explains in the newly released video, “and the idea of a visual prosthesis is to replace lost functionality with an implant. Even though these devices are already out there, the vision they provide is rather limited.”&lt;/p&gt;
&lt;p&gt;With current visual prostheses, blind users are able to see something but not know what it is that they’re looking at. Beyeler’s work intends to fill these gaps, integrating AI and object recognition technology into the devices to let the user know, for example, whether the object they’re looking at is another human or a car or a trash can or something else.&lt;/p&gt;
&lt;iframe width=&#34;800&#34; height=&#34;450&#34; src=&#34;https://www.youtube.com/embed/m2WXEjewqho?si=ZmUSoFthe7Mptz2P&#34; title=&#34;YouTube video player&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share&#34; allowfullscreen&gt;&lt;/iframe&gt;
&lt;p&gt;“If a smart bionic eye gets developed through this research, It’s going to change the lives of millions of people around the world, not just myself,” says Jason Esterhuizen, a bionic eye user. “Blindness will not be an issue any more.”&lt;/p&gt;
&lt;p&gt;“It’s my life’s work,” adds UCSB PhD student Lucas Gil Nadolskis. “It’s more than research. For a lot of people working with this, it’s a cool little project. For me it’s deeply personal. It’s the goal of my life.”&lt;/p&gt;
&lt;p&gt;An audio-described version of the video is available below:&lt;/p&gt;
&lt;iframe width=&#34;800&#34; height=&#34;450&#34; src=&#34;https://www.youtube.com/embed/vlpG_WRLfw0?si=XRN3XxdEmBbficr9&#34; title=&#34;YouTube video player&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share&#34; allowfullscreen&gt;&lt;/iframe&gt;
&lt;p&gt;An extended version is available as a &lt;a href=&#34;https://www.nnlm.gov/podcast/towards-a-smart-bionic-eye&#34;&gt;NNLM Discovery Podcast&lt;/a&gt; episode below (&lt;a href=&#34;https://www.nnlm.gov/podcast/towards-a-smart-bionic-eye&#34;&gt;transcript&lt;/a&gt;):&lt;/p&gt;
&lt;iframe width=&#34;800&#34; height=&#34;450&#34; src=&#34;https://www.youtube.com/embed/AhEEEyYAegA?si=Ja3SRnQKwJMoHvi3&#34; title=&#34;YouTube video player&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share&#34; allowfullscreen&gt;&lt;/iframe&gt;
&lt;p&gt;Related coverage:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;NNLM Podcast: &lt;a href=&#34;https://www.nnlm.gov/podcast/towards-a-smart-bionic-eye&#34;&gt;https://www.nnlm.gov/podcast/towards-a-smart-bionic-eye&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;CS@UCSB: &lt;a href=&#34;https://cs.ucsb.edu/happenings/news/towards-smart-bionic-eye&#34;&gt;https://cs.ucsb.edu/happenings/news/towards-smart-bionic-eye&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Daily Nexus: &lt;a href=&#34;https://dailynexus.com/2023-07-07/ucsb-professor-receives-nih-directors-new-innovator-award/&#34;&gt;https://dailynexus.com/2023-07-07/ucsb-professor-receives-nih-directors-new-innovator-award/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;UCSB Current: &lt;a href=&#34;https://news.ucsb.edu/2022/020732/clear-vision&#34;&gt;https://news.ucsb.edu/2022/020732/clear-vision&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>3 papers accepted at NeurIPS &#39;23</title>
      <link>https://bionicvisionlab.org/news/2023-09-neurips/</link>
      <pubDate>Thu, 21 Sep 2023 09:59:00 -0700</pubDate>
      
      <guid>https://bionicvisionlab.org/news/2023-09-neurips/</guid>
      <description>&lt;p&gt;The lab had 3 papers accepted at NeurIPS &amp;lsquo;23:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;PhD students &lt;a href=&#34;https://bionicvisionlab.org/people/aiwen_xu&#34;&gt;Aiwen Xu&lt;/a&gt; and &lt;a href=&#34;https://bionicvisionlab.org/people/yuchen_hou&#34;&gt;Yuchen Hou&lt;/a&gt; developed a multimodal recurrent neural net 
that well describes V1 activity in freely moving mice, revealing how some neurons lack pronounced visual RFs and that 
most neurons exhibit mixed selectivity:&lt;/p&gt;
&lt;p&gt;A Xu, Y Hou, CM Niell, M Beyeler (2023). &lt;a href=&#34;https://bionicvisionlab.org/publications/2023-12-v1-mouse/&#34;&gt;Multimodal deep learning model unveils behavioral 
dynamics of V1 activity in freely moving mice&lt;/a&gt;. 
&lt;em&gt;37th Conference on Neural Information Processing Systems (NeurIPS) &amp;lsquo;23&lt;/em&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The latest work by PhD students &lt;a href=&#34;https://bionicvisionlab.org/people/galen_pogoncheff&#34;&gt;Galen Pogoncheff&lt;/a&gt; and &lt;a href=&#34;https://bionicvisionlab.org/people/jacob_granley&#34;&gt;Jacob Granley&lt;/a&gt;
enriches ResNet50 (the previously best V1-aligned deep net) with layers that simulate the processing hallmarks of the 
early visual system and assesses how they affect model-brain alignment:&lt;/p&gt;
&lt;p&gt;G Pogoncheff, J Granley, M Beyeler (2023). &lt;a href=&#34;https://bionicvisionlab.org/publications/2023-12-v1-monkey-neuroai/&#34;&gt;Explaining V1 properties with a biologically constrained deep learning 
architecture&lt;/a&gt;. &lt;em&gt;37th Conference on Neural Information Processing Systems (NeurIPS) &amp;lsquo;23&lt;/em&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;And last but not least, &lt;a href=&#34;https://bionicvisionlab.org/people/jacob_granley&#34;&gt;Jacob Granley&lt;/a&gt; (in collab w/ Tristan Fauvel &amp;amp; Matthew Chalk from Sorbonne University)
combined deep stimulus encoding with preferential Bayesian optimization to develop personalized stimulation strategies for 
neural prostheses:&lt;/p&gt;
&lt;p&gt;J Granley, T Fauvel, M Chalk, M Beyeler (2023). &lt;a href=&#34;https://bionicvisionlab.org/publications/2023-12-hilo-stimulus-encoding/&#34;&gt;Human-in-the-loop optimization for deep stimulus encoding in visual 
prostheses&lt;/a&gt;. &lt;em&gt;37th Conference on Neural Information Processing Systems (NeurIPS) &amp;lsquo;23&lt;/em&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Towards a &lt;i&gt;Smart Bionic Eye&lt;/i&gt;</title>
      <link>https://bionicvisionlab.org/news/2022-10-new-innovator/</link>
      <pubDate>Tue, 04 Oct 2022 09:59:00 +0000</pubDate>
      
      <guid>https://bionicvisionlab.org/news/2022-10-new-innovator/</guid>
      <description>&lt;p&gt;Prof. Beyeler aims to bring to the mainstream an artificial intelligence (AI)-powered bionic eye that can generate artificial vision, in an effort to increase the quality of life for patients who are blind or visually impaired.&lt;/p&gt;
&lt;p&gt;“I envision a smart bionic eye that could find misplaced keys on a counter, read out medication labels, inform a user about people’s gestures and facial expressions during social interactions, and warn a user of nearby obstacles and outline safe paths,” he said.&lt;/p&gt;
&lt;p&gt;For his project, “Towards a Smart Bionic Eye: AI-Powered Artificial Vision for the Treatment of Incurable Blindness,” Beyeler has been selected for a National Institutes of Health (NIH) Director’s New Innovator Award. The five-year, $1.5 million grant was &lt;a href=&#34;https://commonfund.nih.gov/newinnovator/AwardRecipients&#34; target=&#34;_blank&#34;&gt;one of 72 awarded&lt;/a&gt; this week by the NIH to enable exceptionally creative early-career scientists to push the boundaries of biomedical science and pursue high-impact projects that aim to advance knowledge and enhance health.&lt;/p&gt;
&lt;p&gt;“I offer my sincerest congratulations to Professor Beyeler for having his innovative research recognized with the prestigious NIH Director&amp;rsquo;s New Innovator Award,” said Tresa Pollock, the interim dean of the College of Engineering and Alcoa Distinguished Professor of Materials. “His novel approach of using recent advances in computer vision, AI and neuroscience has tremendous potential to uncover new knowledge and provide millions of people with useful vision through a smart bionic eye.”&lt;/p&gt;
&lt;p&gt;Read the full article &lt;a href=&#34;https://www.news.ucsb.edu/2022/020732/clear-vision&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Greedy optimization of electrode arrangement for epiretinal prostheses</title>
      <link>https://bionicvisionlab.org/news/2022-09-miccai-daily/</link>
      <pubDate>Mon, 19 Sep 2022 01:29:00 +0000</pubDate>
      
      <guid>https://bionicvisionlab.org/news/2022-09-miccai-daily/</guid>
      <description>&lt;p&gt;Current epiretinal implants arrange their electrodes on a rectangular grid.
&lt;i&gt;&amp;ldquo;Some people have looked at where to place the whole implant on the retina&amp;rdquo;&lt;/i&gt;, says Prof. Beyeler. &lt;i&gt;&amp;ldquo;Ashley was the first to ask, what if we moved every individual electrode around
based on what we know about how these electrodes produce artificial vision?&amp;quot;&lt;/i&gt;&lt;/p&gt;
&lt;p&gt;However, moving every electrode presents the problem of
combinatorial explosion. Even in current devices with only 60
electrodes, there are many possibilities for arranging them. It is not
usually technically feasible to find a solution.&lt;/p&gt;
&lt;p&gt;&lt;i&gt;&amp;ldquo;Ashley approached this as a greedy optimization problem, where one
electrode is placed after another&amp;rdquo;&lt;/i&gt;, explains Prof. Beyeler.
&lt;i&gt;&amp;ldquo;We used a
computational model of bionic vision to help predict what the vision
would look like for a given electrode placement. By iterating over that,
Ashley found a mathematically proven optimal solution.&amp;quot;&lt;/i&gt;&lt;/p&gt;
&lt;p&gt;Read the full article at &lt;a href=&#34;https://www.rsipvision.com/MICCAI2022-Monday/16/&#34; target=&#34;_blank&#34;&gt;rsipvision.com&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The paper has been accepted at MICCAI &amp;lsquo;22.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Bionic Vision Lab Member Awards 2022</title>
      <link>https://bionicvisionlab.org/news/2022-08-awards/</link>
      <pubDate>Mon, 01 Aug 2022 01:29:00 -0700</pubDate>
      
      <guid>https://bionicvisionlab.org/news/2022-08-awards/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;byron-poster.jpg&#34; align=&#34;left&#34; alt=&#34;Byron Johnson presenting a poster at the Active Vision workshop in Rochester&#34; class=&#34;mr-2&#34; style=&#34;width: 40%&#34;/&gt;
Ph.D. student &lt;a href=&#34;https://bionicvisionlab.org/people/johnson_byron&#34;&gt;Byron Johnson&lt;/a&gt; won not just one, but three travel awards for his exciting work using eye tracking to simulate artificial scotomas (damaged regions of the visual field) and their effects on visual processing and eye movements.
In late May, Byron&#39;s poster &#34;The Effect of a Simulated Scotoma on Rapid Scene Understanding&#34; was selected for a travel fellowship to present at the &lt;a href=&#34;https://www.cvs.rochester.edu/symposium/index.html&#34;&gt;Center for Visual Science&#39;s 32nd Symposium on Active Vision&lt;/a&gt;, hosted at the University of Rochester/Memorial Art Gallery (see photo).
In July, Byron received a travel award from the Helmsley Charitable Trust to attend the prestigious three-week course for &lt;a href=&#34;https://meetings.cshl.edu/courses.aspx?course=C-visi&amp;year=22&#34;&gt;Computational Neuroscience: Vision&lt;/a&gt; at the Cold Spring Harbor Laboratory.
And in August, Byron received a travel award to attend and give a talk about his research at the 2022 Biennial Perceptual Learning Workshop, held in Alyeska, Alaska. Congratulations, Byron!&lt;/p&gt;
&lt;p class=&#34;mt-2&#34;&gt;&lt;img src=&#34;ashley.png&#34; alt=&#34;Ashley Bruce profile picture&#34; align=&#34;right&#34; class=&#34;ml-2&#34; style=&#34;width: 26%&#34;/&gt;
Over in Computer Science, M.S. student Ashley Bruce was recognized with the &lt;a href=&#34;https://www.cs.ucsb.edu/happenings/announcement/congratulations-cs-graduate-student-awardees&#34;&gt;MS Student of the Year&lt;/a&gt; award, presented annually in recognition of a student who has excelled in both research and either department service or teaching.
Ashley&#39;s research involved the &lt;a href=&#34;https://bionicvisionlab.org/publications/2022-09-epiretinal-design/&#34;&gt;optimization of epiretinal implant designs&lt;/a&gt;, which was accepted to the main track at MICCAI &#39;22.
From faculty: &lt;i&gt;“Looking at her success and productivity, it is sometimes easy to forget that Ashley did not come from a traditional CS background. This means that a lot of the computing skills at which she now excels were self-taught. Not only did she make it into our prestigious Masters program, but she has thrived in it.”&lt;/i&gt;&lt;/p&gt;
&lt;p class=&#34;mt-2&#34;&gt;&lt;img src=&#34;yuchen.jpg&#34; alt=&#34;Yuchen Hou receiving the Nasser award&#34; align=&#34;left&#34; class=&#34;mr-2&#34; style=&#34;width: 40%&#34;/&gt;
Meanwhile &lt;a href=&#34;https://bionicvisionlab.org/people/hou_yuchen&#34;&gt;Yuchen Hou&lt;/a&gt; earned one of the most prestigious awards of the Psychological &amp; Brain Sciences (PBS) department: the Abdullah &amp; Marjorie R. Nasser Memorial Scholarship Fund Award.
This award recognizes Yuchen&#39;s outstanding scholarship (she finished her BS with a 3.98 overall GPA) and dedication to research.
We are fortunate to have Yuchen continue as Ph.D. student in the lab.&lt;/p&gt;
&lt;p class=&#34;mt-2&#34;&gt;&lt;img src=&#34;tanya.jpg&#34; alt=&#34;Tanya Bhatia profile picture&#34; align=&#34;right&#34; class=&#34;ml-2&#34; style=&#34;width: 26%&#34;/&gt;And the list goes on, with Tanya Bhatia winning the PBS Chairperson&#39;s Award - as well as the Exceptional Academic Performance Award alongside Yuchen Hou, Anvitha Akkaraju, and Ananth Mahes. In addition, Tanya and Anvitha completed innovative Honors Theses in the lab, which hopefully will see the light of the day as a peer-reviewed publication in the next couple of months.&lt;/p&gt;
&lt;p&gt;What a fantastic array of achievements. Congratulations everyone!&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>A neural autoencoder to enhance sensory neuroprostheses</title>
      <link>https://bionicvisionlab.org/news/2022-06-techxplore/</link>
      <pubDate>Tue, 21 Jun 2022 09:29:00 +0000</pubDate>
      
      <guid>https://bionicvisionlab.org/news/2022-06-techxplore/</guid>
      <description>&lt;p&gt;&amp;ldquo;We started working on this project in an attempt to solve the long-standing problem of stimulus optimization in visual prostheses,&amp;rdquo; &lt;a href=&#34;https://bionicvisionlab.org/people/granley_jacob&#34;&gt;Jacob Granley&lt;/a&gt;, one of the researchers who carried out the study, told TechXplore. &amp;ldquo;One of the likely causes for the poor results achieved by visual prostheses is the naive stimulus encoding strategy that devices conventionally use. Previous works have suggested encoding strategies, but many are unrealistic, and none have given a general solution that could work across implants and patients.&amp;rdquo;&lt;/p&gt;
&lt;p&gt;Read the full article at &lt;a href=&#34;https://techxplore.com/news/2022-06-neural-autoencoder-sensory-neuroprostheses.html&#34; target=&#34;_blank&#34;&gt;techxplore.com&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The paper has been accepted at NeurIPS &amp;lsquo;22.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Are we witnessing the dawn of post-theory science?</title>
      <link>https://bionicvisionlab.org/news/2022-01-guardian/</link>
      <pubDate>Sun, 09 Jan 2022 09:29:00 -0700</pubDate>
      
      <guid>https://bionicvisionlab.org/news/2022-01-guardian/</guid>
      <description>&lt;p&gt;Prof. Beyeler was mentioned in a recent article by The Guardian that discusses recent advances in machine learning and what data-driven discovery means for the classic methodology of hypothesizing, predicting, and testing.&lt;/p&gt;
&lt;blockquote&gt;
A tougher obstacle to the new science may be our human need to explain the world – to talk in terms of cause and effect. In 2019, neuroscientists Bingni Brunton and Michael Beyeler of the University of Washington, Seattle, wrote that this need for interpretability may have prevented scientists from making novel insights about the brain, of the kind that only emerges from large datasets. But they also sympathised. If those insights are to be translated into useful things such as drugs and devices, they wrote, “it is imperative that computational models yield insights that are explainable to, and trusted by, clinicians, end-users and industry”.
&lt;cite&gt;Laura Spinny, The Guardian&lt;/cite&gt;
&lt;/blockquote&gt;
&lt;p&gt;The full article can be read &lt;a href=&#34;https://www.theguardian.com/technology/2022/jan/09/are-we-witnessing-the-dawn-of-post-theory-science&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Will it ever be possible to upload information to my brain?</title>
      <link>https://bionicvisionlab.org/news/2021-09-giz-asks/</link>
      <pubDate>Mon, 20 Sep 2021 09:29:00 +0000</pubDate>
      
      <guid>https://bionicvisionlab.org/news/2021-09-giz-asks/</guid>
      <description>&lt;p&gt;Prof. Beyeler was part of the Giz Asks series, where the focused turned to the prospect of using brain-machine interface technology to directly write in information to the brain.&lt;/p&gt;
&lt;p&gt;Read the full interview &lt;a href=&#34;https://gizmodo.com/will-it-be-possible-to-upload-information-to-my-brain-1847698784&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Bionic Vision Lab featured in NVIDIA&#39;s I AM AI trailer</title>
      <link>https://bionicvisionlab.org/news/2021-04-nvidia-i-am-ai/</link>
      <pubDate>Wed, 21 Apr 2021 09:29:00 +0000</pubDate>
      
      <guid>https://bionicvisionlab.org/news/2021-04-nvidia-i-am-ai/</guid>
      <description>&lt;p&gt;Research by the Bionic Vision Lab was featured in &lt;a href=&#34;https://www.nvidia.com/en-us/about-nvidia/i-am-ai/&#34; target=&#34;_blank&#34;&gt;NVIDIA&amp;rsquo;s I AM AI trailer&lt;/a&gt;, which was premiered at NVIDIA GTC 2021:&lt;/p&gt;
&lt;iframe width=&#34;560&#34; height=&#34;315&#34; src=&#34;https://www.youtube.com/embed/zNX1knTo2F4&#34; title=&#34;YouTube video player&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture&#34; allowfullscreen&gt;&lt;/iframe&gt;</description>
    </item>
    
    <item>
      <title>PCMag: Building the bionic eye... with car tech?</title>
      <link>https://bionicvisionlab.org/news/2021-02-pcmag/</link>
      <pubDate>Tue, 23 Feb 2021 09:29:00 -0700</pubDate>
      
      <guid>https://bionicvisionlab.org/news/2021-02-pcmag/</guid>
      <description>&lt;p&gt;Over the years, cyberpunk tales and sci-fi series have featured characters with cybernetic vision—most recently Star Trek Discovery&amp;rsquo;s Lieutenant Keyla Detmer and her ocular implants. In the real world, restoring “natural” vision is still a complex puzzle, though researchers at UC Santa Barbara are developing a smart prosthesis that provides cues to the visually impaired, much like a computer vision system talks to a self-driving car.&lt;/p&gt;
&lt;p&gt;Today, over 10 million people worldwide are living with profound visual impairment, many due to retinal degeneration diseases. Ahead of this week&amp;rsquo;s Augmented Humans International Conference, we spoke with Dr. Michael Beyeler, Assistant Professor in Computer Science and Psychological &amp;amp; Brain Sciences at UCSB, who is forging ahead with synthetic sight trials at his Bionic Vision Lab and will be presenting a paper at the conference.&lt;/p&gt;
&lt;p&gt;Read the full interview &lt;a href=&#34;https://www.pcmag.com/news/building-the-bionic-eyewith-car-tech&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>SciSection: Interview with Michael Beyeler</title>
      <link>https://bionicvisionlab.org/news/2020-10-scisection/</link>
      <pubDate>Sat, 03 Oct 2020 09:29:00 +0000</pubDate>
      
      <guid>https://bionicvisionlab.org/news/2020-10-scisection/</guid>
      <description>&lt;p&gt;Dr. Beyeler sat down with Luming Cao from SciSection&amp;rsquo;s Human and Science platform to talk about how bionic vision, as sci-fi as it sounds, is already helping to restore vision to the blind.&lt;/p&gt;
&lt;p&gt;The transcript of this informal interview is now available, and a podcast will follow soon.&lt;/p&gt;
&lt;p&gt;Read the full interview &lt;a href=&#34;https://www.humansandscience.com/post/interview-with-dr-beyeler&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>UCSB Convergence: Reverse engineering the brain</title>
      <link>https://bionicvisionlab.org/news/2020-05-convergence/</link>
      <pubDate>Fri, 01 May 2020 09:29:00 -0700</pubDate>
      
      <guid>https://bionicvisionlab.org/news/2020-05-convergence/</guid>
      <description>&lt;p&gt;Michael Beyeler and the Bionic Vision Lab are featured heavily in the Spring Edition of UCSB&amp;rsquo;s College of Engineering Convergence Magazine:&lt;/p&gt;
&lt;blockquote&gt;
There is research to try to understand the brain—how it works on a mechanistic and algorithmic level—and then there&#39;s applying that to an engineered system that can interface with the brain. Brain-computer interfaces can be used both for treating neurological and mental disorders as well as for understanding brain function.
&lt;/blockquote&gt;
&lt;p&gt;Read the full article &lt;a href=&#34;https://engineering.ucsb.edu/convergence/spring-2020&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>PCMag: Restoring vision with bionic eyes - no longer science fiction</title>
      <link>https://bionicvisionlab.org/news/2019-07-pcmag/</link>
      <pubDate>Tue, 09 Jul 2019 09:29:00 +0000</pubDate>
      
      <guid>https://bionicvisionlab.org/news/2019-07-pcmag/</guid>
      <description>&lt;p&gt;A new article appeared in PCMag to celebrate the inauguration of the Bionic Vision Lab at UCSB:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Bionic vision might sound like science fiction, but Dr. Michael Beyeler is working on just that.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Originally from Switzerland, Dr. Beyeler is wrapping up his postdoctoral fellow at the University of Washington before moving to the University of California Santa Barbara this fall to head up the newly formed Bionic Vision Lab in the Departments of Computer Science and Psychological &amp;amp; Brain Sciences.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;We spoke with him about this &amp;ldquo;deep fascination with the brain&amp;rdquo; and how he hopes his work will eventually be able to restore vision to the blind. Here are edited and condensed excerpts from our conversation.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Read the full article &lt;a href=&#34;https://www.pcmag.com/news/369401/restoring-vision-with-bionic-eyes-no-longer-science-fiction&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
